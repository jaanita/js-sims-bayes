#!/usr/bin/env python3
"""
Generates plots / figures when run as a script.
Plot files are placed in the :file:`plots` directory.

By default, simply running ``python -m src.plots`` generates **ALL** plots,
which may not be desired.  Instead, one can pass a list of plots to generate:
``python -m src.plots plot1 plot2 ...``.  The full list of plots is shown in
the usage information ``python -m src.plots --help``.

Typing can be reduced by using shell brace expansion, e.g. ``python -m
src.plots observables_{design,posterior}`` for both ``observables_design`` and
``observables_posterior``.  In addition, plots may be given as paths to plot
filenames, which enables shell globbing, e.g. ``python -m src.plots
plots/observables_*``.

In the code, each plot is generated by a function tagged with the ``@plot``
decorator.
"""

from collections import OrderedDict
import itertools
import logging
from pathlib import Path
import subprocess
import tempfile
import warnings

import h5py
import hsluv
import numpy as np
import matplotlib
import matplotlib.pyplot as plt
from matplotlib import lines
from matplotlib import patches
from matplotlib import ticker
from scipy import special
from scipy.interpolate import PchipInterpolator
import pandas as pd
from textwrap import fill
import dill
#import random
from numpy.random import choice
import plotly.express as px
from plotly.subplots import make_subplots
import plotly.graph_objects as go
import seaborn as sns

from SALib.sample import saltelli
from SALib.analyze import sobol

from bayes_mcmc import Chain, credible_interval
from configurations import *
from emulator import Trained_Emulators, _Covariance
from calculations_load import trimmed_model_data, MAP_data
from bayes_exp import Y_exp_data
from design import Design

from mcmc_diagnostics import autocorrelation

from compare_events import model_data_1, model_data_2

fontsize = dict(
    large=11,
    normal=10,
    small=9,
    tiny=8,
)

qm_font_large = 11
qm_font_small = 9

cb,co,cg,cr = plt.cm.Blues(.6), \
    plt.cm.Oranges(.6), plt.cm.Greens(.6), plt.cm.Reds(.6)
offblack = '#262626'
gray = '0.8'

# new tableau colors
# https://www.tableau.com/about/blog/2016/7/colors-upgrade-tableau-10-56782
colors = OrderedDict([
    ('blue', '#4e79a7'),
    ('orange', '#f28e2b'),
    ('green', '#59a14f'),
    ('red', '#e15759'),
    ('cyan', '#76b7b2'),
    ('purple', '#b07aa1'),
    ('brown', '#9c755f'),
    ('yellow', '#edc948'),
    ('pink', '#ff9da7'),
    ('gray', '#bab0ac')
])

offblack = '.15'

plt.rcdefaults()
plt.rcParams.update({
    'font.family': 'sans-serif',
    'font.sans-serif': ['Lato'],
    'mathtext.fontset': 'custom',
    'mathtext.default': 'it',
    'mathtext.rm': 'sans',
    'mathtext.it': 'sans:italic:medium',
    'mathtext.cal': 'sans',
    'font.size': fontsize['normal'],
    'legend.fontsize': fontsize['normal'],
    'axes.labelsize': fontsize['normal'],
    'axes.titlesize': fontsize['large'],
    'xtick.labelsize': fontsize['small'],
    'ytick.labelsize': fontsize['small'],
    #'font.weight': 400,
    'axes.labelweight': 400,
    'axes.titleweight': 400,
    'axes.prop_cycle': plt.cycler('color', list(colors.values())),
    'lines.linewidth': .8,
    'lines.markersize': 3,
    'lines.markeredgewidth': 0,
    'patch.linewidth': .8,
    'axes.linewidth': .6,
    'xtick.major.width': .6,
    'ytick.major.width': .6,
    'xtick.minor.width': .4,
    'ytick.minor.width': .4,
    'xtick.major.size': 3.,
    'ytick.major.size': 3.,
    'xtick.minor.size': 2.,
    'ytick.minor.size': 2.,
    'xtick.major.pad': 3.5,
    'ytick.major.pad': 3.5,
    'axes.labelpad': 4.,
    'axes.formatter.limits': (-5, 5),
    'axes.spines.top': False,
    'axes.spines.right': False,
    'text.color': offblack,
    'axes.edgecolor': offblack,
    'axes.labelcolor': offblack,
    'xtick.color': offblack,
    'ytick.color': offblack,
    'legend.frameon': False,
    'image.cmap': 'Blues',
    'image.interpolation': 'none',
})

plotdir = workdir / 'plots'
plotdir.mkdir(exist_ok=True)
plot_functions = {}

def plot(f):
    """
    Plot function decorator.  Calls the function, does several generic tasks,
    and saves the figure as the function name.

    """
    def wrapper(*args, **kwargs):
        logging.info('generating plot: %s', f.__name__)
        f(*args, **kwargs)

        fig = plt.gcf()

        """
        if not fig.get_tight_layout():
            set_tight(fig)
        """

        plotfile = plotdir / '{}.png'.format(f.__name__)
        fig.savefig(str(plotfile), dpi=400, bbox_inches = 'tight', pad_inches = 0.05)
        logging.info('wrote %s', plotfile)
        plt.close(fig)

    plot_functions[f.__name__] = wrapper

    return wrapper


def figsize(relwidth=1, aspect=.618, refwidth=6):
    """
    Return figure dimensions from a relative width (to a reference width) and
    aspect ratio (default: 1/golden ratio).

    """
    width = relwidth * refwidth
    return width, width*aspect


def set_tight(fig=None, **kwargs):
    """
    Set tight_layout with a better default pad.

    """
    if fig is None:
        fig = plt.gcf()

    kwargs.setdefault('pad', .1)
    fig.set_tight_layout(kwargs)


def auto_ticks(ax, axis='both', minor=False, **kwargs):
    """
    Convenient interface to matplotlib.ticker locators.

    """
    axis_list = []

    if axis in {'x', 'both'}:
        axis_list.append(ax.xaxis)
    if axis in {'y', 'both'}:
        axis_list.append(ax.yaxis)

    for axis in axis_list:
        axis.get_major_locator().set_params(**kwargs)
        if minor:
            axis.set_minor_locator(ticker.AutoMinorLocator(minor))


def format_system(system):
    """
    Format a system string into a display name, e.g.:

    >>> format_system('PbPb2760')
    'Pb-Pb 2.76 TeV'

    >>> format_system('AuAu200')
    'Au-Au 200 GeV'

    """
    proj, energy = parse_system(system)

    if energy > 1000:
        energy /= 1000
        prefix = 'T'
    else:
        prefix = 'G'

    return '{} {} {}eV'.format('-'.join(proj), energy, prefix)


def darken(rgb, amount=.5):
    """
    Darken a color by the given amount in HSLuv space.

    """
    H, S, L = hsluv.rgb_to_hsluv(rgb)
    return hsluv.hsluv_to_rgb((H, S, (1 - amount)*L))


def obs_color_hsluv(obs, subobs):
    """
    Return a nice color for the given observable in HSLuv space.
    Use obs_color() to obtain an RGB color.

    """
    if obs in {'dNch_deta', 'pT_fluct'}:
        return 250, 90, 55

    if obs == 'dET_deta':
        return 10, 65, 55

    if obs in {'dN_dy', 'mean_pT'}:
        return dict(
            pion=(210, 85, 70),
            kaon=(130, 88, 68),
            proton=(30, 90, 62),
        )[subobs]

    if obs == 'vnk':
        return {
            (2, 2): (230, 90, 65),
            (2, 4): (262, 80, 63),
            (3, 2): (150, 90, 67),
            (4, 2): (310, 70, 50),
        }[subobs]

    raise ValueError('unknown observable: {} {}'.format(obs, subobs))

def obs_color(obs, subobs):
    """
    Return a nice color for the given observable.

    """
    return hsluv.hsluv_to_rgb(obs_color_hsluv(obs, subobs))

def obs_label(obs, subobs, differentials=False, full_cumulants=False):
    """
    Return a formatted label for the given observable.

    """
    if obs.startswith('d') and obs.endswith('_deta'):
        return (r'$d{}/d\eta$' if differentials else '${}$').format(
            {'Nch': r'N_\mathrm{ch}', 'ET': r'E_T'}[obs[1:-5]])

    id_parts_labels = {
        'dN_dy': '$dN_{}/dy$' if differentials else '$N_{}$',
        'mean_pT': r'$\langle p_T^{} \rangle$'
    }
    if obs in id_parts_labels:
        return id_parts_labels[obs].format(
            {'pion': '\pi', 'kaon': 'K', 'proton': 'p'}[subobs]
        )

    if obs == 'pT_fluct':
        return r'$\delta p_T/\langle p_T \rangle$'

    if obs == 'vnk':
        n, k = subobs
        return '$v_{}{}$'.format(
            n,
            (r'\{' + str(k) + r'\}') if full_cumulants else ''
        )
obs_tex_labels = {
                    'dNch_deta' : r'$dN_{ch}/d\eta$',
                    'dN_dy_pion' : r'$dN_{\pi}/dy$',
                    'dN_dy_kaon' : r'$dN_{k}/dy$',
                    'dN_dy_proton' : r'$dN_{p}/dy$',
                    'dN_dy_Lambda' : r'$dN_{\Lambda}/dy$',
                    'dN_dy_Omega' : r'$dN_{\Omega}/dy$',
                    'dN_dy_Xi' : r'$dN_{\Xi}/dy$',
                    'dN_dy_d' : r'$dN_{d}/dy$',
                    'dET_deta' : r'$dE_{T}/d\eta$',
                    'mean_pT_pion' : r'$\pi$',
                    'mean_pT_kaon' : r'$k$',
                    'mean_pT_proton' : r'$p$',
                    'mean_pT_d' : r'$d$',
                    'pT_fluct' : None,
                    'v22' : r'$v_2\{2\}$',
                    'v32' : r'$v_3\{2\}$',
                    'v42' : r'$v_4\{2\}$',
                    'v22_d' : r'$v_2\{2\}_{d}$',
}

obs_tex_labels_2 = {
                    'dNch_deta' : r'$dN_{ch}/d\eta$',
                    'dN_dy_pion' : r'$dN_{\pi}/dy$',
                    'dN_dy_kaon' : r'$dN_{k}/dy$',
                    'dN_dy_proton' : r'$dN_{p}/dy$',
                    'dN_dy_Lambda' : r'$dN_{\Lambda}/dy$',
                    'dN_dy_Omega' : r'$dN_{\Omega}/dy$',
                    'dN_dy_Xi' : r'$dN_{\Xi}/dy$',
                    'dET_deta' : r'$dE_{T}/d\eta$',
                    'mean_pT_pion' : r'$\langle p_T \rangle _{\pi}$',
                    'mean_pT_kaon' : r'$\langle p_T \rangle _{k}$',
                    'mean_pT_proton' : r'$\langle p_T \rangle _{p}$',
                    'pT_fluct' : r'$\delta p_T / \langle p_T \rangle$',
                    'v22' : r'$v_2\{2\}$',
                    'v32' : r'$v_3\{2\}$',
                    'v42' : r'$v_4\{2\}$',
}

idf_color = {0 : 'blue', 1 : 'red', 2 : 'magenta', 3 : 'green'}

def truncate_colormap(cmap, minval=0.0, maxval=1.0, n=100):
    new_cmap = matplotlib.colors.LinearSegmentedColormap.from_list(
        'trunc({n},{a:.2f},{b:.2f})'.format(n=cmap.name, a=minval, b=maxval),
        cmap(np.linspace(minval, maxval, n)))
    return new_cmap

def calculate_information_gain(h0, h1, dx):
    """ Return the information gain of pdf x1 w.r.t. x0, approximated by
    riemann sum over histograms of each pdf. Assumes that distributions have the exact same bins
    and that bin widths are uniform! """
    #get nonzero values of posterior, the logarithm is ill-defined for bins with zero
    nonzero_idx = np.nonzero(h1)
    h1 = h1[ nonzero_idx ]
    h0 = h0[ nonzero_idx ]
    nonzero_idx = np.nonzero(h0)
    h1 = h1[ nonzero_idx ]
    h0 = h0[ nonzero_idx ]

    info = np.sum( h1 * np.log2(h1/h0) ) * np.prod(dx)
    return info

def _observables(posterior=False, ratio=False):
    """
    Model observables at all design points or drawn from the posterior with
    experimental data points.

    """

    #sns.set()

    if posterior:
        print("Plotting observables drawn from posterior")
        chain = Chain(path=workdir/'mcmc'/'chain-idf-0_LHC_RHIC_PTEMCEE.hdf')
        Ymodel = chain.samples(1000)

    else:
        Ymodel = trimmed_model_data

    if validation:
        #get VALIDATION points
        design_file = design_dir + '/design_points_validation_{:s}{:s}-{:d}.dat'.format(*systems[0])
        logging.info("Loading design points from " + design_file)
        design = pd.read_csv(design_file)
        design = design.drop("idx", axis=1)
        truth = design.values[validation_pt]
        Yexp = Y_exp_data[0]

    else:
        Yexp = Y_exp_data

    highlight_sets =  []
    for system in system_strs:
        fig, axes = plt.subplots(nrows=3, ncols=3, figsize=(6,4), sharex=True)
        subaxes = axes.flatten()
        for obs, ax in zip(active_obs_list[system], subaxes):
            # sys labels
            # Centrality bins
            xbins = np.array(obs_cent_list[system][obs])
            x = (xbins[:,0]+xbins[:,1])/2.

            # plot exp
            try:
                exp_mean = Yexp[system][obs]['mean'][idf]
                exp_err = Yexp[system][obs]['err'][idf]
            except KeyError:
                continue
            ax.errorbar(x, np.ones_like(x) if ratio else exp_mean,
                        yerr=exp_err/exp_mean if ratio else exp_err,
                        fmt='ko')

            # plot calc
            if posterior:
                Y = Ymodel[system][obs]
            else:
                #Y = Ymodel[system][obs]['mean'][idf]
                Y = Ymodel[system][:, idf][obs]['mean']

            alpha = 0.4
            lw = 0.2
            color = idf_color[idf]
            if posterior:
                if ratio:
                    plt.suptitle('Combined System Posterior : Model/Experiment for Au-Au 0.2 TeV')
                    y = Y/exp_mean
                    ax.fill_between(x,
                            np.percentile(y, 5, axis=0),
                            np.percentile(y, 95, axis=0),
                            color=color, alpha=alpha
                    )
                    ax.fill_between(x,
                            np.percentile(y, 20, axis=0),
                            np.percentile(y, 80, axis=0),
                            color=color, alpha=alpha
                    )
                else:
                    ax.plot(x, Y.T, color=color, alpha=alpha, lw=lw)
            else:
                ax.plot(x, (Y/exp_mean).T if ratio else Y.T,
                        color=color, alpha=alpha, lw=lw)
            # axis and limits
            ax.set_xlim(0, 70)
            if ratio:
                ax.set_ylim(0.5, 1.5)
                ax.plot([0,70],[1,1],'k--', alpha=0.6)
                ax.fill_between([0,70],[.9,.9], [1.1,1.1],color='k', alpha=0.2)
            else:
                ax.set_ylim(*obs_range_list[system][obs])
            auto_ticks(ax, 'x', nbins=5, minor=2)

            if ax.is_last_row():
                ax.set_xlabel('Centrality %')

            ax.set_ylabel(obs_tex_labels_2[obs])

    plt.tight_layout(True)
    set_tight(fig, rect=[0, 0, 0.97, 0.95])


@plot
def observables_posterior_discrepancy_PRL():
    """
    Model observables predicted by Chains for each df model, discrepancy against expt. data.

    """

    df_choices = [0, 1, 3] # choose which df models to plot
    obs_choices = ['dN_dy_pion', 'dN_dy_proton', 'dET_deta', 'mean_pT_pion', 'mean_pT_proton', 'pT_fluct', 'v22', 'v32', 'v42']

    color_idf = {0:'blue', 1:'red', 2:'magenta', 3:'green'} # colors for different df models
    ls_idf = {0:'-', 1:'--', 3:':'}

    n_samples = 10000 #number of draws from posterior
    alpha = 0.4 #alpha of plot
    lw = 2

    Ymodels = []
    for idf in df_choices:
        print("idf = " + str(idf))
        chain = Chain(path=workdir/'mcmc'/'chain-idf-{:}_LHC_RHIC_PTEMCEE.hdf'.format(idf))
        Ymodel = chain.samples_given_df(idf, n_samples)
        Ymodels.append(Ymodel)

    Yexp = Y_exp_data

    for system in ['Pb-Pb-2760']:
    #for system in ['Au-Au-200']:
        fig, axes = plt.subplots(nrows=3, ncols=3, figsize=(6,3.5), sharex=True)
        subaxes = axes.flatten()
        #print(active_obs_list[system])
        for obs, ax in zip(obs_choices, subaxes):
            # Centrality bins
            xbins = np.array(obs_cent_list[system][obs])
            x = (xbins[:,0]+xbins[:,1])/2.
            # plot exp
            try:
                exp_mean = Yexp[system][obs]['mean'][idf]
                exp_err = Yexp[system][obs]['err'][idf]
            except KeyError:
                continue
            ax.fill_between([0,70],[-1,-1], [1,1], color='k', alpha=0.2) #1 std dev fill
            #ax.errorbar(x, np.zeros_like(x), yerr=exp_err/exp_mean,fmt='ko')

            # plot calc
            for i, idf in enumerate(df_choices):
                Ymodel = Ymodels[i]
                Y = Ymodel[system][obs]
                y = (Y - exp_mean)/exp_err # model number of expt std deviations from expt mean
                #y = (Y - exp_mean)/exp_mean # model percent error with data
                color = color_idf[idf]
                ls = ls_idf[idf]


                label=None
                if obs == 'dN_dy_pion':
                    if idf == 0:
                        label = idf_label_short[idf]

                if obs == 'dN_dy_proton':
                    if idf == 1:
                        label = idf_label_short[idf]

                if obs == 'dET_deta':
                    if idf == 3:
                        label = idf_label_short[idf]


                #fill between credible intervals
                ax.fill_between(x, np.percentile(y, 5, axis=0), np.percentile(y, 95, axis=0),
                                edgecolor=color, facecolor='None', lw=lw, ls=ls, label=label
                                )
                #ax.fill_between(x, np.percentile(y, 49, axis=0), np.percentile(y, 51, axis=0),
                #                color=color, lw=lw, ls='--'
                #                )

                #plot samples
                #for n in range(n_samples):
                #    ax.plot(x, y[n], color=color, alpha=alpha)

                if obs == 'dN_dy_pion':
                    ax.legend(fontsize=8, borderpad=0, labelspacing=0.2,
                                    handlelength=2, handleheight=1.5,
                                    loc='upper left')
                if obs == 'dN_dy_proton':
                    ax.legend(fontsize=8, borderpad=0, labelspacing=0.2,
                                    handlelength=2, handleheight=1.5,
                                    loc='upper left')
                if obs == 'dET_deta':
                    ax.legend(fontsize=8, borderpad=0, labelspacing=0.2,
                                    handlelength=2, handleheight=1.5,
                                    loc='upper left')


            ax.set_xlim(0, 70)
            ax.set_ylim(-5, 5)
            if obs=='v22':
                ax.set_ylim(-10, 10)
            auto_ticks(ax, 'x', nbins=5, minor=2)
            auto_ticks(ax, 'y', nbins=5, minor=2)

            if ax.is_last_row():
                ax.set_xlabel('Centrality %')

            ax.set_ylabel(obs_tex_labels_2[obs])

    #axes[0,0].legend(fontsize=8, borderpad=0, labelspacing=0.2,
    #                handlelength=2, #handletextpad=0.2,
    #                loc='upper left')
    plt.tight_layout(True)
    plt.subplots_adjust(hspace=0.1, wspace=0.5)
    fig.align_ylabels()


@plot
def observables_posterior_discrepancy_with_xe():
    """
    Model observables predicted by Chains for each df model, discrepancy against expt. data.

    """

    df_choices = [0] # choose which df models to plot

    color_idf = {0:'blue', 1:'red', 2:'magenta', 3:'green'} # colors for different df models
    ls_idf = {0:'-', 1:'--', 3:':'}

    n_samples = 100000 #number of draws from posterior
    alpha = 0.4 #alpha of plot
    lw = 2

    Ymodels = []
    for idf in df_choices:
        print("idf = " + str(idf))
        chain = Chain(path=workdir/'mcmc'/'chain-idf-{:}_LHC_RHIC_XE.hdf'.format(idf))
        Ymodel = chain.samples_given_df(idf, n_samples)
        Ymodels.append(Ymodel)

    Yexp = Y_exp_data

    fig, axes = plt.subplots(nrows=4, ncols=5, figsize=(10,8), sharex=True)
    subaxes = axes.flatten()
    systems = ['Pb-Pb-2760', 'Au-Au-200', 'Xe-Xe-5440']
    sys_labels = {'Pb-Pb-2760': r'Pb 2.76', 'Au-Au-200' : r'Au 0.2', 'Xe-Xe-5440' : r'Xe 5.44'}
    ax_i = 0
    for system in systems:
        sys_label = sys_labels[system]
        obs_choices = active_obs_list[system]
        for obs in obs_choices:

            if (system=='Pb-Pb-2760') and (obs=='mean_pT_kaon'):
                continue
            ax = subaxes[ax_i]
            # Centrality bins
            xbins = np.array(calibration_obs_cent_list[system][obs])
            x = (xbins[:,0]+xbins[:,1])/2.
            # plot exp
            try:
                exp_mean = Yexp[system][obs]['mean'][idf]
                exp_err = Yexp[system][obs]['err'][idf]
            except KeyError:
                continue
            ax.fill_between([0,70],[-1,-1], [1,1], color='k', alpha=0.2) #1 std dev fill

            # plot calc
            for i, idf in enumerate(df_choices):
                Ymodel = Ymodels[i]
                Y = Ymodel[system][obs]
                y = (Y - exp_mean)/exp_err # model number of expt std deviations from expt mean
                color = color_idf[idf]
                ls = ls_idf[idf]

                #fill between credible intervals
                ax.fill_between(x, np.percentile(y, 5, axis=0), np.percentile(y, 95, axis=0),
                                color=color, lw=lw, ls=ls, alpha=0.4
                                )
                ax.fill_between(x, np.percentile(y, 49, axis=0), np.percentile(y, 51, axis=0),
                                color=color, lw=lw,
                                )

            ax.set_xlim(0, 70)
            ax.set_ylim(-6, 6)
            auto_ticks(ax, 'x', nbins=5, minor=2)
            auto_ticks(ax, 'y', nbins=5, minor=2)

            if ax.is_last_row():
                ax.set_xlabel('Centrality %')

            ax.set_ylabel(obs_tex_labels_2[obs] + ' ' + sys_label)
            ax_i += 1

    plt.tight_layout(True)
    fig.align_ylabels()

@plot
def observables_joint_posterior_discrepancy_PRL():
    """
    Model observables predicted by Chains for each df model, discrepancy against expt. data.

    """

    #sns.set()
    gridsize=25
    n_samples = int(1e5) #number of draws from posterior
    alpha = 0.6 #alpha of plot
    lw = 2
    fontsize=7

    obs_choices = ['dNch_deta', 'dN_dy_pion', 'dN_dy_proton', 'v22']
    n_obs = len(obs_choices)

    df_choices = [0, 1] # choose which df models to plot
    cent_bin = 0

    cmaps_idf = {0:plt.get_cmap('Blues'), 1:plt.get_cmap('Reds'), 3:plt.get_cmap('Greens')} # colors for different df models
    colors_idf = {0:'blue', 1:'red', 3:'green'}

    Ymodels = []
    for idf in df_choices:
        chain = Chain(path=workdir/'mcmc'/'chain-idf-{:}_LHC_RHIC_PTEMCEE.hdf'.format(idf))
        Ymodel = chain.samples_given_df(idf, n_samples)
        Ymodels.append(Ymodel)

    Yexp = Y_exp_data

    for system in ['Pb-Pb-2760']:
        fig, axes = plt.subplots(nrows=n_obs, ncols=n_obs, figsize=(1.5*n_obs,1.5*n_obs))
        for col, obs1 in enumerate(obs_choices):
            # Centrality bins
            xbins1 = np.array(obs_cent_list[system][obs1])
            x1 = (xbins1[:,0]+xbins1[:,1])/2.
            x1_bin = x1[cent_bin]
            # plot exp

            exp_mean1 = Yexp[system][obs1]['mean'][0, cent_bin]
            exp_err1 = Yexp[system][obs1]['err'][0, cent_bin]

            for row, obs2 in enumerate(obs_choices):
                # Centrality bins
                xbins2 = np.array(obs_cent_list[system][obs2])
                x2 = (xbins2[:,0]+xbins2[:,1])/2.
                x2_bin = x2[cent_bin]
                # plot exp

                exp_mean2 = Yexp[system][obs2]['mean'][0, cent_bin]
                exp_err2 = Yexp[system][obs2]['err'][0, cent_bin]

                # plot calc
                for i, idf in enumerate(df_choices):
                    Ymodel = Ymodels[i]

                    Y1 = Ymodel[system][obs1][:, cent_bin]
                    y1 = (Y1 - exp_mean1)/exp_err1 # model number of expt std deviations from expt mean

                    Y2 = Ymodel[system][obs2][:, cent_bin]
                    y2 = (Y2 - exp_mean2)/exp_err2 # model number of expt std deviations from expt mean
                    cmap = cmaps_idf[idf]
                    color = colors_idf[idf]

                    if row == col:
                        #axes[row, col].hist(y1, edgecolor=color, facecolor='None', bins=binsx, density=True)
                        sns.kdeplot(y1, color=color, ax=axes[row, col], shade=True)
                        auto_ticks(axes[row,col], 'x', nbins=5, minor=2)
                        axes[row,col].get_yaxis().set_visible(False)
                    elif col < row:
                        #axes[row, col].hist2d(y1, y2, cmap=cmap, bins=[binsx, binsy], alpha=alpha)
                        axes[row,col].axhline(0, ls='--', color='gray')
                        axes[row,col].axvline(0, ls='--', color='gray')
                        sns.kdeplot(y1, y2, color=color, shade=True, ax=axes[row, col],
                        gridsize=gridsize, shade_lowest=False, alpha=alpha, levels=5)
                        auto_ticks(axes[row,col], 'x', nbins=5, minor=2)
                        auto_ticks(axes[row,col], 'y', nbins=7, minor=2)
                    else:
                        axes[row,col].set_visible(False)

                if axes[row,col].is_last_row():
                    axes[row, col].set_xlabel(obs_tex_labels_2[obs1])
                if axes[row,col].is_first_col():
                    axes[row, col].set_ylabel(obs_tex_labels_2[obs2])

                if col == 0:
                    axes[row,col].set_xlim(-5, 0.9)
                if col == 1:
                    axes[row,col].set_xlim(-3, 0.9)
                if col == 2:
                    axes[row,col].set_xlim(-2, 2)
                if col == 3:
                    axes[row,col].set_xlim(-5, 5)

                if row != col:
                    if row == 1:
                        axes[row,col].set_ylim(-3, 0.9)
                    if row == 2:
                        axes[row,col].set_ylim(-2, 2)
                    if row == 3:
                        axes[row,col].set_ylim(-5, 5)

                if ( axes[row,col].is_last_row() == False ):
                    axes[row,col].get_xaxis().set_visible(False)
                if ( axes[row,col].is_first_col() == False ):
                    axes[row,col].get_yaxis().set_visible(False)

    plt.tight_layout(True)
    plt.subplots_adjust(wspace=0, hspace=0)

@plot
def observables_fit():
    """
    Model observables at all design points or drawn from the posterior with
    experimental data points.

    """
    print("Plotting observables drawn from posterior")

    obs_groups = {
                'yields' : ['dN_dy_pion', 'dN_dy_kaon', 'dN_dy_proton', 'dN_dy_Lambda', 'dN_dy_Omega', 'dN_dy_Xi', 'dNch_deta', 'dET_deta'],
                #'yields' : ['dN_dy_pion', 'dN_dy_kaon', 'dN_dy_proton', 'dNch_deta', 'dET_deta'],
                #'mean_pT' : ['mean_pT_pion', 'mean_pT_kaon', 'mean_pT_proton'],
                'flows' : ['v22', 'v32', 'v42'],
                #'fluct' : ['pT_fluct']
                }
    obs_group_labels = {
                #'yields' : r'$dN_{ch}/d\eta$ , $dN/dy$, $dE_T/d\eta$ [GeV]',
                'yields' : r'$dN_{ch}/d\eta$',
                'mean_pT' : r'$ \langle p_T \rangle$ [GeV]',
                'fluct' : r'$\delta p_T / \langle p_T \rangle$',
                'flows' : r'$v_n \{ 2 \} $'
                }

    colors = ['b', 'g', 'r', 'c', 'm', 'tan', 'orange', 'gray']

    #chain = Chain(path=workdir/'mcmc'/'chain-idf-0_LHC_RHIC_PTEMCEE.hdf')
    chain = Chain(path=workdir/'mcmc'/'chain-idf-0_Xe.hdf')
    Ymodel = chain.samples(100)
    Yexp = Y_exp_data
    n_systems = len(system_strs)
    nrows = 4
    height_ratios = [1.9, 1.1, 1.5, 1.]
    if system_strs == ['Au-Au-200']:
        nrows = 3
        height_ratios = [1.8, 1.2, 1.5]
        del obs_groups['fluct']

    elif system_strs == ['Xe-Xe-5440']:
        nrows = 2
        height_ratios = [1., 1.]

    fig, axes = plt.subplots(nrows=nrows, ncols=n_systems, figsize=(2.5*n_systems,2.5*nrows), squeeze=False, gridspec_kw={'height_ratios': height_ratios})
    #fig.suptitle("Observables Posterior : " + idf_label[idf] + " \n Visc. Correction ")
    for row, obs_group in enumerate( obs_groups.keys() ):
        for obs, color in zip(obs_groups[obs_group], colors):
            for col, system in enumerate(system_strs):
                if system == 'Pb-Pb-2760' or system == 'Xe-Xe-5440':
                    expt_label='ALICE'
                    expt_marker='v'
                if system == 'Au-Au-200':
                    expt_label='STAR'
                    expt_marker='.'

                axes[row][col].tick_params(labelsize=11)

                if obs in active_obs_list[system]:
                    if obs_group == 'yields':
                        axes[row][col].set_yscale('log')
                    scale = 1.0
                    if obs == 'dET_deta':
                        scale = 5.
                    #if obs == 'dNch_deta':
                    #    scale = 2.
                    try :
                        axes[row][col].set_ylabel(obs_group_labels[obs_group], fontsize=qm_font_large)
                        xbins = np.array(calibration_obs_cent_list[system][obs])
                        x = (xbins[:,0]+xbins[:,1])/2.
                        Y = Ymodel[system][obs]
                        for iy, y in enumerate(Y):
                            label = None
                            if iy == 0:
                                if scale == 1.0 :
                                    label=obs_tex_labels[obs]
                                else :
                                    label=obs_tex_labels[obs] + 'x' + str(scale)
                            axes[row][col].plot(x, y*scale, alpha=0.3, lw=0.3, color=color, label=label)
                        try:
                            exp_mean = Yexp[system][obs]['mean'][idf]
                            exp_err = Yexp[system][obs]['err'][idf]
                        except KeyError:
                            continue

                        if obs == 'dET_deta':
                            scale = 5.
                        #if obs == 'dNch_deta':
                        #    scale = 2.
                        if scale == 1.0 :
                            label=obs_tex_labels[obs]
                        else :
                            label=obs_tex_labels[obs] + 'x' + str(scale)


                        #if system=='Pb-Pb-2760':
                        l1 = axes[row][col].errorbar( x, exp_mean*scale, exp_err, color='black', fmt=expt_marker, markersize='4', elinewidth=1)
                        #l1 = axes[row][col].errorbar( x, exp_mean*scale, exp_err, color=color, fmt=expt_marker, markersize='4', elinewidth=1, label=label)
                        #elif system=='Au-Au-200':
                        #l2 = axes[row][col].errorbar( x, exp_mean*scale, exp_err, color='black', fmt=expt_marker, markersize='4', elinewidth=1)
                        #l2 = axes[row][col].errorbar( x, exp_mean*scale, exp_err, color=color, fmt=expt_marker, markersize='4', elinewidth=1, label=label)

                    except KeyError :
                        continue

                    leg = axes[row][col].legend(fontsize=qm_font_small, borderpad=0, labelspacing=0, handlelength=1, handletextpad=0.2)
                    if row == 0:
                        if col == 0:
                            leg = axes[row][col].legend(fontsize=qm_font_small, borderpad=0, labelspacing=0, handlelength=1, handletextpad=0.2, loc='upper right')

                    for legobj in leg.legendHandles:
                        legobj.set_linewidth(2.0)
                        legobj.set_alpha(1.0)

                    if system == 'Au-Au-200':
                        axes[row][col].set_xlim(0, 50)
                    else :
                        axes[row][col].set_xlim(0, 70)

                    #if obs_group == 'yields':
                    #    axes[row][col].set_ylim(1.7e0, 1e5)
                    if obs_group == 'mean_pT':
                        axes[row][col].set_ylim(0., 1.5)
                    if obs_group == 'fluct':
                        axes[row][col].set_ylim(0.0, 0.04)
                    #if obs_group == 'flows':
                    #    axes[row][col].set_ylim(0.0, 0.12)
                    if axes[row][col].is_last_row():
                        axes[row][col].set_xlabel('Centrality %', fontsize=qm_font_large)

                    if len(system_strs) > 1:
                        axes[2][1].set_xlabel('Centrality %', fontsize=qm_font_large)

                else :
                    continue

    if num_systems == 2:
        fig.delaxes(axes[3][1])
    plt.tight_layout(True)
    set_tight(fig, rect=[0, 0, 1, .95])
    fig.suptitle("Observables Posterior : " + idf_label[idf], wrap=True)

@plot
def observables_fit_MAP():
    """
    Model observables calculated at MAP parameters with hybrid model, with
    experimental data points.

    """
    print("Plotting observables calculated at MAP params by hybrid model")

    plot_exp = True # if True, plot experimental data. if False, plot emu mean prediction

    obs_groups = {
                'yields' : ['dN_dy_pion', 'dN_dy_kaon', 'dN_dy_proton', 'dNch_deta', 'dET_deta'],
                #'yields' : ['dN_dy_pion', 'dN_dy_kaon', 'dN_dy_proton', 'dN_dy_d'],
                'mean_pT' : ['mean_pT_pion', 'mean_pT_kaon', 'mean_pT_proton'],
                #'mean_pT' : ['mean_pT_pion', 'mean_pT_kaon', 'mean_pT_proton', 'mean_pT_d'],
                'flows' : ['v22', 'v32', 'v42'],
                'fluct' : ['pT_fluct']
                }
    obs_group_labels = {
                'yields' : r'$dN_{ch}/d\eta$ , $dN/dy$, $dE_T/d\eta$ [GeV]',
                'mean_pT' : r'$ \langle p_T \rangle$',
                'fluct' : r'$\delta p_T / \langle p_T \rangle$',
                'flows' : r'$v_n \{ 2 \} $'
                }

    colors = ['b', 'g', 'r', 'c', 'm', 'tan', 'gray']
    Ymodel = MAP_data
    Yexp = Y_exp_data
    n_systems = len(system_strs)
    nrows = 4
    #height_ratios = [1.8, 1.2, 1.5]
    height_ratios = [1.8, 1.2, 1.5, 1.]
    if system_strs == ['Au-Au-200']:
        nrows = 3
        height_ratios = [1.8, 1.2, 1.5]
        del obs_groups['fluct']

    fig, axes = plt.subplots(nrows=nrows, ncols=n_systems, figsize=(2.5*n_systems,9), squeeze=False, gridspec_kw={'height_ratios': height_ratios})
    for row, obs_group in enumerate( obs_groups.keys() ):
        for obs, color in zip(obs_groups[obs_group], colors):

            for col, system in enumerate(system_strs):
                if system == 'Pb-Pb-2760' or system == 'Xe-Xe-5440':
                    expt_label='ALICE'
                    expt_marker='v'
                if system == 'Au-Au-200':
                    expt_label='STAR'
                    expt_marker='.'
                emu = dill.load(open('emulator/emulator-' + system + '-idf-' + str(idf) + '.dill', "rb"))

                axes[row][col].tick_params(labelsize=11)

                if obs in active_obs_list[system]:

                    #Yemu_mean = emu.predict( np.array( [MAP_params[system]] ) )
                    #y_emu = Yemu_mean[obs][0]

                    if obs_group == 'yields':
                        axes[row][col].set_yscale('log')
                    scale = 1.0
                    if obs == 'dET_deta':
                        scale = 5.
                    if obs == 'dNch_deta':
                        scale = 2.
                    if obs == 'dN_dy_d':
                        scale = 200.
                    try :
                        axes[row][col].set_ylabel(obs_group_labels[obs_group], fontsize=qm_font_large)
                        xbins = np.array(obs_cent_list[system][obs])
                        x = (xbins[:,0]+xbins[:,1])/2.
                        Y = Ymodel[system][obs]['mean'][idf][0]
                        Yerr = Ymodel[system][obs]['err'][idf][0]
                        is_mult = ('dN' in obs) or ('dET' in obs)
                        if is_mult and transform_multiplicities:
                            Y = np.exp(Y) - 1.0
                        if scale == 1.0 :
                            label=obs_tex_labels[obs]
                        else :
                            label=obs_tex_labels[obs] + 'x' + str(scale)
                        axes[row][col].plot(x, Y*scale, color=color, label=label, lw=2.0)
                        if not plot_exp:
                            axes[row][col].scatter(x, y_emu*scale, color=color, marker='o', lw=2.0)
                        axes[row][col].fill_between(x, (Y-Yerr)*scale, (Y+Yerr)*scale, color=color, alpha=0.3)

                        #np.savetxt('matt_obs/' + obs + '.dat', (x, Y, Yerr))

                        try:
                            exp_mean = Yexp[system][obs]['mean'][idf]
                            exp_err = Yexp[system][obs]['err'][idf]
                        except KeyError:
                            pass

                        if plot_exp:
                            if system=='Pb-Pb-2760':
                                l1 = axes[row][col].errorbar( x, exp_mean*scale, exp_err, color='black', fmt=expt_marker, markersize='4', elinewidth=1)
                            elif system=='Au-Au-200':
                                l2 = axes[row][col].errorbar( x, exp_mean*scale, exp_err, color='black', fmt=expt_marker, markersize='4', elinewidth=1)

                    except KeyError :
                        pass

                    leg = axes[row][col].legend(fontsize=qm_font_small, borderpad=0, labelspacing=0, handlelength=1, handletextpad=0.2)
                    for legobj in leg.legendHandles:
                        legobj.set_linewidth(2.0)
                        legobj.set_alpha(1.0)

                    if system == 'Au-Au-200':
                        axes[row][col].set_xlim(0, 50)
                    else :
                        axes[row][col].set_xlim(0, 70)

                    if obs_group == 'yields':
                        axes[row][col].set_ylim(1, 1e4)
                    if obs_group == 'mean_pT':
                        axes[row][col].set_ylim(0., 1.6)
                    if obs_group == 'fluct':
                        axes[row][col].set_ylim(0.0, 0.04)
                    if obs_group == 'flows':
                        axes[row][col].set_ylim(0.0, 0.12)
                    if axes[row][col].is_last_row():
                        axes[row][col].set_xlabel('Centrality %', fontsize=qm_font_large)
                else :
                    pass

    if num_systems == 2:
        fig.delaxes(axes[3][1])
    plt.tight_layout(True)
    set_tight(fig, rect=[0, 0, 1, .93])
    fig.suptitle("Observables at MAP : " + idf_label[idf], wrap=True)

@plot
def observables_fit_deuteron():
    """
    Model observables calculated at MAP parameters with hybrid model, with
    experimental data points.

    """
    print("Plotting observables calculated at MAP params by hybrid model")

    obs_groups = {
                'yields' : ['dN_dy_pion', 'dN_dy_kaon', 'dN_dy_proton', 'dN_dy_d'],
                'mean_pT' : ['mean_pT_pion', 'mean_pT_kaon', 'mean_pT_proton', 'mean_pT_d'],
                'flows' : ['v22', 'v32', 'v42', 'v22_d'],
                }
    obs_group_labels = {
                'yields' : r'$dN_{ch}/d\eta$ , $dN/dy$, $dE_T/d\eta$ [GeV]',
                'mean_pT' : r'$ \langle p_T \rangle$',
                'fluct' : r'$\delta p_T / \langle p_T \rangle$',
                'flows' : r'$v_n \{ 2 \} $'
                }

    colors = ['b', 'g', 'r', 'c', 'm', 'tan', 'gray']
    Ymodel = MAP_data
    Yexp = Y_exp_data
    n_systems = len(system_strs)
    nrows = 3
    height_ratios = [1.8, 1.2, 1.5]
    if system_strs == ['Au-Au-200']:
        nrows = 3
        height_ratios = [1.8, 1.2, 1.5]
        del obs_groups['fluct']

    fig, axes = plt.subplots(nrows=nrows, ncols=n_systems, figsize=(2.5*n_systems,9), squeeze=False, gridspec_kw={'height_ratios': height_ratios})
    for row, obs_group in enumerate( obs_groups.keys() ):
        for obs, color in zip(obs_groups[obs_group], colors):

            for col, system in enumerate(system_strs):
                if system == 'Au-Au-200':
                    expt_label='STAR'
                    expt_marker='.'
                else:
                    expt_label='ALICE'
                    expt_marker='v'

                axes[row][col].tick_params(labelsize=11)

                if obs in active_obs_list[system]:

                    if obs_group == 'yields':
                        axes[row][col].set_yscale('log')
                    scale = 1.0
                    if obs == 'dET_deta':
                        scale = 5.
                    if obs == 'dNch_deta':
                        scale = 2.
                    if obs == 'dN_dy_d':
                        scale = 200.
                    try :
                        axes[row][col].set_ylabel(obs_group_labels[obs_group], fontsize=qm_font_large)
                        xbins = np.array(obs_cent_list[system][obs])
                        x = (xbins[:,0]+xbins[:,1])/2.
                        #Y = Ymodel[system][obs]['mean'][idf][0]
                        Y = Ymodel[system][obs]['mean'][0][idf]
                        #Yerr = Ymodel[system][obs]['err'][idf][0]
                        Yerr = Ymodel[system][obs]['err'][0][idf]
                        is_mult = ('dN' in obs) or ('dET' in obs)
                        if is_mult and transform_multiplicities:
                            Y = np.exp(Y) - 1.0
                        if scale == 1.0 :
                            label=obs_tex_labels[obs]
                        else :
                            label=obs_tex_labels[obs] + 'x' + str(scale)
                        axes[row][col].plot(x, Y*scale, color=color, label=label, lw=2.0)
                        axes[row][col].fill_between(x, (Y-Yerr)*scale, (Y+Yerr)*scale, color=color, alpha=0.3)
                        try:
                            exp_mean = Yexp[system][obs]['mean'][idf]
                            exp_err = Yexp[system][obs]['err'][idf]
                        except KeyError:
                            pass

                        if system=='Pb-Pb-2760' or system=='Pb-Pb-5020':
                            l1 = axes[row][col].errorbar( x, exp_mean*scale, exp_err, color='black', fmt=expt_marker, markersize='4', elinewidth=1)
                        elif system=='Au-Au-200':
                            l2 = axes[row][col].errorbar( x, exp_mean*scale, exp_err, color='black', fmt=expt_marker, markersize='4', elinewidth=1)

                    except KeyError :
                        pass

                    leg = axes[row][col].legend(fontsize=qm_font_small, borderpad=0, labelspacing=0, handlelength=1, handletextpad=0.2)
                    for legobj in leg.legendHandles:
                        legobj.set_linewidth(2.0)
                        legobj.set_alpha(1.0)

                    if system == 'Au-Au-200':
                        axes[row][col].set_xlim(0, 50)
                    else :
                        axes[row][col].set_xlim(0, 70)

                    if obs_group == 'yields':
                        axes[row][col].set_ylim(1, 1e4)
                    if obs_group == 'mean_pT':
                        axes[row][col].set_ylim(0., 2.5)
                    if obs_group == 'fluct':
                        axes[row][col].set_ylim(0.0, 0.04)
                    if obs_group == 'flows':
                        axes[row][col].set_ylim(0.0, 0.12)
                    if axes[row][col].is_last_row():
                        axes[row][col].set_xlabel('Centrality %', fontsize=qm_font_large)
                else :
                    pass

    plt.tight_layout(True)
    set_tight(fig, rect=[0, 0, 1, .93])
    fig.suptitle("Observables at MAP : " + idf_label[idf], wrap=True)

@plot
def observables_fit_model_calc_compare():
    """
    Compare Model observables calculated at 2 parameter sets with hybrid model, with
    experimental data points.

    """

    #from compare_events import *

    print("Plotting observables calculated at 2 param sets by hybrid model")

    obs_groups = {
                #'yields' : ['dN_dy_pion', 'dN_dy_kaon', 'dN_dy_proton', 'dNch_deta', 'dET_deta'],
                'yields' : ['dN_dy_pion', 'dN_dy_kaon', 'dN_dy_proton', 'dN_dy_d'],
                #'mean_pT' : ['mean_pT_pion', 'mean_pT_kaon', 'mean_pT_proton'],
                'mean_pT' : ['mean_pT_pion', 'mean_pT_kaon', 'mean_pT_proton', 'mean_pT_d'],
                'flows' : ['v22', 'v32', 'v42'],
                #'flows' : ['v32', 'v42'],
                'fluct' : ['pT_fluct']
                }
    obs_group_labels = {
                'yields' : r'$dN_{ch}/d\eta$ , $dN/dy$, $dE_T/d\eta$ [GeV]',
                'mean_pT' : r'$ \langle p_T \rangle$',
                'fluct' : r'$\delta p_T / \langle p_T \rangle$',
                'flows' : r'$v_n \{ 2 \} $'
                }

    colors = ['b', 'g', 'r', 'c', 'm', 'tan', 'gray']
    Ymodel1 = model_data_1
    Ymodel2 = model_data_2
    Yexp = Y_exp_data
    n_systems = len(system_strs)
    nrows = 4
    height_ratios = [1.8, 1.2, 1.5, 1.]
    if system_strs == ['Au-Au-200']:
        nrows = 3
        height_ratios = [1.8, 1.2, 1.5]
        del obs_groups['fluct']

    fig, axes = plt.subplots(nrows=nrows, ncols=n_systems, figsize=(2.5*n_systems,9), squeeze=False,
                            gridspec_kw={'height_ratios': height_ratios}
                            )
    for row, obs_group in enumerate( obs_groups.keys() ):
        for obs, color in zip(obs_groups[obs_group], colors):

            for col, system in enumerate(system_strs):
                if system == 'Pb-Pb-2760' or system == 'Xe-Xe-5440':
                    expt_label='ALICE'
                    expt_marker='v'
                if system == 'Au-Au-200':
                    expt_label='STAR'
                    expt_marker='.'
                emu = dill.load(open('emulator/emulator-' + system + '-idf-' + str(idf) + '.dill', "rb"))

                axes[row][col].tick_params(labelsize=11)

                if obs in active_obs_list[system]:

                    print(obs)

                    if obs_group == 'yields':
                        axes[row][col].set_yscale('log')
                    scale = 1.0
                    if obs == 'dET_deta':
                        scale = 5.
                    if obs == 'dNch_deta':
                        scale = 2.
                    if obs == 'dN_dy_d':
                        scale = 200.
                    try :
                        axes[row][col].set_ylabel(obs_group_labels[obs_group], fontsize=qm_font_large)
                        xbins = np.array(obs_cent_list[system][obs])
                        x = (xbins[:,0]+xbins[:,1])/2.
                        Y1 = Ymodel1[system][obs]['mean'][idf][0]
                        Y2 = Ymodel2[system][obs]['mean'][idf][0]

                        print("Y1 = " + str(Y1))
                        print("Y2 = " + str(Y2))

                        Y1err = Ymodel1[system][obs]['err'][idf][0]
                        Y2err = Ymodel2[system][obs]['err'][idf][0]
                        if scale == 1.0 :
                            label=obs_tex_labels[obs]
                        else :
                            label=obs_tex_labels[obs] + 'x' + str(scale)
                        #axes[row][col].plot(x, Y1*scale, color=color, label=label, lw=2.0)
                        #axes[row][col].plot(x, Y2*scale, 'o', color=color, label=None)
                        axes[row][col].errorbar(x, Y1*scale, Y1err*scale, color=color, label=label, lw=2.0)
                        axes[row][col].errorbar(x, Y2*scale, Y2err*scale, color=color, marker='o', label=None, ls='none', markersize=4)
                        try:
                            exp_mean = Yexp[system][obs]['mean'][idf]
                            exp_err = Yexp[system][obs]['err'][idf]
                        except KeyError:
                            pass

                        if system=='Pb-Pb-2760':
                            l1 = axes[row][col].errorbar( x, exp_mean*scale, exp_err, color='black', fmt=expt_marker, markersize='4', elinewidth=1)
                        #elif system=='Au-Au-200':
                        #    l2 = axes[row][col].errorbar( x, exp_mean*scale, exp_err, color='black', fmt=expt_marker, markersize='4', elinewidth=1)

                    except KeyError :
                        pass

                    leg = axes[row][col].legend(fontsize=qm_font_small, borderpad=0, labelspacing=0, handlelength=1, handletextpad=0.2)
                    for legobj in leg.legendHandles:
                        legobj.set_linewidth(2.0)
                        legobj.set_alpha(1.0)

                    if system == 'Au-Au-200':
                        axes[row][col].set_xlim(0, 50)
                    else :
                        axes[row][col].set_xlim(0, 70)

                    if obs_group == 'yields':
                        axes[row][col].set_ylim(1, 1e4)
                    if obs_group == 'mean_pT':
                        axes[row][col].set_ylim(0., 2.5)
                    if obs_group == 'fluct':
                        axes[row][col].set_ylim(0.0, 0.04)
                    if obs_group == 'flows':
                        axes[row][col].set_ylim(0.0, 0.12)
                        #axes[row][col].set_ylim(0.0, 0.04)
                    if axes[row][col].is_last_row():
                        axes[row][col].set_xlabel('Centrality %', fontsize=qm_font_large)
                else :
                    pass

    if num_systems == 2:
        fig.delaxes(axes[3][1])
    plt.tight_layout(True)
    set_tight(fig, rect=[0, 0, 1, .93])
    #fig.suptitle("Varying Pre-hydodynamic Viscosity", wrap=True)


@plot
def obs_validation():
    _observables(posterior=True)

@plot
def obs_validation_ratio():
    _observables(posterior=True, ratio=True)

@plot
def obs_prior():
    _observables(posterior=False)


@plot
def observables_map():
    """
    Model observables and ratio to experiment at the maximum a posteriori
    (MAP) estimate.

    """
    plots = _observables_plots()

    ylim = {
        'Yields': (2, 1e5),
        'Flow cumulants': (0, .15),
        'Mean $p_T$': (0, 1.7),
        'Mean $p_T$ fluctuations': (0, .045),
    }

    for n, p in enumerate(plots):
        p['ylim'] = ylim[p['title']]
        if p['title'] == 'Flow cumulants':
            move_index = n
            p.update(
                ylabel=r'$v_n\{k\}$',
                subplots=[
                    ('vnk', nk, dict(label='$v_{}\{{{}\}}$'.format(*nk)))
                    for nk in [(2, 2), (2, 4), (3, 2), (4, 2)]
                ],
                legend=True
            )

    plots.insert(1, plots.pop(move_index))

    ncols = int(len(plots)/2)

    fig, axes = plt.subplots(
        nrows=4, ncols=ncols,
        figsize=figsize(1.1, aspect=2/ncols),
        gridspec_kw=dict(
            height_ratios=list(itertools.chain.from_iterable(
                (p.get('height_ratio', 1), .4) for p in plots[::ncols]
            ))
        )
    )

    labels = {}
    handles = dict(expt={}, model={})

    for plot, ax, ratio_ax in zip(plots, axes[::2].flat, axes[1::2].flat):
        for system, (obs, subobs, opts) in itertools.product(
                systems, plot['subplots']
        ):
            color = obs_color(obs, subobs)
            scale = opts.get('scale')

            linestyle, fill_markers = {
                'PbPb2760': ('solid', True),
                'PbPb5020': ('dashed', False),
            }[system]

            x = model.map_data[system][obs][subobs]['x']
            y = model.map_data[system][obs][subobs]['Y']

            if scale is not None:
                y = y*scale

            ax.plot(x, y, color=color, ls=linestyle)
            handles['model'][system] = \
                lines.Line2D([], [], color=offblack, ls=linestyle)

            if 'label' in opts and (obs, subobs) not in labels:
                labels[obs, subobs] = ax.text(
                    x[-1] + 3, y[-1],
                    opts['label'],
                    color=darken(color), ha='left', va='center'
                )

            try:
                dset = expt.data[system][obs][subobs]
            except KeyError:
                continue

            x = dset['x']
            yexp = dset['y']
            yerr = dset['yerr']
            yerrstat = yerr.get('stat')
            yerrsys = yerr.get('sys', yerr.get('sum'))

            if scale is not None:
                yexp = yexp*scale
                if yerrstat is not None:
                    yerrstat = yerrstat*scale
                if yerrsys is not None:
                    yerrsys = yerrsys*scale

            c = '.25'
            handles['expt'][system] = ax.errorbar(
                x, yexp, yerr=yerrstat, fmt='o',
                capsize=0, color=c,
                mec=c, mfc=(c if fill_markers else '.9'),
                mew=((.2 if fill_markers else .5) *
                     plt.rcParams['lines.linewidth']),
                zorder=1000
            )

            ax.fill_between(
                x, yexp - yerrsys, yexp + yerrsys,
                facecolor='.9', zorder=-10,
            )

            ratio_ax.plot(x, y/yexp, color=color, ls=linestyle)

        if plot.get('yscale') == 'log':
            ax.set_yscale('log')
            ax.minorticks_off()
        else:
            auto_ticks(ax, 'y', nbins=4, minor=2)

        for a in [ax, ratio_ax]:
            a.set_xlim(0, 80)
            auto_ticks(a, 'x', nbins=5, minor=2)

        if ratio_ax.is_last_row():
            ratio_ax.set_xlabel('Centrality %')

        ax.set_ylim(plot['ylim'])
        ax.set_ylabel(plot['ylabel'])

        if plot.get('legend'):
            ax.legend(
                [handles[t][s] for t in ['model', 'expt'] for s in systems],
                [fmt.format(parse_system(s)[1]/1000)
                 for fmt in ['', '{} TeV'] for s in systems],
                ncol=2, loc='upper left', bbox_to_anchor=(0, .94),
                columnspacing=0, handletextpad=0
            )

        ax.text(
            .5, 1 if ax.is_first_row() else .97, plot['title'],
            transform=ax.transAxes, ha='center', va='top',
            size=plt.rcParams['axes.labelsize']
        )

        ratio_ax.axhline(
            1,
            linewidth=plt.rcParams['ytick.major.width'], color='0.5',
            zorder=-100
        )
        ratio_ax.axhspan(.9, 1.1, color='0.93', zorder=-200)
        ratio_ax.set_ylim(.85, 1.15)
        ratio_ax.set_ylabel('Ratio')
        ratio_ax.text(
            ratio_ax.get_xlim()[1], .9, '±10%',
            color='.5', zorder=-50,
            ha='right', va='bottom',
            size=plt.rcParams['xtick.labelsize']
        )

    set_tight(fig)


@plot
def observables_expt_only():
    """
    Observables plots of experimental data only.

    """
    plots = _observables_plots()

    ylim = {
        'Yields': (2, 1e5),
        'Flow cumulants': (0, .15),
        'Mean $p_T$': (0, 1.7),
        'Mean $p_T$ fluctuations': (0, .045),
    }

    for n, p in enumerate(plots):
        p['ylim'] = ylim[p['title']]
        if p['title'] == 'Flow cumulants':
            move_index = n
            p.update(legend=True)

    plots.insert(1, plots.pop(move_index))

    ncols = int(len(plots)/2)

    fig, axes = plt.subplots(
        nrows=2, ncols=ncols,
        figsize=figsize(1.1, aspect=1.5/ncols),
        gridspec_kw=dict(
            height_ratios=[p.get('height_ratio', 1) for p in plots[::ncols]]
        )
    )

    for plot, ax in zip(plots, axes.flat):
        labels = {}
        handles = {}

        for system, (obs, subobs, opts) in itertools.product(
                systems, plot['subplots']
        ):
            try:
                dset = expt.data[system][obs][subobs]
            except KeyError:
                continue

            x = dset['x']
            yexp = dset['y']
            yerr = dset['yerr']
            yerrstat = yerr.get('stat')
            yerrsys = yerr.get('sys', yerr.get('sum'))

            scale = opts.get('scale')
            if scale is not None:
                yexp = yexp*scale
                if yerrstat is not None:
                    yerrstat = yerrstat*scale
                if yerrsys is not None:
                    yerrsys = yerrsys*scale

            color = obs_color(obs, subobs)
            fill_markers = {'PbPb2760': True, 'PbPb5020': False}[system]

            c = darken(color, .15)
            h = ax.errorbar(
                x, yexp, yerr=yerrstat, fmt='o',
                capsize=0, color=c,
                mec=c, mfc=(c if fill_markers else '.9'),
                mew=((.2 if fill_markers else .6) *
                     plt.rcParams['lines.linewidth']),
                zorder=1000
            )
            if system not in handles:
                handles[system] = h

            ax.fill_between(
                x, yexp - yerrsys, yexp + yerrsys,
                facecolor='.9', zorder=-10,
            )

            if 'label' in opts and (obs, subobs) not in labels:
                labels[obs, subobs] = ax.text(
                    x[-1] + 3, yexp[-1],
                    opts['label'],
                    color=darken(color), ha='left', va='center'
                )

        if plot.get('yscale') == 'log':
            ax.set_yscale('log')
            ax.minorticks_off()
        else:
            auto_ticks(ax, 'y', nbins=4, minor=2)

        ax.set_xlim(0, 80)
        auto_ticks(ax, 'x', nbins=5, minor=2)

        if ax.is_last_row():
            ax.set_xlabel('Centrality %')

        ax.set_ylim(plot['ylim'])
        ax.set_ylabel(plot['ylabel'])

        if plot.get('legend'):
            ax.legend(
                *zip(*[(handles[s], format_system(s)) for s in systems]),
                loc='upper left', bbox_to_anchor=(0, .94),
                handletextpad=0
            )

        ax.text(
            .5, 1 if ax.is_first_row() else .97, plot['title'],
            transform=ax.transAxes, ha='center', va='top',
            size=plt.rcParams['axes.labelsize']
        )

    set_tight(fig)



def corner(data, axes, ranges, labels, ptype='hist'):
    cmap = plt.get_cmap('Blues')
    cmap.set_bad('white')
    for i, row in enumerate(axes):
        for j, ax in enumerate(row):
            x = data[j]
            y = data[i]
            xlabel = labels[j]
            xlim = ranges[j]
            ylabel = labels[i]
            ylim = ranges[i]
            if i==j:
                H, _, _ = ax.hist(x, bins=20, histtype='step', normed=True)
                ax.set_xlim(*xlim)
                ax.set_ylim(0, H.max())
            if i>j:
                if ptype=='hist':
                    ax.hist2d(x, y, bins=20, cmap=cmap)
                if ptype=='scatter':
                    ax.scatter(x, y, s=.4, color=cb)
                ax.set_xlim(*xlim)
                ax.set_ylim(*ylim)
            if i<j:
                ax.axis('off')
            if ax.is_first_col():
                ax.set_ylabel(ylabel, fontsize=5)
            if ax.is_first_col() and i!=0:
                l = ylim[1]-ylim[0]
                ax.set_yticks([ylim[0]+l*.1, ylim[1]-l*.1])
                ax.set_yticklabels(["{:1.1f} ".format(ylim[0]),
                                    " {:1.1f}".format(ylim[1])], fontsize=7)
            else:
                ax.set_yticks([])
            if ax.is_last_row():
                ax.set_xlabel(xlabel, fontsize=5)
                l = xlim[1]-xlim[0]
                ax.set_xticks([xlim[0]+l*.1, xlim[1]-l*.1])
                ax.set_xticklabels(["{:1.1f} ".format(xlim[0]),
                                    " {:1.1f}".format(xlim[1])], fontsize=7)
            else:
                ax.set_xticks([])
    plt.subplots_adjust(wspace=0., hspace=0.)

@plot
def param_prior():
    design, dmin, dmax, labels = load_design(system=('Pb','Pb',2760), pset='main')
    ranges = np.array([dmin, dmax]).T

    nsamples, ndims = design.values.shape
    fig, axes = plt.subplots(nrows=ndims, ncols=ndims, figsize=(10,10))
    corner(design.values.T, axes, ranges, labels, ptype='scatter')
    set_tight(pad=.0, h_pad=.0, w_pad=.0, rect=(.0, 0, 1, 1))

@plot
def etas_prior():
    design, dmin, dmax, labels = load_design(system=('Pb','Pb',2760), pset='main')

    fig, (ax, axt) = plt.subplots(
        nrows=2, ncols=1,
        figsize=(2.8,3), sharex=True, sharey=False
    )
    T = np.linspace(0.0, 0.5, 400)
    for (Tk, al, ah, ek, bpi) in zip(
				design['eta_over_s_T_kink_in_GeV'],
				design['eta_over_s_low_T_slope_in_GeV'],
				design['eta_over_s_high_T_slope_in_GeV'],
				design['eta_over_s_at_kink'],
                design['shear_relax_time_factor']):
        y = eta_over_s(T, Tk, al, ah, ek)
        ax.plot(T, y, 'b-', alpha=0.3)
        axt.plot(T, T*taupi(T, bpi, Tk, al, ah, ek), 'b-', alpha=0.3)
    ax.set_ylabel(r"$\eta/s$")
    ax.set_xticks([0.0, 0.1, 0.2, 0.3, 0.4, 0.5])


    axt.set_xlabel(r"$T$ [GeV]")
    axt.set_ylabel(r"$ T \tau_\pi$")
    axt.set_xticks([0.0, 0.1, 0.2, 0.3, 0.4, 0.5])
    axt.set_ylim(0,15)
    axt.set_xlim(0.1, 0.45)
    axt.annotate(r'$T\tau_\pi = b_\pi \frac{\eta}{s} \frac{T s}{e+p}$', xy=(.5, .7), xycoords="axes fraction", va='center', ha='center')

    ax.annotate(r'$\frac{\eta}{s} = (\eta/s)_{\mathrm{kink}} + a_{\eta,\mathrm{low}}(T-T_{\eta,\mathrm{kink}}), T<T_{\eta,\mathrm{kink}}$', xy=(.5, .9),
 xycoords="axes fraction", va='center', ha='center', fontsize=7)
    ax.annotate(r'$\frac{\eta}{s} = (\eta/s)_{\mathrm{kink}} + a_{\eta,\mathrm{high}}(T-T_{\eta,\mathrm{kink}}), T>T_{\eta,\mathrm{kink}}$', xy=(.5, .75),
 xycoords="axes fraction", va='center', ha='center', fontsize=7)

    set_tight(fig, rect=[0, 0, 1, 1])

@plot
def freestream_prior():
    design, dmin, dmax, labels = load_design(system=('Pb','Pb',2760), pset='main')

    fig, ax = plt.subplots(
        nrows=1, ncols=1,
        figsize=(2.8,2), sharex=True, sharey=False
    )
    e = np.linspace(.2, 25, 100)
    for (t0, a) in zip(
				design['tau_R'],
				design['alpha'],
           ):
        y = tau_fs(e, t0, a)
        ax.plot(e, y, 'b-', alpha=0.3)
    ax.set_xlabel(r"$e/e_0$")
    ax.set_ylabel(r"$\tau_{\mathrm{fs}}$ [fm/$c$]")
    ax.set_xticks([1,5,10,15,20,25])
    ax.set_ylim(0,4)
    ax.set_xlim(0, 25)

    set_tight(fig, rect=[0, 0, 1, 1])



@plot
def zetas_prior():
    design, dmin, dmax, labels = load_design(system=('Pb','Pb',2760), pset='main')

    fig, (ax, axt) = plt.subplots(
        nrows=2, ncols=1,
        figsize=(2.8,3), sharex=True, sharey=False
    )
    T = np.linspace(0.0, 0.5, 100)
    for (zm, T0, w, asym, bPi, q) in zip(
				design['zeta_over_s_max'],
				design['zeta_over_s_T_peak_in_GeV'],
				design['zeta_over_s_width_in_GeV'],
				design['zeta_over_s_lambda_asymm'],
                design['bulk_relax_time_factor'],
                design['bulk_relax_time_power']):
        y = zeta_over_s(T, zm, T0, w, asym)
        ax.plot(T, y, 'b-', alpha=0.3)
        axt.plot(T, tauPi(T, bPi, zm, T0, w, asym, q)/5.026, 'b-', alpha=0.3)
    ax.set_ylabel(r"$\zeta/s$")
    ax.set_xticks([0.0, 0.1, 0.2, 0.3, 0.4, 0.5])
    ax.set_ylim(0,.5)

    axt.set_xlabel(r"$T$ [GeV]")
    axt.set_ylabel(r"$\tau_\Pi$ [fm/$c$]")
    axt.set_xticks([0.0, 0.1, 0.2, 0.3, 0.4, 0.5])
    axt.set_ylim(0,20)
    axt.set_xlim(0.1, 0.45)
    set_tight(fig, rect=[0, 0, 1, 1])

#@plot
def viscous_posterior(plot_samples = False):

    T = np.linspace(0.135, 0.35, 200)

    color_CI = idf_color[idf]
    if plot_samples:
        color_CI = 'gray'

    if validation:
        v_design, _, _, _ = \
                load_design(system_strs[0], pset='validation')
        tp = v_design.values[validation_pt]
        true_etas = eta_over_s(T, *tp[7:11])
        true_zetas = zeta_over_s(T, *tp[11:15])

    chain = Chain(path=workdir/'mcmc'/'chain-idf-0_LHC_RHIC_PTEMCEE.hdf')
    data = chain.load_wo_reshape()
    if num_systems == 1:
        data = data.reshape(-1, 18)
    elif num_systems == 2:
        data = data.reshape(-1, 19)

    index = np.random.choice(np.arange(data.shape[0]), 50000)

    design, dmin, dmax, labels = load_design(system_str=system_strs[0], pset='main')
    samples = data[index, 1:]
    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(5,3),
                    sharex=False, sharey=False, constrained_layout=True)
    fig.suptitle("Viscosity Posterior : " + idf_label[idf], fontsize=qm_font_large, wrap=True)

    prior_zetas = []

    n_samples_prior = 100000
    for (zm, T0, w, asym) in zip(
                np.random.uniform( min(design['zeta_over_s_max']), max(design['zeta_over_s_max']), n_samples_prior),
                np.random.uniform( min(design['zeta_over_s_T_peak_in_GeV']), max(design['zeta_over_s_T_peak_in_GeV']), n_samples_prior),
                np.random.uniform( min(design['zeta_over_s_width_in_GeV']), max(design['zeta_over_s_width_in_GeV']), n_samples_prior),
                np.random.uniform( min(design['zeta_over_s_lambda_asymm']), max(design['zeta_over_s_lambda_asymm']), n_samples_prior)
                ):
        prior_zetas.append(zeta_over_s(T, zm, T0, w, asym))

    if not plot_samples:
        axes[0].fill_between(T, np.percentile(prior_zetas, 0, axis=0),
                             np.percentile(prior_zetas, 100, axis=0),
                             color='gray', alpha=0.3, label='100% C.I. (Prior)'
                             )
        axes[0].fill_between(T, np.percentile(prior_zetas, 5, axis=0),
                             np.percentile(prior_zetas, 95, axis=0),
                             color='gray', alpha=0.5, label='90% C.I. (Prior)'
                             )

    if num_systems == 1:
        posterior_zetas = [ zeta_over_s(T, *d[10:14]) for d in samples ]
    elif num_systems == 2:
        posterior_zetas = [ zeta_over_s(T, *d[11:15]) for d in samples ]

    if plot_samples:
        for sample, ls in zip(posterior_zetas[:nsamples], ['-', '--', '-.', ':']):
            axes[0].plot(T, sample, '--', alpha=1.0, lw=1.5, zorder=10, ls=ls, color='red')
    if validation:
        axes[0].plot(T, true_zetas, 'k--')


    axes[0].fill_between(T, np.percentile(posterior_zetas, 5, axis=0),
                            np.percentile(posterior_zetas, 95, axis=0),
                            color=color_CI, alpha=0.4,
                            label='90% C.I. (Posterior)')
    axes[0].fill_between(T, np.percentile(posterior_zetas, 20, axis=0),
                            np.percentile(posterior_zetas, 80, axis=0),
                            color=color_CI, alpha=0.7,
                            label='60% C.I (Posterior)')

    ##########################
    prior_etas = []

    for (T_k, alow, ahigh, etas_k) in zip(
                np.random.uniform( min(design['eta_over_s_T_kink_in_GeV']), max(design['eta_over_s_T_kink_in_GeV']), n_samples_prior),
                np.random.uniform( min(design['eta_over_s_low_T_slope_in_GeV']), max(design['eta_over_s_low_T_slope_in_GeV']), n_samples_prior),
                np.random.uniform( min(design['eta_over_s_high_T_slope_in_GeV']), max(design['eta_over_s_high_T_slope_in_GeV']), n_samples_prior),
                np.random.uniform( min(design['eta_over_s_at_kink']), max(design['eta_over_s_at_kink']), n_samples_prior)
                ):
        prior_etas.append(eta_over_s(T, T_k, alow, ahigh, etas_k))

    if not plot_samples:
        axes[1].fill_between(T, np.percentile(prior_etas, 0, axis=0),
                             np.percentile(prior_etas, 100, axis=0),
                             color='gray', alpha=0.3, label='100% C.I. (Prior)'
                             )
        axes[1].fill_between(T, np.percentile(prior_etas, 5, axis=0),
                             np.percentile(prior_etas, 95, axis=0),
                             color='gray', alpha=0.5, label='90% C.I. (Prior)'
                             )

    if num_systems == 1:
        posterior_etas = [ eta_over_s(T, *d[6:10]) for d in samples ]
    elif num_systems == 2:
        posterior_etas = [ eta_over_s(T, *d[7:11]) for d in samples ]

    if plot_samples:
        for sample, ls in zip(posterior_etas[:nsamples], ['-', '--', '-.', ':']):
            axes[1].plot(T, sample, '--', alpha=1.0, lw=1.5, zorder=10, ls=ls, color='red')
    if validation:
        axes[1].plot(T, true_etas, 'k--')


    axes[1].fill_between(T, np.percentile(posterior_etas, 5, axis=0),
                            np.percentile(posterior_etas, 95, axis=0),
                            color=color_CI, alpha=0.4,
                            label='90% Conf. (Posterior)')
    axes[1].fill_between(T, np.percentile(posterior_etas, 20, axis=0),
                            np.percentile(posterior_etas, 80, axis=0),
                            color=color_CI, alpha=0.7,
                            label='60% Conf. (Posterior)')

    axes[0].legend(fontsize = qm_font_small)

    axes[0].set_ylabel(r"$\zeta/s$")
    axes[0].set_xlabel(r"$T$ [GeV]")
    axes[0].set_ylim(0., 0.35)

    axes[1].set_ylabel(r"$\eta/s$")
    axes[1].set_xlabel(r"$T$ [GeV]")

    axes[0].set_xlabel(r"$T$ [GeV]")
    axes[1].set_xlabel(r"$T$ [GeV]")

    T_ticks = [0.15, 0.2, 0.25, 0.3, 0.35]
    axes[0].set_xticks(T_ticks)
    axes[1].set_xticks(T_ticks)

    plt.tight_layout(True)
    set_tight(fig, rect=[0, 0, 0.98, .9])

@plot
def bayes_model_avg_viscous_posterior_1():
    """ Plot the viscosity posterior using a Bayesian Model Average
    of the visc. correction models.
    Beforehand one needs the posteriors of each invididual model,
    as well as their mutual Bayes factors calculated. """

    colors = matplotlib.cm.Oranges(np.linspace( 0.4, 1., 4 ) ) #this should match the cmap in 'bayes_model_avg_viscous_posterior_2()'
    color_CI = colors[0]

    thin_factor=5
    T = np.linspace(0.135, 0.35, 200)

    #chains of each model
    chain_a = Chain(path=workdir/'mcmc'/'chain-idf-0_LHC_RHIC_PTEMCEE.hdf') #Grad
    chain_b = Chain(path=workdir/'mcmc'/'chain-idf-1_LHC_RHIC_PTEMCEE.hdf') #CE
    chain_c = Chain(path=workdir/'mcmc'/'chain-idf-3_LHC_RHIC_PTEMCEE.hdf') #PTB

    data_a = chain_a.load_wo_reshape(thin=thin_factor)
    data_b = chain_b.load_wo_reshape(thin=thin_factor)
    data_c = chain_c.load_wo_reshape(thin=thin_factor)

    data_a = data_a.reshape(-1, 19)
    data_b = data_b.reshape(-1, 19)
    data_c = data_c.reshape(-1, 19)

    #get samples for the individual posteriors
    n_samples = 50000
    index1 = np.random.choice(np.arange(data_a.shape[0]), n_samples)
    index2 = np.random.choice(np.arange(data_b.shape[0]), n_samples)
    index3 = np.random.choice(np.arange(data_c.shape[0]), n_samples)

    samples1 = data_a[index1, 1:]
    samples2 = data_b[index2, 1:]
    samples3 = data_c[index3, 1:]

    #Bayes factor of each model w.r.t. model a
    #here a = Grad, b = CE, c = PTB
    #NOTE THE PROPAGATION OF ERRORS ON THE LN Z ESTIMATE FROM PTSAMPLER
    #First factor of sigmas of observation, where sigma is numerical uncertainty
    #Then compute left-sided p-value, and then the odds
    B_aa = 1.
    B_ba = 0.0002
    B_ca = 0.38

    #define the relative weights
    norm = B_aa + B_ba + B_ca
    r_a = B_aa / norm
    r_b = B_ba / norm
    r_c = B_ca / norm

    n_samples = data_a.shape[0]

    #get frequency of model a, b, c...
    n_samples_a = int( np.floor(n_samples * r_a) )
    n_samples_b = int( np.floor(n_samples * r_b) )
    n_samples_c = int( np.floor(n_samples * r_c) )

    #now draw these samples from each distribution
    index_a = np.random.choice(np.arange(data_a.shape[0]), n_samples_a)
    index_b = np.random.choice(np.arange(data_b.shape[0]), n_samples_b)
    index_c = np.random.choice(np.arange(data_c.shape[0]), n_samples_c)

    design, dmin, dmax, labels = load_design(system_str=system_strs[0], pset='main')

    samples_a = data_a[index_a, 1:]
    samples_b = data_b[index_b, 1:]
    samples_c = data_c[index_c, 1:]

    samples_mix = np.append(samples_a, samples_b, axis=0)
    samples_mix = np.append(samples_mix, samples_c, axis=0)

    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(6,2.5),
                    sharex=True, sharey=False, constrained_layout=True)

    np.save('mcmc/bma_grad_ce_ptb_chain', samples_mix)

    ##########################
    #BULK VISCOSITY
    prior_zetas = []

    n_samples_prior = 100000
    for (zm, T0, w, asym) in zip(
                np.random.uniform( min(design['zeta_over_s_max']), max(design['zeta_over_s_max']), n_samples_prior),
                np.random.uniform( min(design['zeta_over_s_T_peak_in_GeV']), max(design['zeta_over_s_T_peak_in_GeV']), n_samples_prior),
                np.random.uniform( min(design['zeta_over_s_width_in_GeV']), max(design['zeta_over_s_width_in_GeV']), n_samples_prior),
                np.random.uniform( min(design['zeta_over_s_lambda_asymm']), max(design['zeta_over_s_lambda_asymm']), n_samples_prior)
                ):
        prior_zetas.append(zeta_over_s(T, zm, T0, w, asym))

    axes[0].fill_between(T, np.percentile(prior_zetas, 5, axis=0),
                            np.percentile(prior_zetas, 95, axis=0),
                            color='gray', alpha=0.3, label='Prior')

    posterior_zetas_1 = [ zeta_over_s(T, *d[11:15]) for d in samples1 ]
    posterior_zetas_2 = [ zeta_over_s(T, *d[11:15]) for d in samples2 ]
    posterior_zetas_3 = [ zeta_over_s(T, *d[11:15]) for d in samples3 ]

    posterior_zetas_mix = [ zeta_over_s(T, *d[11:15]) for d in samples_mix ]

    axes[0].fill_between(T, np.percentile(posterior_zetas_mix, 5, axis=0),
                            np.percentile(posterior_zetas_mix, 95, axis=0),
                            color=color_CI, label='BMA')

    axes[0].fill_between(T, np.percentile(posterior_zetas_1, 5, axis=0),
                            np.percentile(posterior_zetas_1, 95, axis=0),
                            edgecolor='blue', facecolor='None', ls='-', lw=2, label=idf_label_short[0])
    axes[0].fill_between(T, np.percentile(posterior_zetas_2, 5, axis=0),
                            np.percentile(posterior_zetas_2, 95, axis=0),
                            edgecolor='red', facecolor='None', ls='--', lw=2, label=idf_label_short[1])
    axes[0].fill_between(T, np.percentile(posterior_zetas_3, 5, axis=0),
                            np.percentile(posterior_zetas_3, 95, axis=0),
                            edgecolor='green', facecolor='None', ls=':', lw=2, label=idf_label_short[3])

    #axes[0].legend(fontsize = qm_font_small, loc='upper left')
    ##########################
    #SHEAR VISCOSITY
    prior_etas = []

    for (T_k, alow, ahigh, etas_k) in zip(
                np.random.uniform( min(design['eta_over_s_T_kink_in_GeV']), max(design['eta_over_s_T_kink_in_GeV']), n_samples_prior),
                np.random.uniform( min(design['eta_over_s_low_T_slope_in_GeV']), max(design['eta_over_s_low_T_slope_in_GeV']), n_samples_prior),
                np.random.uniform( min(design['eta_over_s_high_T_slope_in_GeV']), max(design['eta_over_s_high_T_slope_in_GeV']), n_samples_prior),
                np.random.uniform( min(design['eta_over_s_at_kink']), max(design['eta_over_s_at_kink']), n_samples_prior)
                ):
        prior_etas.append(eta_over_s(T, T_k, alow, ahigh, etas_k))


    axes[1].fill_between(T, np.percentile(prior_etas, 5, axis=0),
                            np.percentile(prior_etas, 95, axis=0),
                            color='gray', alpha=0.3)

    posterior_etas_1 = [ eta_over_s(T, *d[7:11]) for d in samples1 ]
    posterior_etas_2 = [ eta_over_s(T, *d[7:11]) for d in samples2 ]
    posterior_etas_3 = [ eta_over_s(T, *d[7:11]) for d in samples3 ]

    posterior_etas_mix = [ eta_over_s(T, *d[7:11]) for d in samples_mix ]

    axes[1].fill_between(T, np.percentile(posterior_etas_mix, 5, axis=0),
                            np.percentile(posterior_etas_mix, 95, axis=0),
                            color=color_CI, label='BMA' )

    axes[1].fill_between(T, np.percentile(posterior_etas_1, 5, axis=0),
                            np.percentile(posterior_etas_1, 95, axis=0),
                            edgecolor='blue', facecolor='None', ls='-', lw=2, label=idf_label_short[0])
    axes[1].fill_between(T, np.percentile(posterior_etas_2, 5, axis=0),
                            np.percentile(posterior_etas_2, 95, axis=0),
                            edgecolor='red', facecolor='None', ls='--', lw=2, label=idf_label_short[1])
    axes[1].fill_between(T, np.percentile(posterior_etas_3, 5, axis=0),
                            np.percentile(posterior_etas_3, 95, axis=0),
                            edgecolor='green', facecolor='None', ls=':', lw=2, label=idf_label_short[3])

    axes[1].legend(fontsize=7, loc='upper center', borderpad=0, labelspacing=0.3, handletextpad=0.3)

    axes[0].set_ylabel(r"$\zeta/s$")
    axes[1].set_ylabel(r"$\eta/s$")

    axes[0].set_xlabel(r"$T$ [GeV]")
    axes[1].set_xlabel(r"$T$ [GeV]")

    axes[0].set_xlim([0.135, 0.35])
    axes[1].set_xlim([0.135, 0.35])

    T_ticks = [0.15, 0.2, 0.25, 0.3, 0.35]
    axes[0].set_xticks(T_ticks)
    axes[1].set_xticks(T_ticks)

    plt.tight_layout(True)

@plot
def bayes_model_avg_viscous_posterior_2():
    """ Plot the viscosity posterior using a Bayesian Model Average
    of the visc. correction models.
    Beforehand one needs the posteriors of each invididual model,
    as well as their mutual Bayes factors calculated. """

    colors = matplotlib.cm.Oranges(np.linspace( 0.4, 1., 4 ) )

    thin_factor = 5

    T = np.linspace(0.135, 0.35, 200)

    #chains of each model
    chain_a = Chain(path=workdir/'mcmc'/'chain-idf-0_LHC_RHIC_PTEMCEE.hdf') #Grad
    chain_b = Chain(path=workdir/'mcmc'/'chain-idf-1_LHC_RHIC_PTEMCEE.hdf') #CE
    chain_c = Chain(path=workdir/'mcmc'/'chain-idf-3_LHC_RHIC_PTEMCEE.hdf') #PTB

    data_a = chain_a.load_wo_reshape(thin=thin_factor)
    data_b = chain_b.load_wo_reshape(thin=thin_factor)
    data_c = chain_c.load_wo_reshape(thin=thin_factor)

    data_a = data_a.reshape(-1, 19)
    data_b = data_b.reshape(-1, 19)
    data_c = data_c.reshape(-1, 19)

    #get samples for the individual posteriors
    n_samples = 50000
    index1 = np.random.choice(np.arange(data_a.shape[0]), n_samples)
    index2 = np.random.choice(np.arange(data_b.shape[0]), n_samples)
    index3 = np.random.choice(np.arange(data_c.shape[0]), n_samples)

    samples1 = data_a[index1, 1:]
    samples2 = data_b[index2, 1:]
    samples3 = data_c[index3, 1:]

    #Bayes factor of each model w.r.t. model a
    #here a = Grad, b = CE, c = PTB
    #NOTE THE PROPAGATION OF ERRORS ON THE LN Z ESTIMATE FROM PTSAMPLER
    #First factor of sigmas of observation, where sigma is numerical uncertainty
    #Then compute left-sided p-value, and then the odds
    B_aa = 1.
    B_ba = 0.0002
    B_ca = 0.38

    #define the relative weights
    norm = B_aa + B_ba + B_ca
    r_a = B_aa / norm
    r_b = B_ba / norm
    r_c = B_ca / norm

    n_samples = data_a.shape[0]

    #get frequency of model a, b, c...
    n_samples_a = int( np.floor(n_samples * r_a) )
    n_samples_b = int( np.floor(n_samples * r_b) )
    n_samples_c = int( np.floor(n_samples * r_c) )

    #now draw these samples from each distribution
    index_a = np.random.choice(np.arange(data_a.shape[0]), n_samples_a)
    index_b = np.random.choice(np.arange(data_b.shape[0]), n_samples_b)
    index_c = np.random.choice(np.arange(data_c.shape[0]), n_samples_c)

    design, dmin, dmax, labels = load_design(system_str=system_strs[0], pset='main')

    samples_a = data_a[index_a, 1:]
    samples_b = data_b[index_b, 1:]
    samples_c = data_c[index_c, 1:]

    samples_mix = np.append(samples_a, samples_b, axis=0)
    samples_mix = np.append(samples_mix, samples_c, axis=0)

    height_ratios = [1., .3]
    fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(6,3.5),
                    sharex=True, sharey=False, constrained_layout=True, gridspec_kw={'height_ratios': height_ratios})


    ##########################
    #BULK VISCOSITY
    prior_zetas = []

    n_samples_prior = 100000
    for (zm, T0, w, asym) in zip(
                np.random.uniform( min(design['zeta_over_s_max']), max(design['zeta_over_s_max']), n_samples_prior),
                np.random.uniform( min(design['zeta_over_s_T_peak_in_GeV']), max(design['zeta_over_s_T_peak_in_GeV']), n_samples_prior),
                np.random.uniform( min(design['zeta_over_s_width_in_GeV']), max(design['zeta_over_s_width_in_GeV']), n_samples_prior),
                np.random.uniform( min(design['zeta_over_s_lambda_asymm']), max(design['zeta_over_s_lambda_asymm']), n_samples_prior)
                ):
        prior_zetas.append( zeta_over_s(T, zm, T0, w, asym) )
    prior_zetas = np.array(prior_zetas)

    axes[0, 0].fill_between(T, np.percentile(prior_zetas, 5, axis=0),
                            np.percentile(prior_zetas, 95, axis=0),
                            edgecolor='gray', facecolor='None', lw=2)

    posterior_zetas_1 = [ zeta_over_s(T, *d[11:15]) for d in samples1 ]
    posterior_zetas_2 = [ zeta_over_s(T, *d[11:15]) for d in samples2 ]
    posterior_zetas_3 = [ zeta_over_s(T, *d[11:15]) for d in samples3 ]

    posterior_zetas_mix = [ zeta_over_s(T, *d[11:15]) for d in samples_mix ]

    posterior_zetas_mix = np.array(posterior_zetas_mix)

    #calculate the information gain between the posterior and prior as func. of T
    nbins = 40
    range_zeta_bins = [0., 0.5]
    info_gain_zeta = []
    fig = matplotlib.figure.Figure()
    ax = matplotlib.axes.Axes(fig, (0,0,0,0))
    for iT, T0 in enumerate(T):
        H0, bins, _ = ax.hist(prior_zetas[:, iT], bins=nbins, histtype='step', range=range_zeta_bins, density=True)
        H1, _, _ = ax.hist(posterior_zetas_mix[:, iT], bins=nbins, histtype='step', range=range_zeta_bins, density=True)
        bin_width = bins[1] - bins[0]
        info = calculate_information_gain(H0, H1, bin_width)
        info_gain_zeta.append(info)
    del ax, fig

    axes[1, 0].plot(T, info_gain_zeta, lw=2)
    axes[1, 0].set_ylabel(r'$D_{\rm KL}(\zeta/s)$')


    axes[0, 0].fill_between(T, np.percentile(posterior_zetas_mix, 5, axis=0),
                            np.percentile(posterior_zetas_mix, 95, axis=0),
                            color=colors[0], lw=2)
    #axes[0].fill_between(T, np.percentile(posterior_zetas_mix, 15, axis=0),
    #                        np.percentile(posterior_zetas_mix, 85, axis=0),
    #                        color=colors[1])
    axes[0, 0].fill_between(T, np.percentile(posterior_zetas_mix, 20, axis=0),
                            np.percentile(posterior_zetas_mix, 80, axis=0),
                            color=colors[1], lw=2)

    #axes[0].fill_between(T, np.percentile(posterior_zetas_mix, 25, axis=0),
    #                        np.percentile(posterior_zetas_mix, 75, axis=0),
    #                        color=colors[2])
    #axes[0].fill_between(T, np.percentile(posterior_zetas_mix, 35, axis=0),
    #                        np.percentile(posterior_zetas_mix, 65, axis=0),
    #                        color=colors[3])

    #axes[0, 0].fill_between(T, np.percentile(prior_zetas, 20, axis=0),
    #                        np.percentile(prior_zetas, 80, axis=0),
    #                        edgecolor='gray', facecolor='gray', ls='None', lw=2, zorder=-1)

    axes[0, 0].fill_between(T, np.percentile(prior_zetas, 20, axis=0),
                            np.percentile(prior_zetas, 80, axis=0),
                            edgecolor='gray', facecolor='None', ls='--', lw=2, zorder=2)


    ##########################
    #SHEAR VISCOSITY
    prior_etas = []

    for (T_k, alow, ahigh, etas_k) in zip(
                np.random.uniform( min(design['eta_over_s_T_kink_in_GeV']), max(design['eta_over_s_T_kink_in_GeV']), n_samples_prior),
                np.random.uniform( min(design['eta_over_s_low_T_slope_in_GeV']), max(design['eta_over_s_low_T_slope_in_GeV']), n_samples_prior),
                np.random.uniform( min(design['eta_over_s_high_T_slope_in_GeV']), max(design['eta_over_s_high_T_slope_in_GeV']), n_samples_prior),
                np.random.uniform( min(design['eta_over_s_at_kink']), max(design['eta_over_s_at_kink']), n_samples_prior)
                ):
        prior_etas.append(eta_over_s(T, T_k, alow, ahigh, etas_k))
    prior_etas = np.array(prior_etas)

    axes[0, 1].fill_between(T, np.percentile(prior_etas, 5, axis=0),
                            np.percentile(prior_etas, 95, axis=0),
                            edgecolor='gray', facecolor='None', lw=2, label='$90$% CI Prior')

    posterior_etas_1 = [ eta_over_s(T, *d[7:11]) for d in samples1 ]
    posterior_etas_2 = [ eta_over_s(T, *d[7:11]) for d in samples2 ]
    posterior_etas_3 = [ eta_over_s(T, *d[7:11]) for d in samples3 ]

    posterior_etas_mix = [ eta_over_s(T, *d[7:11]) for d in samples_mix ]
    posterior_etas_mix = np.array(posterior_etas_mix)

    #calculate the information gain between the posterior and prior as func. of T
    nbins = 40
    range_eta_bins = [0., 0.7]
    info_gain_eta = []
    fig = matplotlib.figure.Figure()
    ax = matplotlib.axes.Axes(fig, (0,0,0,0))
    for iT, T0 in enumerate(T):
        H0, bins, _ = ax.hist(prior_etas[:, iT], bins=nbins, histtype='step', range=range_eta_bins, density=True)
        H1, _, _ = ax.hist(posterior_etas_mix[:, iT], bins=nbins, histtype='step', range=range_eta_bins, density=True)
        bin_width = bins[1] - bins[0]
        info = calculate_information_gain(H0, H1, bin_width)
        info_gain_eta.append(info)
    del ax, fig

    axes[1, 1].plot(T, info_gain_eta, lw=2)
    axes[1, 1].set_ylabel(r'$D_{\rm KL}(\eta/s)$')

    axes[0, 1].fill_between(T, np.percentile(posterior_etas_mix, 5, axis=0),
                            np.percentile(posterior_etas_mix, 95, axis=0),
                            color=colors[0], label=r'$90$% CI Posterior', lw=2)
    #axes[1].fill_between(T, np.percentile(posterior_etas_mix, 15, axis=0),
    #                        np.percentile(posterior_etas_mix, 85, axis=0),
    #                        color=colors[1], label=r'$70$%')
    axes[0, 1].fill_between(T, np.percentile(posterior_etas_mix, 20, axis=0),
                            np.percentile(posterior_etas_mix, 80, axis=0),
                            color=colors[1], label=r'$60$% CI Posterior', lw=2)
    #axes[1].fill_between(T, np.percentile(posterior_etas_mix, 25, axis=0),
    #                        np.percentile(posterior_etas_mix, 75, axis=0),
    #                        color=colors[2], label=r'$50$%')
    #axes[1].fill_between(T, np.percentile(posterior_etas_mix, 35, axis=0),
    #                        np.percentile(posterior_etas_mix, 65, axis=0),
    #                        color=colors[3], label=r'$30$%')

    #axes[0, 1].fill_between(T, np.percentile(prior_etas, 20, axis=0),
    #                        np.percentile(prior_etas, 80, axis=0),
    #                        edgecolor='gray', facecolor='Gray', ls='None', lw=2, label='$60$% CI Prior', zorder=-1)

    axes[0, 1].fill_between(T, np.percentile(prior_etas, 20, axis=0),
                            np.percentile(prior_etas, 80, axis=0),
                            edgecolor='gray', facecolor='None', ls='--', lw=2, zorder=2,
                            label='$60$% CI Prior')

    axes[0, 1].legend(fontsize=7, loc='upper center')

    axes[0, 0].set_ylabel(r"$\zeta/s$")
    axes[0, 1].set_ylabel(r"$\eta/s$")

    axes[1, 0].set_xlabel(r"$T$ [GeV]")
    axes[1, 1].set_xlabel(r"$T$ [GeV]")

    axes[1, 0].set_xlim([0.135, 0.35])
    axes[1, 1].set_xlim([0.135, 0.35])

    T_ticks = [0.15, 0.2, 0.25, 0.3, 0.35]
    axes[1, 0].set_xticks(T_ticks)
    axes[1, 1].set_xticks(T_ticks)

    KL_ticks = [0., 0.5, 1.0, 1.5]
    axes[1, 0].set_ylim(0., 1.5)
    axes[1, 0].set_yticks(KL_ticks)

    axes[1, 1].set_ylim(0., 1.5)
    axes[1, 1].set_yticks(KL_ticks)

    zeta_ticks = [0., 0.05, .1, 0.15, 0.2]
    axes[0, 0].set_yticks(zeta_ticks)
    eta_ticks = [0., 0.1, .2, 0.3, 0.4]
    axes[0, 1].set_yticks(eta_ticks)

    plt.tight_layout(True)
    plt.subplots_adjust(wspace=0.3, hspace=0.1)

@plot
def bayes_model_avg_viscous_posterior_density():
    """ Plot the viscosity posterior using a Bayesian Model Average
    of the visc. correction models.
    Beforehand one needs the posteriors of each invididual model,
    as well as their mutual Bayes factors calculated.
    This plots the density not just credible intervals."""

    color_CI = 'black'
    cmap = plt.get_cmap('Blues')
    T_low = 0.135
    T_high = 0.35

    T = np.linspace(T_low, T_high, 200)

    #chains of each model
    chain_a = Chain(path=workdir/'mcmc'/'chain-idf-0_LHC_RHIC_PTEMCEE.hdf') #Grad
    chain_b = Chain(path=workdir/'mcmc'/'chain-idf-1_LHC_RHIC_PTEMCEE.hdf') #CE
    chain_c = Chain(path=workdir/'mcmc'/'chain-idf-3_LHC_RHIC_PTEMCEE.hdf') #PTB

    data_a = chain_a.load_wo_reshape(thin=5)
    data_b = chain_b.load_wo_reshape(thin=5)
    data_c = chain_c.load_wo_reshape(thin=5)

    data_a = data_a.reshape(-1, 19)
    data_b = data_b.reshape(-1, 19)
    data_c = data_c.reshape(-1, 19)

    #bayes factor of each model w.r.t. model a
    #here a = Grad, b = CE, c = PTB
    B_aa = 1.
    B_ba = 0.0002
    B_ca = 0.38

    #define the relative weights
    norm = B_aa + B_ba + B_ca
    r_a = B_aa / norm
    r_b = B_ba / norm
    r_c = B_ca / norm

    n_samples = data_a.shape[0]

    #get frequency of model a, b, c...
    n_samples_a = int( np.floor(n_samples * r_a) )
    n_samples_b = int( np.floor(n_samples * r_b) )
    n_samples_c = int( np.floor(n_samples * r_c) )

    #now draw these samples from each distribution
    index_a = np.random.choice(np.arange(data_a.shape[0]), n_samples_a)
    index_b = np.random.choice(np.arange(data_b.shape[0]), n_samples_b)
    index_c = np.random.choice(np.arange(data_c.shape[0]), n_samples_c)

    design, dmin, dmax, labels = load_design(system_str=system_strs[0], pset='main')

    samples_a = data_a[index_a, 1:]
    samples_b = data_b[index_b, 1:]
    samples_c = data_c[index_c, 1:]

    samples_mix = np.append(samples_a, samples_b, axis=0)
    samples_mix = np.append(samples_mix, samples_c, axis=0)

    #now sample T uniformly
    n_samples_T = samples_mix.shape[0]
    T_samples = np.random.uniform(T_low, T_high, n_samples_T)
    #get samples of zeta/s and eta/s
    zeta_over_s_samples  = [ zeta_over_s(T_val, *sample[11:15]) for T_val, sample in zip(T_samples, samples_mix) ]

    #sample the prior uniformly
    zeta_mag_samples = np.random.uniform(0.01, .2, n_samples_T)
    zeta_T_p_samples = np.random.uniform(0.12, .3, n_samples_T)
    zeta_w_samples = np.random.uniform(0.025, .15, n_samples_T)
    zeta_l_samples = np.random.uniform(-.8, .8, n_samples_T)
    #get the prior values of zeta
    zeta_over_s_samples_prior = [ zeta_over_s(T_val, mag, T_p, w, l) \
                                        for T_val, mag, T_p, w, l
                                    in zip(T_samples, zeta_mag_samples, zeta_T_p_samples, zeta_w_samples, zeta_l_samples) ]


    #try using plotly to make a density plot
    fig = make_subplots(rows=1, cols=2)
    #prior
    fig.add_trace( go.Histogram2dContour(x=T_samples, y=zeta_over_s_samples_prior),
                                        row=1, col=1 )
    #posterior
    fig.add_trace( go.Histogram2dContour(x=T_samples, y=zeta_over_s_samples),
                                        row=1, col=2 )

    fig.update_traces(contours_coloring="fill", line_smoothing=1.)
    fig.show()

@plot
def viscous_prior():
    """
    Credible interval priors of eta/s(T) and zeta/s(T).
    """

    T = np.linspace(0.1, 0.45, 100)

    design, dmin, dmax, labels = load_design(system_str=system_strs[0], pset='main')
    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(5,3),
                    sharex=False, sharey=False, constrained_layout=True)
    fig.suptitle("Viscosity Prior", fontsize=qm_font_large, wrap=True)

    prior_zetas = []

    n_samples_prior = 100000
    for (zm, T0, w, asym) in zip(
                np.random.uniform( min(design['zeta_over_s_max']), max(design['zeta_over_s_max']), n_samples_prior),
                np.random.uniform( min(design['zeta_over_s_T_peak_in_GeV']), max(design['zeta_over_s_T_peak_in_GeV']), n_samples_prior),
                np.random.uniform( min(design['zeta_over_s_width_in_GeV']), max(design['zeta_over_s_width_in_GeV']), n_samples_prior),
                np.random.uniform( min(design['zeta_over_s_lambda_asymm']), max(design['zeta_over_s_lambda_asymm']), n_samples_prior)
                ):
        prior_zetas.append(zeta_over_s(T, zm, T0, w, asym))


    axes[0].fill_between(T, np.percentile(prior_zetas, 0, axis=0),
                         np.percentile(prior_zetas, 100, axis=0),
                         color='gray', alpha=0.3, label='100% C.I. (Prior)'
                         )
    axes[0].fill_between(T, np.percentile(prior_zetas, 5, axis=0),
                         np.percentile(prior_zetas, 95, axis=0),
                         color='gray', alpha=0.6, label='90% C.I. (Prior)'
                         )
    axes[0].fill_between(T, np.percentile(prior_zetas, 20, axis=0),
                         np.percentile(prior_zetas, 80, axis=0),
                         color='gray', alpha=0.8, label='60% C.I. (Prior)'
                         )

    ##########################
    prior_etas = []
    for (T_k, alow, ahigh, etas_k) in zip(
                np.random.uniform( min(design['eta_over_s_T_kink_in_GeV']), max(design['eta_over_s_T_kink_in_GeV']), n_samples_prior),
                np.random.uniform( min(design['eta_over_s_low_T_slope_in_GeV']), max(design['eta_over_s_low_T_slope_in_GeV']), n_samples_prior),
                np.random.uniform( min(design['eta_over_s_high_T_slope_in_GeV']), max(design['eta_over_s_high_T_slope_in_GeV']), n_samples_prior),
                np.random.uniform( min(design['eta_over_s_at_kink']), max(design['eta_over_s_at_kink']), n_samples_prior)
                ):
        prior_etas.append(eta_over_s(T, T_k, alow, ahigh, etas_k))

    axes[1].fill_between(T, np.percentile(prior_etas, 0, axis=0),
                             np.percentile(prior_etas, 100, axis=0),
                             color='gray', alpha=0.3, label='100% C.I. (Prior)'
                             )
    axes[1].fill_between(T, np.percentile(prior_etas, 5, axis=0),
                             np.percentile(prior_etas, 95, axis=0),
                             color='gray', alpha=0.5, label='90% C.I. (Prior)'
                             )
    axes[1].fill_between(T, np.percentile(prior_etas, 20, axis=0),
                             np.percentile(prior_etas, 80, axis=0),
                             color='gray', alpha=0.7, label='60% C.I. (Prior)'
                             )

    axes[0].legend(fontsize = qm_font_small)

    axes[0].set_ylabel(r"$\zeta/s$")
    axes[0].set_xlabel(r"$T$ [GeV]")
    axes[0].set_ylim(0., 0.35)

    axes[1].set_ylabel(r"$\eta/s$")
    axes[1].set_xlabel(r"$T$ [GeV]")

    axes[0].set_xlabel(r"$T$ [GeV]")
    axes[1].set_xlabel(r"$T$ [GeV]")

    plt.tight_layout(True)
    set_tight(fig, rect=[0, 0, 1, .9])

@plot
def viscous_posterior_overlay():
    """
    Credible interval posterior of eta/s(T) and zeta/s(T), overlaying the 3 df models.
    """

    T = np.linspace(0.15, 0.35, 100)

    color_CI = idf_color[idf]

    chain1 = Chain(path=workdir/'mcmc'/'chain-idf-0_LHC_RHIC_PTEMCEE.hdf')
    data1 = chain1.load_wo_reshape(thin=10)
    data1 = data1.reshape(-1, 19)

    chain2 = Chain(path=workdir/'mcmc'/'chain-idf-1_LHC_RHIC_PTEMCEE.hdf')
    data2 = chain2.load_wo_reshape(thin=10)
    data2 = data2.reshape(-1, 19)

    chain3 = Chain(path=workdir/'mcmc'/'chain-idf-3_LHC_RHIC_PTEMCEE.hdf')
    data3 = chain3.load_wo_reshape(thin=10)
    data3 = data3.reshape(-1, 19)

    index1 = np.random.choice(np.arange(data1.shape[0]), 50000)
    index2 = np.random.choice(np.arange(data2.shape[0]), 50000)
    index3 = np.random.choice(np.arange(data3.shape[0]), 50000)

    #design, dmin, dmax, labels = load_design(system_str=system_strs[0], pset='main')
    samples1 = data1[index1, 1:]
    samples2 = data2[index2, 1:]
    samples3 = data3[index3, 1:]

    #the prior density
    design, dmin, dmax, labels = load_design(system_str=system_strs[0], pset='main')

    n_samples_prior = 100000
    prior_zetas = []
    for (zm, T0, w, asym) in zip(
                np.random.uniform( min(design['zeta_over_s_max']), max(design['zeta_over_s_max']), n_samples_prior),
                np.random.uniform( min(design['zeta_over_s_T_peak_in_GeV']), max(design['zeta_over_s_T_peak_in_GeV']), n_samples_prior),
                np.random.uniform( min(design['zeta_over_s_width_in_GeV']), max(design['zeta_over_s_width_in_GeV']), n_samples_prior),
                np.random.uniform( min(design['zeta_over_s_lambda_asymm']), max(design['zeta_over_s_lambda_asymm']), n_samples_prior)
                ):
        prior_zetas.append(zeta_over_s(T, zm, T0, w, asym))

    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(5.5,3.5),
                    sharex=False, sharey=False, constrained_layout=True)
    fig.suptitle(r" Viscosity Posterior", fontsize=qm_font_large, wrap=True)

    posterior_zetas_1 = [ zeta_over_s(T, *d[11:15]) for d in samples1 ]
    posterior_zetas_2 = [ zeta_over_s(T, *d[11:15]) for d in samples2 ]
    posterior_zetas_3 = [ zeta_over_s(T, *d[11:15]) for d in samples3 ]

    axes[0].fill_between(T, np.percentile(prior_zetas, 5, axis=0),
                         np.percentile(prior_zetas, 95, axis=0),
                         color='gray', alpha=0.4, label='90% C.I. (Prior)'
                         )

    axes[0].fill_between(T, np.percentile(posterior_zetas_1, 5, axis=0),
                            np.percentile(posterior_zetas_1, 95, axis=0),
                            edgecolor='blue', lw=2.0, facecolor='None', ls='-',
                            label=r'90% C.I. ' + idf_label_short[0])

    axes[0].fill_between(T, np.percentile(posterior_zetas_2, 5, axis=0),
                            np.percentile(posterior_zetas_2, 95, axis=0),
                            edgecolor='red', lw=2.0, facecolor='None', ls='--',
                            label=r'90% C.I. ' + idf_label_short[1])

    axes[0].fill_between(T, np.percentile(posterior_zetas_3, 5, axis=0),
                            np.percentile(posterior_zetas_3, 95, axis=0),
                            edgecolor='green', lw=2.0, facecolor='None', ls=':',
                            label=r'90% C.I. ' + idf_label_short[3])


    axes[0].legend(loc=(.05, .75), fontsize=qm_font_small)
    ##########################

    posterior_etas_1 = [ eta_over_s(T, *d[7:11]) for d in samples1 ]
    posterior_etas_2 = [ eta_over_s(T, *d[7:11]) for d in samples2 ]
    posterior_etas_3 = [ eta_over_s(T, *d[7:11]) for d in samples3 ]

    prior_etas = []
    for (T_k, alow, ahigh, etas_k) in zip(
                np.random.uniform( min(design['eta_over_s_T_kink_in_GeV']), max(design['eta_over_s_T_kink_in_GeV']), n_samples_prior),
                np.random.uniform( min(design['eta_over_s_low_T_slope_in_GeV']), max(design['eta_over_s_low_T_slope_in_GeV']), n_samples_prior),
                np.random.uniform( min(design['eta_over_s_high_T_slope_in_GeV']), max(design['eta_over_s_high_T_slope_in_GeV']), n_samples_prior),
                np.random.uniform( min(design['eta_over_s_at_kink']), max(design['eta_over_s_at_kink']), n_samples_prior)
                ):
        prior_etas.append(eta_over_s(T, T_k, alow, ahigh, etas_k))

    axes[1].fill_between(T, np.percentile(prior_etas, 5, axis=0),
                             np.percentile(prior_etas, 95, axis=0),
                             color='gray', alpha=0.4, label='90% C.I. (Prior)'
                             )

    axes[1].fill_between(T, np.percentile(posterior_etas_1, 5, axis=0),
                            np.percentile(posterior_etas_1, 95, axis=0),
                            edgecolor='blue', lw=2.0, facecolor='None',ls='-')

    axes[1].fill_between(T, np.percentile(posterior_etas_2, 5, axis=0),
                            np.percentile(posterior_etas_2, 95, axis=0),
                            edgecolor='red', lw=2.0, facecolor='None', ls='--')

    axes[1].fill_between(T, np.percentile(posterior_etas_3, 5, axis=0),
                            np.percentile(posterior_etas_3, 95, axis=0),
                            edgecolor='green', lw=2.0, facecolor='None', ls=':')


    axes[0].set_ylabel(r"$\zeta/s$")
    axes[0].set_xlabel(r"$T$ [GeV]")
    axes[0].set_ylim(0,.35)

    axes[1].set_ylabel(r"$\eta/s$")
    axes[1].set_xlabel(r"$T$ [GeV]")

    axes[0].set_xlabel(r"$T$ [GeV]")
    axes[1].set_xlabel(r"$T$ [GeV]")

    T_ticks = [0.15, 0.2, 0.25, 0.3, 0.35]
    axes[0].set_xticks(T_ticks)
    axes[1].set_xticks(T_ticks)

    plt.tight_layout(True)
    set_tight(fig, rect=[0, 0, 0.98, .9])


@plot
def viscous_prior_sensitivity():
    """
    Plot the sensitivity of the posterior credible intervals to changes in the range of the prior.
    """
    sns.set()

    T = 0.15 # the Temperature

    color_idf = {0 : 'blue', 1 : 'red', 2 : 'green', 3 : 'magenta'}

    chain1 = Chain(path=workdir/'mcmc'/'chain-idf-0_LHC_RHIC_PTEMCEE.hdf')
    data1 = chain1.load_wo_reshape(thin=10)
    data1 = data1.reshape(-1, 19)

    chain2 = Chain(path=workdir/'mcmc'/'chain-idf-1_LHC_RHIC_PTEMCEE.hdf')
    data2 = chain2.load_wo_reshape(thin=10)
    data2 = data2.reshape(-1, 19)

    chain3 = Chain(path=workdir/'mcmc'/'chain-idf-3_LHC_RHIC_PTEMCEE.hdf')
    data3 = chain3.load_wo_reshape(thin=10)
    data3 = data3.reshape(-1, 19)

    index1 = np.random.choice(np.arange(data1.shape[0]), 50000)
    index2 = np.random.choice(np.arange(data2.shape[0]), 50000)
    index3 = np.random.choice(np.arange(data3.shape[0]), 50000)

    samples1 = data1[index1, 1:]
    samples2 = data2[index2, 1:]
    samples3 = data3[index3, 1:]

    #the prior density
    design, dmin, dmax, labels = load_design(system_str=system_strs[0], pset='main')

    #now find the restricted-prior posteriors

    #zeta/s
    bounds_zeta_1 = []
    bounds_zeta_2 = []
    bounds_zeta_3 = []

    zeta_min = 0.05
    zeta_upper = 0.25
    idx_restrict = 11
    zeta_lim_arr = np.linspace(zeta_min, zeta_upper, 10)
    for zeta_max in zeta_lim_arr:
        samples1_restrict = samples1[ (samples1[:, idx_restrict] <= zeta_max) ]
        posterior_zetas_1 = [ zeta_over_s(T, *d[11:15]) for d in samples1_restrict ]

        samples2_restrict = samples2[ (samples2[:, idx_restrict] <= zeta_max) ]
        posterior_zetas_2 = [ zeta_over_s(T, *d[11:15]) for d in samples2_restrict ]

        samples3_restrict = samples3[ (samples3[:, idx_restrict] <= zeta_max) ]
        posterior_zetas_3 = [ zeta_over_s(T, *d[11:15]) for d in samples3_restrict ]

        #calculate the 90% credible bounds
        bounds_zeta_1.append( np.percentile(posterior_zetas_1, 95, axis=0) )
        bounds_zeta_2.append( np.percentile(posterior_zetas_2, 95, axis=0) )
        bounds_zeta_3.append( np.percentile(posterior_zetas_3, 95, axis=0) )

    #eta/s
    bounds_eta_1 = []
    bounds_eta_2 = []
    bounds_eta_3 = []

    eta_min = .5
    eta_upper = -2.
    idx_restrict = 8
    eta_lim_arr = np.linspace(eta_min, eta_upper, 10)
    for eta_max in eta_lim_arr:
        samples1_restrict = samples1[ (samples1[:, idx_restrict] >= eta_max) ]
        posterior_etas_1 = [ eta_over_s(T, *d[7:11]) for d in samples1_restrict ]

        samples2_restrict = samples2[ (samples2[:, idx_restrict] >= eta_max) ]
        posterior_etas_2 = [ eta_over_s(T, *d[7:11]) for d in samples2_restrict ]

        samples3_restrict = samples3[ (samples3[:, idx_restrict] >= eta_max) ]
        posterior_etas_3 = [ eta_over_s(T, *d[7:11]) for d in samples3_restrict ]

        #calculate the 90% credible bounds
        bounds_eta_1.append( np.percentile(posterior_etas_1, 95, axis=0) )
        bounds_eta_2.append( np.percentile(posterior_etas_2, 95, axis=0) )
        bounds_eta_3.append( np.percentile(posterior_etas_3, 95, axis=0) )


    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(7,3))
    axes[0].plot(zeta_lim_arr, bounds_zeta_1, color=color_idf[0], lw=2, ls='-')
    axes[0].plot(zeta_lim_arr, bounds_zeta_2, color=color_idf[1], lw=2, ls='--')
    axes[0].plot(zeta_lim_arr, bounds_zeta_3, color=color_idf[2], lw=2, ls=':')
    axes[0].set_xlabel(r'$\max( (\zeta/s)_0 ) $')
    axes[0].set_ylabel(r'$  w[\zeta/s(T=0.15$ MeV $)$]' )
    axes[0].set_ylim(0., 0.2)

    axes[1].plot(eta_lim_arr, bounds_eta_1, color=color_idf[0], lw=2, ls='-')
    axes[1].plot(eta_lim_arr, bounds_eta_2, color=color_idf[1], lw=2, ls='--')
    axes[1].plot(eta_lim_arr, bounds_eta_3, color=color_idf[2], lw=2, ls=':')
    axes[1].set_xlabel(r'$\min( a_{\rm low} ) $')
    axes[1].set_ylabel(r'$ w[\eta/s(T=0.15$ MeV $)]$' )
    axes[1].set_ylim(0., 0.3)

    plt.tight_layout(True)

@plot
def viscous_prior_sensitivity_surface():
    """
    Plot the sensitivity of the posterior credible intervals to changes in the range of the prior.
    """
    sns.set()

    color_idf = {0 : 'blue', 1 : 'red', 2 : 'green', 3 : 'magenta'}

    chain1 = Chain(path=workdir/'mcmc'/'chain-idf-0_LHC_RHIC_PTEMCEE.hdf')
    data1 = chain1.load_wo_reshape(thin=10)
    data1 = data1.reshape(-1, 19)

    chain2 = Chain(path=workdir/'mcmc'/'chain-idf-1_LHC_RHIC_PTEMCEE.hdf')
    data2 = chain2.load_wo_reshape(thin=10)
    data2 = data2.reshape(-1, 19)

    chain3 = Chain(path=workdir/'mcmc'/'chain-idf-3_LHC_RHIC_PTEMCEE.hdf')
    data3 = chain3.load_wo_reshape(thin=10)
    data3 = data3.reshape(-1, 19)

    index1 = np.random.choice(np.arange(data1.shape[0]), 50000)
    index2 = np.random.choice(np.arange(data2.shape[0]), 50000)
    index3 = np.random.choice(np.arange(data3.shape[0]), 50000)

    samples1 = data1[index1, 1:]
    samples2 = data2[index2, 1:]
    samples3 = data3[index3, 1:]

    #the prior density
    design, dmin, dmax, labels = load_design(system_str=system_strs[0], pset='main')

    fig, axes = plt.subplots(nrows=3, ncols=3, figsize=(9,9), sharey=True )

    #now find the restricted-prior posteriors
    zeta_max_idx = 11
    zeta_width_idx = 13

    #find the correlations among the parameter posteriors
    sns.kdeplot(samples1[:, zeta_max_idx], samples1[:, zeta_width_idx], color='blue', shade=True,
    ax=axes[0, 0], n_levels=5, shade_lowest=False, gridsize=25)

    sns.kdeplot(samples2[:, zeta_max_idx], samples2[:, zeta_width_idx], color='red', shade=True,
    ax=axes[0, 1], n_levels=5, shade_lowest=False, gridsize=25)

    sns.kdeplot(samples3[:, zeta_max_idx], samples3[:, zeta_width_idx], color='green', shade=True,
    ax=axes[0, 2], n_levels=5, shade_lowest=False, gridsize=25)

    T = 0.15 # the Temperature
    #zeta/s
    zeta_max_min = 0.02
    zeta_max_upper = 0.25
    zeta_max_arr = np.linspace(zeta_max_min, zeta_max_upper, 14)

    zeta_width_min = 0.03
    zeta_width_upper = 0.15
    zeta_width_arr = np.linspace(zeta_width_min, zeta_width_upper, 15)

    bounds_arr_1 = np.zeros( ( len(zeta_max_arr), len(zeta_width_arr) ) )
    bounds_arr_2 = np.zeros( ( len(zeta_max_arr), len(zeta_width_arr) ) )
    bounds_arr_3 = np.zeros( ( len(zeta_max_arr), len(zeta_width_arr) ) )

    for i, zeta_max in enumerate(zeta_max_arr):
        samples1_restrict = samples1[ (samples1[:, zeta_max_idx] <= zeta_max) ]
        samples2_restrict = samples2[ (samples2[:, zeta_max_idx] <= zeta_max) ]
        samples3_restrict = samples3[ (samples3[:, zeta_max_idx] <= zeta_max) ]

        for j, zeta_width in enumerate(zeta_width_arr):
            samples1_restrict_b = samples1_restrict[ (samples1_restrict[:, zeta_width_idx] <= zeta_width) ]
            posterior_zetas_1 = [ zeta_over_s(T, *d[11:15]) for d in samples1_restrict_b ]

            samples2_restrict_b = samples2_restrict[ (samples2_restrict[:, zeta_width_idx] <= zeta_width) ]
            posterior_zetas_2 = [ zeta_over_s(T, *d[11:15]) for d in samples2_restrict_b ]

            samples3_restrict_b = samples3_restrict[ (samples3_restrict[:, zeta_width_idx] <= zeta_width) ]
            posterior_zetas_3 = [ zeta_over_s(T, *d[11:15]) for d in samples3_restrict_b ]

            #calculate the 90% credible bounds
            bounds_arr_1[i,j] = np.percentile(posterior_zetas_1, 90, axis=0)
            bounds_arr_2[i,j] = np.percentile(posterior_zetas_2, 90, axis=0)
            bounds_arr_3[i,j] = np.percentile(posterior_zetas_3, 90, axis=0)


    im1 = axes[1, 0].contourf(zeta_max_arr, zeta_width_arr, bounds_arr_1.T, cmap=plt.get_cmap('Blues'))
    im2 = axes[1, 1].contourf(zeta_max_arr, zeta_width_arr, bounds_arr_2.T, cmap=plt.get_cmap('Reds'))
    im3 = axes[1, 2].contourf(zeta_max_arr, zeta_width_arr, bounds_arr_3.T, cmap=plt.get_cmap('Greens'))

    T = 0.35 # the Temperature
    for i, zeta_max in enumerate(zeta_max_arr):
        samples1_restrict = samples1[ (samples1[:, zeta_max_idx] <= zeta_max) ]
        samples2_restrict = samples2[ (samples2[:, zeta_max_idx] <= zeta_max) ]
        samples3_restrict = samples3[ (samples3[:, zeta_max_idx] <= zeta_max) ]

        for j, zeta_width in enumerate(zeta_width_arr):
            samples1_restrict_b = samples1_restrict[ (samples1_restrict[:, zeta_width_idx] <= zeta_width) ]
            posterior_zetas_1 = [ zeta_over_s(T, *d[11:15]) for d in samples1_restrict_b ]

            samples2_restrict_b = samples2_restrict[ (samples2_restrict[:, zeta_width_idx] <= zeta_width) ]
            posterior_zetas_2 = [ zeta_over_s(T, *d[11:15]) for d in samples2_restrict_b ]

            samples3_restrict_b = samples3_restrict[ (samples3_restrict[:, zeta_width_idx] <= zeta_width) ]
            posterior_zetas_3 = [ zeta_over_s(T, *d[11:15]) for d in samples3_restrict_b ]

            #calculate the 90% credible bounds
            bounds_arr_1[i,j] = np.percentile(posterior_zetas_1, 90, axis=0)
            bounds_arr_2[i,j] = np.percentile(posterior_zetas_2, 90, axis=0)
            bounds_arr_3[i,j] = np.percentile(posterior_zetas_3, 90, axis=0)


    im1 = axes[2, 0].contourf(zeta_max_arr, zeta_width_arr, bounds_arr_1.T, cmap=plt.get_cmap('Blues'))
    im2 = axes[2, 1].contourf(zeta_max_arr, zeta_width_arr, bounds_arr_2.T, cmap=plt.get_cmap('Reds'))
    im3 = axes[2, 2].contourf(zeta_max_arr, zeta_width_arr, bounds_arr_3.T, cmap=plt.get_cmap('Greens'))

    for j in range(3):
    #    axes[2, j].set_xlabel(r'$(\zeta/s)_{\rm max}$')
    #    axes[j, 0].set_ylabel(r'$w_{\zeta}$[GeV]')
        for i in range(3):
            axes[i,j].set_xlim(zeta_max_min, zeta_max_upper)
            axes[i,j].set_ylim(zeta_width_min, zeta_width_upper)

    axes[0, 0].set_ylabel(r'$w_{\zeta}$[GeV]')
    axes[1, 0].set_ylabel(r'$w_{\zeta, \rm max}$[GeV]')
    axes[2, 0].set_ylabel(r'$w_{\zeta, \rm max}$[GeV]')

    axes[0, 0].set_xlabel(r'$\bar{\zeta}_c$')
    axes[0, 1].set_xlabel(r'$\bar{\zeta}_c$')
    axes[0, 2].set_xlabel(r'$\bar{\zeta}_c$')

    for j in [0, 1, 2]:
        axes[1, j].set_xlabel(r'$\bar{\zeta}_{c, \rm max}$' )
        axes[2, j].set_xlabel(r'$\bar{\zeta}_{c, \rm max}$' )

    plt.tight_layout(True)


@plot
def viscous_posterior_overlay_2():
    """
    Another version of the credible interval posterior of eta/s(T) and zeta/s(T).
    """

    T = np.linspace(0.15, 0.35, 100)

    color_CI = idf_color[idf]

    chain1 = Chain(path=workdir/'mcmc'/'chain-idf-0_LHC_RHIC_PTEMCEE.hdf')
    data1 = chain1.load_wo_reshape()
    data1 = data1.reshape(-1, 19)

    chain2 = Chain(path=workdir/'mcmc'/'chain-idf-0_LHC_RHIC_XE.hdf')
    data2 = chain2.load_wo_reshape()
    data2 = data2.reshape(-1, 20)

    index1 = np.random.choice(np.arange(data1.shape[0]), 50000)
    index2 = np.random.choice(np.arange(data2.shape[0]), 50000)

    samples1 = data1[index1, 1:]
    samples2 = data2[index2, 1:]

    #the prior density
    design, dmin, dmax, labels = load_design(system_str=system_strs[0], pset='main')

    n_samples_prior = 100000
    prior_zetas = []
    for (zm, T0, w, asym) in zip(
                np.random.uniform( min(design['zeta_over_s_max']), max(design['zeta_over_s_max']), n_samples_prior),
                np.random.uniform( min(design['zeta_over_s_T_peak_in_GeV']), max(design['zeta_over_s_T_peak_in_GeV']), n_samples_prior),
                np.random.uniform( min(design['zeta_over_s_width_in_GeV']), max(design['zeta_over_s_width_in_GeV']), n_samples_prior),
                np.random.uniform( min(design['zeta_over_s_lambda_asymm']), max(design['zeta_over_s_lambda_asymm']), n_samples_prior)
                ):
        prior_zetas.append(zeta_over_s(T, zm, T0, w, asym))

    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(5.5,3.5),
                    sharex=False, sharey=False, constrained_layout=True)

    posterior_zetas_1 = [ zeta_over_s(T, *d[11:15]) for d in samples1 ]
    posterior_zetas_2 = [ zeta_over_s(T, *d[12:16]) for d in samples2 ]

    axes[0].fill_between(T, np.percentile(prior_zetas, 5, axis=0),
                         np.percentile(prior_zetas, 95, axis=0),
                         color='gray', alpha=0.4, label='90% C.I. (Prior)'
                         )

    axes[0].fill_between(T, np.percentile(posterior_zetas_1, 5, axis=0),
                            np.percentile(posterior_zetas_1, 95, axis=0),
                            edgecolor='purple', lw=2.0, facecolor='None', ls='-',
                            label='90% C.I. Posterior \n Pb Au')

    axes[0].fill_between(T, np.percentile(posterior_zetas_2, 5, axis=0),
                            np.percentile(posterior_zetas_2, 95, axis=0),
                            edgecolor='orange', lw=2.0, facecolor='None', ls='--',
                            label='90% C.I. Posterior \n Pb Xe Au')

    axes[0].legend(loc=(.05, .75), fontsize=qm_font_small)
    ##########################

    posterior_etas_1 = [ eta_over_s(T, *d[7:11]) for d in samples1 ]
    posterior_etas_2 = [ eta_over_s(T, *d[8:12]) for d in samples2 ]

    prior_etas = []
    for (T_k, alow, ahigh, etas_k) in zip(
                np.random.uniform( min(design['eta_over_s_T_kink_in_GeV']), max(design['eta_over_s_T_kink_in_GeV']), n_samples_prior),
                np.random.uniform( min(design['eta_over_s_low_T_slope_in_GeV']), max(design['eta_over_s_low_T_slope_in_GeV']), n_samples_prior),
                np.random.uniform( min(design['eta_over_s_high_T_slope_in_GeV']), max(design['eta_over_s_high_T_slope_in_GeV']), n_samples_prior),
                np.random.uniform( min(design['eta_over_s_at_kink']), max(design['eta_over_s_at_kink']), n_samples_prior)
                ):
        prior_etas.append(eta_over_s(T, T_k, alow, ahigh, etas_k))

    axes[1].fill_between(T, np.percentile(prior_etas, 5, axis=0),
                             np.percentile(prior_etas, 95, axis=0),
                             color='gray', alpha=0.4)

    axes[1].fill_between(T, np.percentile(posterior_etas_1, 5, axis=0),
                            np.percentile(posterior_etas_1, 95, axis=0),
                            edgecolor='purple', lw=2.0, facecolor='None',ls='-')

    axes[1].fill_between(T, np.percentile(posterior_etas_2, 5, axis=0),
                            np.percentile(posterior_etas_2, 95, axis=0),
                            edgecolor='orange', lw=2.0, facecolor='None', ls='--')

    axes[0].set_ylabel(r"$\zeta/s$")
    axes[0].set_xlabel(r"$T$ [GeV]")
    axes[0].set_ylim(0,.35)

    axes[1].set_ylabel(r"$\eta/s$")
    axes[1].set_xlabel(r"$T$ [GeV]")

    axes[0].set_xlabel(r"$T$ [GeV]")
    axes[1].set_xlabel(r"$T$ [GeV]")

    T_ticks = [0.15, 0.2, 0.25, 0.3, 0.35]
    axes[0].set_xticks(T_ticks)
    axes[1].set_xticks(T_ticks)

    plt.tight_layout(True)
    set_tight(fig, rect=[0, 0, 0.98, .9])


@plot
def viscous_posterior_overlay_3():
    """
    Another version of the credible interval posterior of eta/s(T) and zeta/s(T).
    """

    T = np.linspace(0.15, 0.35, 100)

    color_CI = idf_color[idf]

    chain1 = Chain(path=workdir/'mcmc'/'chain-idf-3_LHC_PTEMCEE_full_prior.hdf')
    data1 = chain1.load_wo_reshape(thin=1)

    chain2 = Chain(path=workdir/'mcmc'/'chain-idf-3_LHC_PTEMCEE_reduced_prior.hdf')
    data2 = chain2.load_wo_reshape(thin=1)

    if num_systems == 1:
        data1 = data1.reshape(-1, 18)
        data2 = data2.reshape(-1, 18)
    elif num_systems == 2:
        data1 = data1.reshape(-1, 19)
        data2 = data2.reshape(-1, 19)

    index1 = np.random.choice(np.arange(data1.shape[0]), 50000)
    index2 = np.random.choice(np.arange(data2.shape[0]), 50000)

    #design, dmin, dmax, labels = load_design(system_str=system_strs[0], pset='main')
    samples1 = data1[index1, 1:]
    samples2 = data2[index2, 1:]

    #the prior density
    design, dmin, dmax, labels = load_design(system_str=system_strs[0], pset='main')

    n_samples_prior = 100000
    prior_zetas = []
    for (zm, T0, w, asym) in zip(
                np.random.uniform( min(design['zeta_over_s_max']), max(design['zeta_over_s_max']), n_samples_prior),
                np.random.uniform( min(design['zeta_over_s_T_peak_in_GeV']), max(design['zeta_over_s_T_peak_in_GeV']), n_samples_prior),
                np.random.uniform( min(design['zeta_over_s_width_in_GeV']), max(design['zeta_over_s_width_in_GeV']), n_samples_prior),
                np.random.uniform( min(design['zeta_over_s_lambda_asymm']), max(design['zeta_over_s_lambda_asymm']), n_samples_prior)
                ):
        prior_zetas.append(zeta_over_s(T, zm, T0, w, asym))

    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(5.5,3.5),
                    sharex=False, sharey=False, constrained_layout=True)
    fig.suptitle(idf_label_short[3] + r" Viscosity Posterior : Effect of Prior", fontsize=qm_font_large, wrap=True)

    if num_systems == 1:
        posterior_zetas_1 = [ zeta_over_s(T, *d[10:14]) for d in samples1 ]
        posterior_zetas_2 = [ zeta_over_s(T, *d[10:14]) for d in samples2 ]
    elif num_systems == 2:
        posterior_zetas_1 = [ zeta_over_s(T, *d[11:15]) for d in samples1 ]
        posterior_zetas_2 = [ zeta_over_s(T, *d[11:15]) for d in samples2 ]

    axes[0].fill_between(T, np.percentile(posterior_zetas_1, 5, axis=0),
                            np.percentile(posterior_zetas_1, 95, axis=0),
                            edgecolor='green', lw=2.0, facecolor='None', ls='-',
                            #label='90% C.I. 10 PCs Pb, \n 6 PCs Au')
                            label='90% C.I. posterior \n w/ full prior')

    axes[0].fill_between(T, np.percentile(posterior_zetas_2, 5, axis=0),
                            np.percentile(posterior_zetas_2, 95, axis=0),
                            edgecolor='green', lw=2.0, facecolor='None', ls='--',
                            #label='90% C.I. 5 PCs Pb, \n 3 PCs Au')
                            label='90% C.I. posterior \n w/ reduced prior')


    axes[0].legend(loc=(.05, .75), fontsize=qm_font_small)
    ##########################

    if num_systems == 1:
        posterior_etas_1 = [ eta_over_s(T, *d[6:10]) for d in samples1 ]
        posterior_etas_2 = [ eta_over_s(T, *d[6:10]) for d in samples2 ]
    elif num_systems == 2:
        posterior_etas_1 = [ eta_over_s(T, *d[7:11]) for d in samples1 ]
        posterior_etas_2 = [ eta_over_s(T, *d[7:11]) for d in samples2 ]

    prior_etas = []
    for (T_k, alow, ahigh, etas_k) in zip(
                np.random.uniform( min(design['eta_over_s_T_kink_in_GeV']), max(design['eta_over_s_T_kink_in_GeV']), n_samples_prior),
                np.random.uniform( min(design['eta_over_s_low_T_slope_in_GeV']), max(design['eta_over_s_low_T_slope_in_GeV']), n_samples_prior),
                np.random.uniform( min(design['eta_over_s_high_T_slope_in_GeV']), max(design['eta_over_s_high_T_slope_in_GeV']), n_samples_prior),
                np.random.uniform( min(design['eta_over_s_at_kink']), max(design['eta_over_s_at_kink']), n_samples_prior)
                ):
        prior_etas.append(eta_over_s(T, T_k, alow, ahigh, etas_k))

    axes[1].fill_between(T, np.percentile(posterior_etas_1, 5, axis=0),
                            np.percentile(posterior_etas_1, 95, axis=0),
                            edgecolor='green', lw=2.0, facecolor='None',ls='-')

    axes[1].fill_between(T, np.percentile(posterior_etas_2, 5, axis=0),
                            np.percentile(posterior_etas_2, 95, axis=0),
                            edgecolor='green', lw=2.0, facecolor='None', ls='--')


    axes[0].set_ylabel(r"$\zeta/s$")
    axes[0].set_xlabel(r"$T$ [GeV]")
    axes[0].set_ylim(0,.35)

    axes[1].set_ylabel(r"$\eta/s$")
    axes[1].set_xlabel(r"$T$ [GeV]")

    axes[0].set_xlabel(r"$T$ [GeV]")
    axes[1].set_xlabel(r"$T$ [GeV]")

    T_ticks = [0.15, 0.2, 0.25, 0.3, 0.35]
    axes[0].set_xticks(T_ticks)
    axes[1].set_xticks(T_ticks)

    plt.tight_layout(True)
    set_tight(fig, rect=[0, 0, 0.98, .9])

@plot
def viscous_posterior_w_samples():
    viscous_posterior(plot_samples=True)
@plot
def viscous_posterior_wo_samples():
    viscous_posterior(plot_samples=False)


@plot
def freestream_time_posterior_overlay():
    """
    Plots the credible intervals of the energy-dependent freestreaming time tau_FS = tau_FS(e),
    overlaying all 3 df models.
    """

    e_R = 4.0 # GeV / fm^3
    e = np.linspace(e_R * 1e-1, e_R * 1e1, 1000)

    color_CI = idf_color[idf]

    chain1 = Chain(path=workdir/'mcmc'/'chain-idf-0_LHC_RHIC_PTEMCEE.hdf')
    data1 = chain1.load_wo_reshape(thin=5)
    data1 = data1.reshape(-1, 19)

    chain2 = Chain(path=workdir/'mcmc'/'chain-idf-1_LHC_RHIC_PTEMCEE.hdf')
    data2 = chain2.load_wo_reshape(thin=5)
    data2 = data2.reshape(-1, 19)

    chain3 = Chain(path=workdir/'mcmc'/'chain-idf-3_LHC_RHIC_PTEMCEE.hdf')
    data3 = chain3.load_wo_reshape(thin=5)
    data3 = data3.reshape(-1, 19)

    index1 = np.random.choice(np.arange(data1.shape[0]), 50000)
    index2 = np.random.choice(np.arange(data2.shape[0]), 50000)
    index3 = np.random.choice(np.arange(data3.shape[0]), 50000)

    #design, dmin, dmax, labels = load_design(system_str=system_strs[0], pset='main')
    samples1 = data1[index1, 1:]
    samples2 = data2[index2, 1:]
    samples3 = data3[index3, 1:]

    #the prior density
    design, dmin, dmax, labels = load_design(system_str=system_strs[0], pset='main')

    n_samples_prior = 100000
    prior_tau_fs = []
    for (tau_R, alpha) in zip(
                np.random.uniform( min(design['tau_R']), max(design['tau_R']), n_samples_prior),
                np.random.uniform( min(design['alpha']), max(design['alpha']), n_samples_prior),
                ):
        prior_tau_fs.append(tau_fs(e, e_R, tau_R, alpha))

    #fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(5.5,3.5), sharex=False, sharey=False, constrained_layout=True)
    fig = plt.figure(figsize=(4,4))
    plt.suptitle(r"Freestreaming Time Posterior", fontsize=qm_font_large, wrap=True)

    posterior_tau_fs_1 = [ tau_fs(e, e_R, *d[5:7]) for d in samples1 ]
    posterior_tau_fs_2 = [ tau_fs(e, e_R, *d[5:7]) for d in samples2 ]
    posterior_tau_fs_3 = [ tau_fs(e, e_R, *d[5:7]) for d in samples3 ]

    plt.fill_between(e, np.percentile(prior_tau_fs, 5, axis=0),
                         np.percentile(prior_tau_fs, 95, axis=0),
                         color='gray', alpha=0.4, label='90% C.I. (Prior)'
                         )

    plt.fill_between(e, np.percentile(posterior_tau_fs_1, 5, axis=0),
                            np.percentile(posterior_tau_fs_1, 95, axis=0),
                            edgecolor='blue', lw=2.0, facecolor='None', ls='-',
                            label=r'90% C.I. ' + idf_label_short[0])

    plt.fill_between(e, np.percentile(posterior_tau_fs_2, 5, axis=0),
                            np.percentile(posterior_tau_fs_2, 95, axis=0),
                            edgecolor='red', lw=2.0, facecolor='None', ls='--',
                            label=r'90% C.I. ' + idf_label_short[1])

    plt.fill_between(e, np.percentile(posterior_tau_fs_3, 5, axis=0),
                            np.percentile(posterior_tau_fs_3, 95, axis=0),
                            edgecolor='green', lw=2.0, facecolor='None', ls=':',
                            label=r'90% C.I. ' + idf_label_short[3])


    plt.legend(loc='upper center', fontsize=qm_font_small)
    plt.ylabel(r"$\tau_{fs}$ [fm/c]")
    plt.xlabel(r"$\langle \bar{\epsilon} \rangle$ [GeV / fm$^2$]")
    plt.ylim(0, 3.5)

    plt.tight_layout(True)
    set_tight(fig, rect=[0, 0, 1, .9])

@plot
def freestream_time_posterior():
    """
    Plots the credible intervals of the energy-dependent freestreaming time tau_FS = tau_FS(e).
    """

    e_R = 4.0 # GeV / fm^3
    e = np.linspace(e_R * 1e-1, e_R * 1e1, 1000)

    color_CI = idf_color[idf]
    label_idf = idf_label_short[idf]

    chain1 = Chain(path=workdir/'mcmc'/'chain-idf-{:d}_LHC_RHIC_PTEMCEE.hdf'.format(idf))
    data1 = chain1.load_wo_reshape(thin=5)
    data1 = data1.reshape(-1, 19)

    index1 = np.random.choice(np.arange(data1.shape[0]), 50000)
    samples1 = data1[index1, 1:]

    #the prior density
    design, dmin, dmax, labels = load_design(system_str=system_strs[0], pset='main')

    n_samples_prior = 100000
    prior_tau_fs = []
    for (tau_R, alpha) in zip(
                np.random.uniform( min(design['tau_R']), max(design['tau_R']), n_samples_prior),
                np.random.uniform( min(design['alpha']), max(design['alpha']), n_samples_prior),
                ):
        prior_tau_fs.append(tau_fs(e, e_R, tau_R, alpha))

    #fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(5.5,3.5), sharex=False, sharey=False, constrained_layout=True)
    fig = plt.figure(figsize=(4,4))
    plt.suptitle(r"Freestreaming Time Posterior : " + label_idf, fontsize=qm_font_large, wrap=True)

    posterior_tau_fs_1 = [ tau_fs(e, e_R, *d[5:7]) for d in samples1 ]

    plt.fill_between(e, np.percentile(prior_tau_fs, 5, axis=0),
                         np.percentile(prior_tau_fs, 95, axis=0),
                         color='gray', alpha=0.4, label='90% C.I. (Prior)'
                         )

    plt.fill_between(e, np.percentile(posterior_tau_fs_1, 5, axis=0),
                            np.percentile(posterior_tau_fs_1, 95, axis=0),
                            color=color_CI, alpha=0.4, label=r'90% C.I.')
    plt.fill_between(e, np.percentile(posterior_tau_fs_1, 45, axis=0),
                            np.percentile(posterior_tau_fs_1, 55, axis=0),
                            color=color_CI, alpha=0.7, label=r'60% C.I.')

    plt.legend(loc='upper center', fontsize=qm_font_small)
    plt.ylabel(r"$\tau_{FS}$ [fm/c]")
    plt.xlabel(r"$e_0$ [GeV / fm$^3$]")
    plt.ylim(0, 3.5)

    plt.tight_layout(True)
    set_tight(fig, rect=[0, 0, 1, .9])

@plot
def freestream_time_posterior_density():
    """
    Plot the density rather than credible intervals for the
    energy-dependent freestreaming time tau_FS = tau_FS(e).
    """

    e_R = 4.0 # GeV / fm^3

    chain = Chain(path=workdir/'mcmc'/'chain-idf-1_LHC_RHIC_PTEMCEE.hdf')
    cmap = plt.get_cmap('Reds')

    data = chain.load_wo_reshape(thin=5)
    data = data.reshape(-1, 19)

    fig = plt.figure(figsize=(4,4))
    plt.suptitle(r"Freestream Time Posterior", fontsize=qm_font_large, wrap=True)

    #sample e and tau_fs n_samples times
    n_samples = int(1e8)

    tau_vals = []
    #draw samples
    e_vals = np.random.uniform(e_R * 1e-1, e_R * 1e1, n_samples)
    indices = np.random.choice(np.arange(data.shape[0]), n_samples)

    for n in range(n_samples):
        e_val = e_vals[n]
        index = indices[n]
        sample = data[index, 1:]
        tau_R = sample[5]
        alpha = sample[6]
        #get tau_fs
        tau_val = tau_fs(e_val, e_R, tau_R, alpha)
        tau_vals.append(tau_val)

    n_samples_eff = len(tau_vals)
    #draw a density plot
    plt.hist2d(e_vals[:n_samples_eff], tau_vals, bins=100, cmap=cmap)
    plt.legend(loc='upper center', fontsize=qm_font_small)
    plt.ylabel(r"$\tau_{FS}$ [fm/c]")
    plt.xlabel(r"$e$")
    plt.tight_layout(True)
    set_tight(fig, rect=[0, 0, 1, .9])

@plot
def zetas_validation():
    """
    Closure test plot for zeta/s(T). Not sure if functional/deprecated?
    """
    # prior
    design,_,_,_ = load_design(system_strs[0], pset='main')
    T = np.linspace(0.13, 0.37, 500)
    #prior = np.array([zeta_over_s(T, *truth) for truth in design[11:14]])
    prior = np.array([zeta_over_s(T, X[11], X[12], X[13], X[14]) for X in design.values])


    fig, axes = plt.subplots(
        nrows=5, ncols=5,
        figsize=(6,6), sharex=True, sharey=True
    )

    # validation
    #design, _, _, _ = prepare_emu_design(systems[0],pset='validation')
    design,_,_,_ = load_design(system_strs[0], pset='validation')
    #for iv, ax in zip(np.random.choice(range(93),25), axes.flatten()):
    for iv, ax in zip([0,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17], axes.flatten()):
        f = "./validate/{:d}-zetas.dat".format(iv)
        t, m, M, l1, l2, h1, h2 = np.loadtxt(f).T

        X=design.values[iv]

        #true = zeta_over_s(T, *design[iv])
        true = zeta_over_s(T, X[11], X[12], X[13], X[14])
        ax.plot(T, true, ls="--", c=".3", linewidth=2)
        Ttest = t #[.155, .175, .2, .25, .35]
        #ax.errorbar(Ttest, M, yerr=[M-l1,h2-M], color=cr,fmt='o', linewidth=.5)
        ax.fill_between(Ttest, l1, h2, color='blue', alpha=.2)
        ax.fill_between(Ttest, l2, h1, color='blue', alpha=.4)
        ax.annotate(r"$\tau_{\pi}: $"+r"${:1.1f}$".format(X[15]),xy=(.3, .9), xycoords="axes fraction")
        ax.annotate(r"$\tau_0: $"+r"${:1.2f}$".format(X[5]),xy=(.3, .75), xycoords="axes fraction")
        ax.annotate(r"$\alpha: $"+r"${:1.2f}$".format(X[6]),xy=(.3, .6), xycoords="axes fraction")
        ax.annotate(r"$\sigma: $"+r"${:1.3f}$".format(X[2]),xy=(.3, .45), xycoords="axes fraction")

        #for iT, im, iy1, iy2 in zip(Ttest, M,l2,h1):
        #    ax.fill_between([iT-.01, iT+.01], [iy1, iy1], [iy2, iy2], edgecolor=cr, linewidth=.5, facecolor='none')

        ax.fill_between(T, np.min(prior, axis=0), np.max(prior, axis=0), color='gray', alpha=.1)
        if ax.is_last_row():
            ax.set_xlabel(r"$T$ [GeV]")
        if ax.is_first_col():
            ax.set_ylabel(r"$\zeta/s$")

    ax.set_xticks([0.15, 0.25,  0.35])
    ax.set_xticklabels([0.15, 0.25, 0.35])
    set_tight(fig, rect=[0, 0, 1, 1])

@plot
def etas_validation():
    """
    Closure test plot for eta/s(T). Not sure if functional/deprecated?
    """
    # prior
    design,_,_,_ = load_design(system_strs[0], pset='main')
    T = np.linspace(0.13, 0.37, 500)
    prior = np.array([eta_over_s(T, X[7], X[8], X[9], X[10]) for X in design.values])


    fig, axes = plt.subplots(
        nrows=5, ncols=5,
        figsize=(6,6), sharex=True, sharey=True
    )

    # validation
    #design, _, _, _ = prepare_emu_design(systems[0],pset='validation')
    design,_,_,_ = load_design(system_strs[0], pset='validation')
    #for iv, ax in zip(np.random.choice(range(93),25), axes.flatten()):
    for iv, ax in zip([0,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17], axes.flatten()):
        f = "./validate/{:d}-etas.dat".format(iv)
        t, m, M, l1, l2, h1, h2 = np.loadtxt(f).T

        X=design.values[iv]

        #true = zeta_over_s(T, *design[iv])
        true = eta_over_s(T, X[7], X[8], X[9], X[10])
        ax.plot(T, true, ls="--", c=".3", linewidth=2)
        Ttest = t #[.155, .175, .2, .25, .35]
        #ax.errorbar(Ttest, M, yerr=[M-l1,h2-M], color=cr,fmt='o', linewidth=.5)
        ax.fill_between(Ttest, l1, h2, color='blue', alpha=.2)
        ax.fill_between(Ttest, l2, h1, color='blue', alpha=.4)
        #for iT, im, iy1, iy2 in zip(Ttest, M,l2,h1):
        #    ax.fill_between([iT-.01, iT+.01], [iy1, iy1], [iy2, iy2], edgecolor=cr, linewidth=.5, facecolor='none')
        ax.annotate(r"$\tau_{\pi}: $"+r"${:1.1f}$".format(X[15]),xy=(.3, .9), xycoords="axes fraction")
        ax.annotate(r"$\tau_0: $"+r"${:1.2f}$".format(X[5]),xy=(.3, .75), xycoords="axes fraction")
        ax.annotate(r"$\alpha: $"+r"${:1.2f}$".format(X[6]),xy=(.3, .6), xycoords="axes fraction")
        ax.annotate(r"$\sigma: $"+r"${:1.3f}$".format(X[2]),xy=(.3, .45), xycoords="axes fraction")

        ax.fill_between(T, np.min(prior, axis=0), np.max(prior, axis=0), color='gray', alpha=.1)
        if ax.is_last_row():
            ax.set_xlabel(r"$T$ [GeV]")
        if ax.is_first_col():
            ax.set_ylabel(r"$\eta/s$")

    ax.set_xticks([0.15, 0.25,  0.35])
    ax.set_xticklabels([0.15, 0.25, 0.35])
    set_tight(fig, rect=[0, 0, 1, 1])

@plot
def validate_extraction():
    """
    For making a closure test plot? Not sure if functional/deprecated, needs check.
    """
    import glob
    true = []
    mid = []
    maxi = []
    L1 = []
    L2 = []
    H1 = []
    H2 = []
    for f in glob.glob("./validate/*"):
        t, m, M, l1, l2, h1, h2 = np.loadtxt(f).T
        true.append(t)
        mid.append(m)
        maxi.append(M)
        L1.append(l1)
        L2.append(l2)
        H1.append(h1)
        H2.append(h2)
    true = np.array(true)
    mid = np.array(mid)
    maxi = np.array(maxi)
    L1 = np.array(L1)
    L2 = np.array(L2)
    H1 = np.array(H1)
    H2 = np.array(H2)
    labels = [r'$N_{2.76\mathrm{TeV}}$',r'$k$', r'$w$ [fm]', r'$\tau_R$ [fm/$c$]',
              r'$\alpha$', r'$\eta/s$', r'$(\zeta/s)_{\max}$',
              r'$T_{\zeta/s}^{\mathrm{peak}}$ [GeV]', r'$A^{1/4}_{\zeta/s}$',
              r'$\lambda^{asym}_{\zeta/s}$']
    # get range
    range_file = design_dir + \
               '/design_ranges_main_{:s}{:s}-{:d}.dat'.format(*systems[0])
    design_range = pd.read_csv(range_file)
    design_max = design_range['max'].values
    design_min = design_range['min'].values

    fig, axes = plt.subplots(
        nrows=3, ncols=5,
        figsize=(8,5),
    )

    for i, (label, ax) in enumerate(zip(labels, axes.flatten())):
        ax.errorbar(true[:,i], mid[:,i], yerr=[mid[:,i]-L2[:,i],H2[:,i]-mid[:,i]], color=cr,fmt='o', linewidth=.1)
        ax.errorbar(true[:,i], mid[:,i], yerr=[mid[:,i]-L1[:,i],H1[:,i]-mid[:,i]], color=cr,fmt='o', linewidth=.5)
        ax.scatter(true[:,i], maxi[:,i], color=cb)
        cov = np.cov(np.stack((true[:,i], mid[:,i]), axis=0))
        #label = label+r", $r = {:1.2f}$".format(cov[1,0]/np.sqrt(cov[0,0]*cov[1,1]))
        ax.set_title(label)
        if ax.is_last_row():
            ax.set_xlabel("Truth")
        if ax.is_first_col():
            ax.set_ylabel("Extracted")
        ax.plot([design_min[i],design_max[i]], [design_min[i],design_max[i]], ls="--", c=".3")
        ax.set_aspect('equal')

    for ax, Ttest, i in zip(axes[2], [.155, .175, .2, .25, .35], [10,11,12,13,14]):
        ax.errorbar(true[:,i], mid[:,i], yerr=[mid[:,i]-L2[:,i],H2[:,i]-mid[:,i]], color=cr,fmt='o', linewidth=.1)
        ax.errorbar(true[:,i], mid[:,i], yerr=[mid[:,i]-L1[:,i],H1[:,i]-mid[:,i]], color=cr,fmt='o', linewidth=.5)
        ax.scatter(true[:,i], maxi[:,i], color=cb)
        ax.set_title(r"$\zeta/s$"+r"$(T={:1.3f})$".format(Ttest))
        if ax.is_last_row():
            ax.set_xlabel("Truth")
        if ax.is_first_col():
            ax.set_ylabel("Extracted")
        ax.plot([0,0.25], [0,0.25], ls="--", c=".3")
    set_tight(fig, rect=[0, 0, 1, 1])


@plot
def find_map():
    """
    Find the maximum a posteriori (MAP) point and compare emulator predictions
    to experimental data. (Plotting is Deprecated - needs update)

    """
    from scipy.optimize import minimize
    from scipy.optimize import basinhopping

    chain = Chain(path=workdir/'mcmc'/'chain-idf-{:d}_LHC_RHIC_PTEMCEE.hdf'.format(idf))

    fixed_params = {
        #'trento_p': 0.,
        #'etas_min': .08,
        #'etas_hrg': .3,
        #'model_sys_err': .1,
    }

    opt_params = [k for k in chain.labels if k not in fixed_params]

    def full_x(x):
        x = dict(zip(opt_params, x), **fixed_params)
        return [x[k] for k in chain.labels]

    print("####################################################")
    print("Minimizing -log(Posterior) to find MAP parameters...")
    bounds=[
        (a + 1e-6*(b - a), b - 1e-6*(b - a))
        for (a, b), k in zip(chain.range, chain.labels)
        if k in opt_params
    ]
    #minimizer_kwargs = dict(method="L-BFGS-B", bounds=bounds)
    x0 = np.median(chain.load(), axis=0)
    #res = basinhopping(
    #        lambda x: -chain.log_posterior(full_x(x))[0],
    #        x0,
    #        minimizer_kwargs=minimizer_kwargs
    #        )
    #NOTE scipy.optimize minimize finds local minima not global minima
    res = minimize(
        lambda x: -chain.log_posterior(full_x(x))[0],
        x0 = x0,
        tol = 1e-7,
        bounds=bounds
        )

    print('optimization result:\n%s', res)
    width = max(map(len, chain.labels)) + 2
    print(
        'MAP params:\n%s',
        '\n'.join(
            k.ljust(width) + str(x) for k, x in zip(chain.labels, full_x(res.x))
        )
    )
    systems_title = ''
    for s in system_strs:
        systems_title += (' ' + s)
    with open('plots/MAP_' + idf_label[idf] + '.md', 'w') as myfile:
        myfile.write('## MAP parameters : ' + idf_label_short[idf] + ' ' + systems_title + '\n')
        myfile.write('| Parameter | MAP Value |\n')
        myfile.write('| --------- | --------- |\n')
        myfile.write(
            '\n'.join(
                #k.ljust(width) + str(x) for k, x in zip(chain.keys, full_x(res.x))
                '|'+k+'|'+str(round(x, 3))+'|' for k, x in zip(chain.labels, full_x(res.x))
            )
        )

    print("####################################################")

    #the following plot is deprectaed, needs to be updated to work.
    """
    pred = chain._predict(np.atleast_2d(full_x(res.x)))

    plots = _observables_plots()

    fig, axes = plt.subplots(
        nrows=2*len(plots), ncols=len(systems),
        figsize=figsize(1.1, aspect=1.7),
        gridspec_kw=dict(
            height_ratios=list(itertools.chain.from_iterable(
                (p.get('height_ratio', 1), .4) for p in plots
            ))
        )
    )

    for (plot, system), ax, ratio_ax in zip(
            itertools.product(plots, systems), axes[::2].flat, axes[1::2].flat
    ):
        for obs, subobs, opts in plot['subplots']:
            color = obs_color(obs, subobs)
            scale = opts.get('scale')

            x = model.data[system][obs][subobs]['x']
            y = pred[system][obs][subobs][0]

            if scale is not None:
                y = y*scale

            ax.plot(x, y, color=color)

            if 'label' in opts:
                ax.text(
                    x[-1] + 3, y[-1],
                    opts['label'],
                    color=darken(color), ha='left', va='center'
                )

            try:
                dset = expt.data[system][obs][subobs]
            except KeyError:
                continue

            x = dset['x']
            yexp = dset['y']
            yerr = dset['yerr']
            yerrstat = yerr.get('stat')
            yerrsys = yerr.get('sys', yerr.get('sum'))

            if scale is not None:
                yexp = yexp*scale
                if yerrstat is not None:
                    yerrstat = yerrstat*scale
                if yerrsys is not None:
                    yerrsys = yerrsys*scale

            ax.errorbar(
                x, yexp, yerr=yerrstat, fmt='o',
                capsize=0, color='.25', zorder=1000
            )

            ax.fill_between(
                x, yexp - yerrsys, yexp + yerrsys,
                color='.9', zorder=-10
            )

            ratio_ax.plot(x, y/yexp, color=color)

        if plot.get('yscale') == 'log':
            ax.set_yscale('log')
            ax.minorticks_off()
        else:
            auto_ticks(ax, 'y', nbins=4, minor=2)

        for a in [ax, ratio_ax]:
            a.set_xlim(0, 80)
            auto_ticks(a, 'x', nbins=5, minor=2)

        ax.set_xticklabels([])

        ax.set_ylim(plot['ylim'])

        if ax.is_first_row():
            ax.set_title(format_system(system))
        elif ax.is_last_row():
            ax.set_xlabel('Centrality %')

        if ax.is_first_col():
            ax.set_ylabel(plot['ylabel'])

        if ax.is_last_col():
            ax.text(
                1.02, .5, plot['title'],
                transform=ax.transAxes, ha='left', va='center',
                size=plt.rcParams['axes.labelsize'], rotation=-90
            )

        ratio_ax.axhline(1, lw=.5, color='0.5', zorder=-100)
        ratio_ax.axhspan(0.9, 1.1, color='0.95', zorder=-200)
        ratio_ax.set_ylim(0.8, 1.2)
        ratio_ax.set_yticks(np.arange(80, 121, 20)/100)
        ratio_ax.set_ylabel('Ratio')

    set_tight(fig, rect=[0, 0, .97, 1])
    """


def format_ci(samples, ci=.9):
    """
    Compute the median and a credible interval for an array of samples and
    return a TeX-formatted string.

    """
    cil, cih = credible_interval(samples, ci=ci)
    median = np.median(samples)
    ul = median - cil
    uh = cih - median

    # decide precision for formatting numbers
    # this is NOT general but it works for the present data
    if abs(median) < .05 or (uh + ul) < abs(median) < .5:
        precision = 3
    elif abs(median) < 5:
        precision = 2
    else:
        precision = 1

    fmt = str(precision).join(['{:#.', 'f}'])

    return ''.join([
        '$', fmt.format(median),
        '_{-', fmt.format(ul), '}',
        '^{+', fmt.format(uh), '}$'
    ])

def _posterior():
    """
    Plot the corner plot of parameter posteriors. Parameters are selected for
    inclusion by index in the indices array.
    """

    chain = Chain()
    labels = chain.labels
    ranges = chain.range

    thin_factor=50 #factor by which we thin chain when loading
    gridsize=25 # a parameter for the kdeplot
    #bw = 0.1
    fontsize = 9
    #indices = np.arange(18) #all
    indices = [1, 2, 3, 4] #the selected parameters to include in the corner plot
    #indices = [2, 3, 4, 5] #the selected parameters to include in the corner plot
    resize_shape = 18 #typically for one system (one normalization) this is 18, for two systems 19, ...

    chain0 = Chain(path=workdir/'mcmc'/'chain-idf-0_LHC_PTEMCEE.hdf')
    #chain0 = Chain(path=workdir/'mcmc'/'chain-idf-0_LHC_RHIC_PTEMCEE.hdf')
    #chain0 = Chain(path=workdir/'mcmc'/'chain-idf-0_LHC_RHIC_diff_nucl_width.hdf')
    data0 = chain0.load_wo_reshape(thin=thin_factor)

    chain1 = Chain(path=workdir/'mcmc'/'chain-idf-0_Xe.hdf')
    #chain1 = Chain(path=workdir/'mcmc'/'chain-idf-1_LHC_RHIC_PTEMCEE.hdf')
    #chain1 = Chain(path=workdir/'mcmc'/'chain-idf-0_LHC_RHIC_PTEMCEE_fix_zero_bulk.hdf')
    data1 = chain1.load_wo_reshape(thin=thin_factor)

    #chain3 = Chain(path=workdir/'mcmc'/'chain-idf-3_LHC_RHIC_PTEMCEE.hdf')
    #data3 = chain3.load_wo_reshape(thin=thin_factor)

    print("before reshaping, ")
    print("data0.shape = " + str(data0.shape))
    print("data1.shape = " + str(data1.shape))
    data0 = data0.reshape(-1, resize_shape).T
    data1 = data1.reshape(-1, resize_shape).T
    #data3 = data3.reshape(-1, resize_shape).T

    print("after reshaping, ")
    print("data0.shape = " + str(data0.shape))
    print("data1.shape = " + str(data1.shape))

    data0 = np.take(data0, indices, axis=0)
    data1 = np.take(data1, indices, axis=0)
    #data3 = np.take(data3, indices, axis=0)

    labels = np.take(labels, indices)
    ranges = np.take(ranges, indices)

    #manual specification of labels if they do not match default chain labels
    #labels = ['$N$[$2.76$TeV]', '$N$[$0.20$TeV]', '$p$', '$\\sigma_k$', '$w$',
    #        '$d_{\\mathrm{min}}^3$', '$\\tau_R$', '$\\alpha$',
    #        '$T_{\\eta}$',
    #        '$a_{\\mathrm{low}}$',
    #        '$a_{\\mathrm{high}}$',
    #        '$(\\eta/s)_{\\mathrm{kink}}$', '$(\\zeta/s)_{\\max}$',
    #        '$T_{\\zeta}$', '$w_{\\zeta}$', '$\\lambda_{\\zeta}$',
    #        '$b_{\\pi}$', '$T_{\\mathrm{sw}}$']

    #labels = [r'$p$', r'$\sigma_k$', r'$w$[2.76 TeV] [fm]', r'$w$[0.2 TeV] [fm]' ]
    labels = [r'$p$', r'$\sigma_k$', r'$w$ [fm]', '$d_{\\mathrm{min}}^3$ [fm$^3$]' ]

    ndims, nsamples = data0.shape
    ranges = np.array([np.min(data0, axis=1), np.max(data0, axis=1)]).T

    #blue and red
    cmap0 = plt.get_cmap('Blues')
    cmap1 = plt.get_cmap('Reds')
    cmap3 = plt.get_cmap('Greens')
    color0='b'
    color1='r'
    color3='g'

    change_colors = True
    #purple and orange
    if change_colors:
        cmap0 = plt.get_cmap('Purples')
        cmap1 = plt.get_cmap('Greys')
        color0 = 'purple'
        color1 = 'grey'

    cmap0.set_bad('white')
    cmap1.set_bad('white')
    cmap3.set_bad('white')

    fig, axes = plt.subplots( nrows=ndims, ncols=ndims,figsize=(.8*ndims, .8*ndims) )

    for i, row in enumerate(axes):
        for j, ax in enumerate(row):
            x0 = data0[j]
            y0 = data0[i]
            x1 = data1[j]
            y1 = data1[i]
            #x3 = data3[j]
            #y3 = data3[i]
            xlabel = labels[j]
            xlim = ranges[j]
            ylabel = labels[i]
            ylim = ranges[i]
            if i==j:
                sns.kdeplot(x0, color=color0, shade=True, ax=ax)
                sns.kdeplot(x1, color=color1, shade=True, ax=ax)
                #sns.kdeplot(x3, color=color3, shade=False, ax=ax)
                stex0 = format_ci(x0)
                stex1 = format_ci(x1)
                ax.annotate(stex0, xy=(0.1, 1.), xycoords="axes fraction", ha='center', va='bottom', fontsize=5, color=color0)
                ax.annotate(stex1, xy=(.9, 1.), xycoords="axes fraction", ha='center', va='bottom', fontsize=5, color=color1)
                ax.set_xlim(*xlim)
                #if i < ndims-1:
                #    ax.axvline(x=truth[i], color='r')
                #ax.set_ylim(0, max(H0.max(), H1.max()))
            if i>j:
                sns.kdeplot(x1, y1, cmap=cmap1, shade=False, ax=ax, n_levels=2, shade_lowest=False, gridsize=gridsize, linewidths=1)
                sns.kdeplot(x0, y0, cmap=cmap0, shade=False, ax=ax, n_levels=2, shade_lowest=False, gridsize=gridsize, linewidths=1)
                #sns.kdeplot(x1, y1, cmap=cmap1, shade=False, ax=ax, n_levels=2, shade_lowest=False, gridsize=gridsize, linewidths=1)
                #sns.kdeplot(x3, y3, cmap=cmap3, shade=False, ax=ax, n_levels=2, shade_lowest=False, gridsize=gridsize, alpha=0.8)
                ax.set_xlim(*xlim)
                ax.set_ylim(*ylim)
            if i<j:
                ax.axis('off')
                #sns.kdeplot(x1, y1, color=color1, shade=True, ax=ax, n_levels=5, shade_lowest=False, gridsize=gridsize)
                #ax.set_xlim(*xlim)
                #ax.set_ylim(*ylim)

            if ax.is_first_col():
                ax.set_ylabel(ylabel, fontsize=fontsize)
            if ax.is_first_col() and i!=0:
                l = ylim[1]-ylim[0]
                ax.set_yticks([ylim[0]+l*.1, ylim[1]-l*.1])
                ax.set_yticklabels(["{:1.2f} ".format(ylim[0]), " {:1.2f}".format(ylim[1])], fontsize=7)
            else:
                ax.set_yticks([])
            if ax.is_last_row():
                ax.set_xlabel(xlabel, fontsize=fontsize)
                l = xlim[1]-xlim[0]
                ax.set_xticks([xlim[0]+l*.1, xlim[1]-l*.1])
                ax.set_xticklabels(["{:1.2f} ".format(xlim[0]),
                                    " {:1.2f}".format(xlim[1])], fontsize=7)
            else:
                ax.set_xticks([])
    fig.align_ylabels()
    set_tight(pad=.0, h_pad=.0, w_pad=.0, rect=(.01, 0, 1, 1))


@plot
def posterior_bayes_model_average():
    """
    Plot the corner plot of parameter posteriors for the bma. Parameters are selected for
    inclusion by index in the indices array.
    """

    chain = Chain()
    labels = chain.labels
    ranges = chain.range

    gridsize=25 # a parameter for the kdeplot
    fontsize = 9
    #indices = np.arange(18) #all
    indices = [1, 2, 3, 4] #the selected parameters to include in the corner plot

    data0 = np.load('mcmc/bma_grad_ce_ptb_chain.npy').T
    print("data0.shape = " + str(data0.shape))
    data0 = np.take(data0, indices, axis=0)

    labels = np.take(labels, indices)
    ranges = np.take(ranges, indices)

    labels = [r'$p$', r'$\sigma_k$', r'$w$ [fm]', '$d_{\\mathrm{min}}^3$ [fm$^3$]' ]

    #manual specification of labels if they do not match default chain labels
    #labels = ['$N$[$2.76$TeV]', '$N$[$0.20$TeV]', '$p$', '$\\sigma_k$', '$w$',
    #        '$d_{\\mathrm{min}}^3$', '$\\tau_R$', '$\\alpha$',
    #        '$T_{\\eta}$',
    #        '$a_{\\mathrm{low}}$',
    #        '$a_{\\mathrm{high}}$',
    #        '$(\\eta/s)_{\\mathrm{kink}}$', '$(\\zeta/s)_{\\max}$',
    #        '$T_{\\zeta}$', '$w_{\\zeta}$', '$\\lambda_{\\zeta}$',
    #        '$b_{\\pi}$', '$T_{\\mathrm{sw}}$']

    ndims, nsamples = data0.shape
    ranges = np.array([np.min(data0, axis=1), np.max(data0, axis=1)]).T

    cmap0 = plt.get_cmap('Oranges')
    cmap0 = truncate_colormap(cmap0, 0.4, 1., 4)
    color0 = cmap0(0.4)
    cmap0.set_bad('white')

    fig, axes = plt.subplots( nrows=ndims, ncols=ndims,figsize=(.8*ndims, .8*ndims) )

    for i, row in enumerate(axes):
        for j, ax in enumerate(row):
            x0 = data0[j]
            y0 = data0[i]
            xlabel = labels[j]
            xlim = ranges[j]
            ylabel = labels[i]
            ylim = ranges[i]
            if i==j:
                sns.kdeplot(x0, color=color0, shade=True, ax=ax)
                stex0 = format_ci(x0)
                ax.annotate(stex0, xy=(0.1, 1.), xycoords="axes fraction", ha='center', va='bottom', fontsize=5, color=color0)
                ax.set_xlim(*xlim)
            if i>j:
                sns.kdeplot(x0, y0, color=color0, shade=True, ax=ax, n_levels=5, shade_lowest=False, gridsize=gridsize)
                ax.set_xlim(*xlim)
                ax.set_ylim(*ylim)
            if i<j:
                ax.axis('off')

            #if ax.is_first_col():
            #    ax.set_ylabel(ylabel, fontsize=fontsize)
            if ax.is_first_col() and i!=0:
                l = ylim[1]-ylim[0]
                ax.set_yticks([ylim[0]+l*.1, ylim[1]-l*.1])
                ax.set_yticklabels(["{:1.2f} ".format(ylim[0]), " {:1.2f}".format(ylim[1])], fontsize=7)
            else:
                ax.set_yticks([])
            if ax.is_last_row():
                ax.set_xlabel(xlabel, fontsize=fontsize)
                l = xlim[1]-xlim[0]
                ax.set_xticks([xlim[0]+l*.1, xlim[1]-l*.1])
                ax.set_xticklabels(["{:1.2f} ".format(xlim[0]),
                                    " {:1.2f}".format(xlim[1])], fontsize=7)
            else:
                ax.set_xticks([])
    fig.align_ylabels()
    set_tight(pad=.0, h_pad=.0, w_pad=.0, rect=(.01, 0, 1, 1))


@plot
def information_gain_w_posterior():
    """
    Make a table/plot which estimates the mutual information (K-L divergence) between two distributions.
    The distributions are approximated by the MCMC samples.
    The information gain  H = /int P(X) log_2( P(X) / pi(X) )
    where P(X) is the posterior, and pi(X) is the prior
    """

    #this sets the number of bins for the samples of the distribution
    #it thereby controls the integration mesh for estimating the mutual information
    nbins=70
    #factor to thin chains
    thin=1

    chain0 = Chain(path=workdir/'mcmc'/'chain-idf-0_RHIC_PTEMCEE.hdf')
    data0 = chain0.load_wo_reshape(thin=thin)
    data0 = data0.reshape(-1, 18).T

    chain1 = Chain(path=workdir/'mcmc'/'chain-idf-0_LHC_RHIC_PTEMCEE.hdf')
    data1 = chain1.load_wo_reshape(thin=thin)
    data1 = data1.reshape(-1, 19).T

    labels = chain1.labels
    ranges = np.array(chain0.range)

    #indices0 = [1, 2, 3, 4, 5, 6, 16] # TRENTo, FS and T_sw
    #indices1 = [2, 3, 4, 5, 6, 7, 17] # TRENTo, FS and T_sw

    indices0 = np.arange(1, 17)
    indices1 = np.arange(2, 18)

    data0 = np.take(data0, indices0, axis=0)
    data1 = np.take(data1, indices1, axis=0)

    labels = np.take(labels, indices1)
    ranges = np.take(ranges, indices1, axis=0)

    ndims, nsamples = data0.shape

    fig, axes = plt.subplots( nrows=ndims, ncols=ndims, figsize=(1.*ndims, 1.*ndims) )

    cmap0 = plt.get_cmap('Purples')
    cmap1 = plt.get_cmap('Oranges')
    color0 = 'purple'
    color1 = 'orange'
    cmap0.set_bad('white')
    cmap1.set_bad('white')

    for i, row in enumerate(axes):
        for j, ax in enumerate(row):
            x0 = data0[j]
            y0 = data0[i]
            x1 = data1[j]
            y1 = data1[i]
            xlabel = labels[j]
            ylabel = labels[i]
            if i==j:
                H0, bins, _ = ax.hist(x0, bins=nbins, histtype='step', range=ranges[i, :], normed=True, color=color0)
                H1, _, _ = ax.hist(x1, bins=nbins, histtype='step', range=ranges[i, :], normed=True, color=color1)
                sns.kdeplot(x0, color=color0, shade=True, ax=ax)
                sns.kdeplot(x1, color=color1, shade=True, ax=ax)

                bin_width = bins[1] - bins[0]
                info = calculate_information_gain(H0, H1, bin_width)
                info = "{:.1e}".format(info)
                info_str = "IG = " + info
                ax.annotate(info_str, xy=(0.5, 0.9), xycoords="axes fraction", ha='center', va='bottom', fontsize=4, weight='bold')
                ax.set_ylim(0, max( H0.max()*1.2, H1.max()*1.2 ))
            if i>j:
                H0, xbins, ybins, _ = ax.hist2d(x0, y0, bins=nbins, range=[ ranges[j, :], ranges[i,:] ], alpha=1.0, zorder=1, cmap=cmap0)

            if i<j:
                #ax.set_visible(False)
                H0, xbins, ybins, _ = ax.hist2d(x0, y0, bins=nbins, range=[ ranges[j, :], ranges[i,:] ], alpha=0., zorder=1, cmap=cmap0)
                H1, xbins, ybins, _ = ax.hist2d(x1, y1, bins=nbins, range=[ ranges[j, :], ranges[i,:] ], alpha=1.0, zorder=1, cmap=cmap1)
                dx = xbins[1] - xbins[0]
                dy = ybins[1] - ybins[0]
                bin_width = [dx, dy]
                info = calculate_information_gain(H0, H1, bin_width)
                info = "{:.1e}".format(info)
                info_str = "IG = " + info
                ax.annotate(info_str, xy=(0.5, 0.9), xycoords="axes fraction", ha='center', va='bottom', fontsize=4, weight='bold')

            if ax.is_first_col():
                ax.set_ylabel(ylabel, fontsize=5)
            if ax.is_first_col() and i!=0:
                pass
            else:
                ax.set_yticks([])

            if ax.is_last_row():
                ax.set_xlabel(xlabel, fontsize=5)
            else:
                ax.set_xticks([])

            plt.subplots_adjust(wspace=0., hspace=0.)

            for tick in ax.xaxis.get_major_ticks():
                tick.label.set_fontsize(5)
            for tick in ax.yaxis.get_major_ticks():
                tick.label.set_fontsize(5)


    fig.align_ylabels()
    set_tight(pad=.0, h_pad=.0, w_pad=.0, rect=(.01, 0, 1, 1))

@plot
def information_gain_observable_sensitivity():
    """
    For each pair of parameter and observable, compute the KL Div
    between the marginal posterior of the parameter which includes
    the observable in the likelihood, vs the marginal posterior of
    parameter which excludes the observable (relative information of inclusion).
    The information gain  H = /int P(X) log_2( P(X) / pi(X) )
    where P(X) is the posterior, and pi(X) is the prior.
    """

    #this sets the number of bins for the samples of the distribution
    #it thereby controls the integration mesh for estimating the mutual information
    nbins=50
    #factor to thin chains
    thin_fac=1

    obs_omit_list = ['dNch_deta', 'dET_deta', 'dN_dy_pion', 'dN_dy_proton',
                    'mean_pT_pion', 'mean_pT_proton', 'pT_fluct',
                    'v22', 'v32', 'v42']

    #obs_plot_list = ['dNch_deta', 'dN_dy_pion', 'dN_dy_proton', 'mean_pT_pion', 'mean_pT_proton', 'v22']
    obs_plot_list = obs_omit_list

    labels = [r'$D_{\rm KL}[N]$', r'$D_{\rm KL}[p]$', r'$D_{\rm KL}[\sigma_k]$', r'$D_{\rm KL}[w]$',
    r'$D_{\rm KL}[d_{\mathrm{min}}^3]$', r'$D_{\rm KL}[\tau_R]$', r'$D_{\rm KL}[\alpha]$',
    r'$D_{\rm KL}[T_{\eta,\mathrm{kink}}]$',
    r'$D_{\rm KL}[a_{\eta,\mathrm{low}}]$', r'$D_{\rm KL}[a_{\eta,\mathrm{high}}]$', r'$D_{\rm KL}[(\eta/s)_{\mathrm{kink}}]$',
    r'$D_{\rm KL}[(\zeta/s)_{\max}]$', r'$D_{\rm KL}[T_{\zeta,c}]$',
    r'$D_{\rm KL}[w_{\zeta}]$', r'$D_{\rm KL}[\lambda_{\zeta}]$', r'$D_{\rm KL}[b_{\pi}]$', r'$D_{\rm KL}[T_{\mathrm{sw}}]$',
    r'$D_{\rm KL}[\sigma_M]$']

    obs_labels = [obs_tex_labels_2[obs] for obs in obs_plot_list]
    obs_indx = np.arange(len(obs_labels))
    width=0.3

    indices = np.arange(17)
    n_params = len(indices)

    chain_all = Chain(path=workdir/'mcmc'/'chain-idf-0_LHC_PTEMCEE.hdf')
    data_all = chain_all.load_wo_reshape(thin=thin_fac)
    data_all = data_all.reshape(-1, 18).T
    data_all = np.take(data_all, indices, axis=0)

    chains_by_obs = []
    data_by_obs = []
    for ichain, obs in enumerate(obs_omit_list):
        chain = Chain(path=workdir/'mcmc_by_obs'/'mcmc_{}'.format(ichain)/'chain-idf-0.hdf')
        chains_by_obs.append(chain)
        data = chain.load_wo_reshape(thin=thin_fac)
        data = data.reshape(-1, 18).T
        data = np.take(data, indices, axis=0)
        data_by_obs.append(data)
    data_by_obs = np.array(data_by_obs)

    fig, axes = plt.subplots(nrows=17, ncols=1, figsize=(7,13), sharex=True)
    for ip in range(n_params):
        x = data_all[ip, :]
        info_by_obs = []
        for iobs, obs in enumerate(obs_omit_list):
            x_omit = data_by_obs[iobs, ip, :]

            H0, bins,  = np.histogram(x_omit, bins=nbins, density=True)
            H1, _ = np.histogram(x, bins=bins, density=True)
            bin_width = bins[1] - bins[0]
            info = calculate_information_gain(H0, H1, bin_width)
            if obs in obs_plot_list:
                info_by_obs.append(info)

            #print("omitting obs " + obs)
            #plt.hist(x, color='b', bins=nbins, alpha=0.5, normed=True, label='Data')
            #plt.hist(x_omit, color='r', bins=nbins, alpha=0.5, normed=True, label='Data w/o ' + obs)
            #plt.xlabel(r'$N$')
            #plt.legend()
            #plt.show()

        axes[ip].bar(obs_indx, info_by_obs, yerr = 0, width=width, #bottom=None,
                align='center', facecolor='b', edgecolor='b')
        axes[ip].set_ylabel(labels[ip], fontsize=7)
        #axes[row].spines['bottom'].set_position('zero')
        for tick in axes[ip].yaxis.get_major_ticks():
            tick.label.set_fontsize(7)
        axes[ip].tick_params(axis='x', pad=15)
        axes[ip].axes.set_xticks(obs_indx)
        axes[ip].axes.set_xticklabels( obs_labels )


    fig.align_ylabels()

def _posterior_diag():

    """
    Plots histograms of the 1d marginal distributions of model parameters,
    given by MCMC chain. If doing validation (closure test), also plots the true values.
    """

    chain = Chain()

    if validation:
        truths = []
        #get VALIDATION points
        for s in system_strs:
            v_design, _, _, _ = \
                load_design(s, pset='validation')
            truths.append(v_design.values[validation_pt,0])
        truths = truths + list(v_design.values[validation_pt,1:]) + [-1]


        labels = chain.labels
        ranges = chain.range
        data = chain.load().T
        ndims, nsamples = data.shape


        cmap = plt.get_cmap('Blues')
        cmap.set_bad('white')

        fig, axes = plt.subplots(nrows=4, ncols=5, figsize=(8, 6) )
        fig.suptitle("Parameters Posterior : " + idf_label[idf] + " Visc. Correction ")

        for ax, x, xlabel, xlim, truth in zip(axes.flatten(), data, labels, ranges, truths):

                H, _, _ = ax.hist(x, bins=21, histtype='step', density=True)

                stex = format_ci(x)
                ax.annotate(stex, xy=(.75, .8), xycoords="axes fraction", ha='center', va='bottom', fontsize=6)
                ax.set_xlim(*xlim)
                ax.axvline(x=truth, color='r')
                ax.set_ylim(0, H.max()*1.25)
                ax.set_yticks([])

                ax.annotate(xlabel, xy=(.25, .8), xycoords="axes fraction", ha='center', va='bottom', fontsize=6)
                l = xlim[1]-xlim[0]
                ax.set_xticks([xlim[0]+l*.05, (xlim[0]+xlim[1])/2., xlim[1]-l*.05])
                ax.set_xticklabels(["{:1.2f} ".format(xlim[0]),
                                    "{:1.2f} ".format((xlim[0]+xlim[1])/2.),
                                    " {:1.2f}".format(xlim[1])], fontsize=6)

                plt.subplots_adjust(wspace=0.05, hspace=0.1)
        plt.tight_layout(True)
        set_tight(fig, rect=[0, 0, 1, .9])

    else :
        labels = chain.labels
        ranges = chain.range
        data = chain.load().T
        ndims, nsamples = data.shape
        ranges = np.array([np.min(data, axis=1), np.max(data, axis=1)]).T

        cmap = plt.get_cmap('Blues')
        cmap.set_bad('white')

        fig, axes = plt.subplots(nrows=4, ncols=5, figsize=(6, 4.5) )

        for ax, x, xlabel, xlim in zip(axes.flatten(), data, labels, ranges):

                H, _, _ = ax.hist(x, bins=21, histtype='step', density=True)

                stex = format_ci(x)
                ax.annotate(stex, xy=(.75, .8), xycoords="axes fraction", ha='center', va='bottom', fontsize=6)
                ax.set_xlim(*xlim)
                ax.set_ylim(0, H.max()*1.25)
                ax.set_yticks([])
                ax.annotate(xlabel, xy=(.25, .8), xycoords="axes fraction", ha='center', va='bottom', fontsize=6)
                l = xlim[1]-xlim[0]
                ax.set_xticks([xlim[0]+l*.05, (xlim[0]+xlim[1])/2., xlim[1]-l*.05])
                ax.set_xticklabels(["{:1.2f} ".format(xlim[0]),
                                    "{:1.2f} ".format((xlim[0]+xlim[1])/2.),
                                    " {:1.2f}".format(xlim[1])], fontsize=6)

                plt.subplots_adjust(wspace=0.05, hspace=0.1)
        set_tight(pad=.0, h_pad=.1, w_pad=.05, rect=(.01, 0, 1, 1))

@plot
def observables_sensitivity():

    """
    Plots linear Sensitivity index of model observables to model parameters.

    """
    labels = [r'$S[N]$', r'$S[p]$', r'$S[\sigma_k]$', r'$S[w]$', r'$S[d_{\mathrm{min}}^3]$', r'$S[\tau_R]$', r'$S[\alpha]$', r'$S[T_{\eta}]$',
    r'$S[a_{\mathrm{low}}]$', r'$S[a_{\mathrm{high}}]$', r'$S[(\eta/s)_{\mathrm{kink}}]$', r'$S[(\zeta/s)_{\max}]$', r'$S[T_{\zeta}]$',
    r'$S[w_{\zeta}]$', r'$S[\lambda_{\zeta}]$', r'$S[b_{\pi}]$', r'$S[T_{\mathrm{sw}}]$', r'$S[\sigma_M]$']

    obs_names = ['dNch_deta', 'dN_dy_pion', 'dN_dy_proton', 'mean_pT_pion', 'mean_pT_proton', 'v22', 'v32', 'v42', 'pT_fluct']
    obs_labels = [obs_tex_labels_2[obs] for obs in obs_names]
    obs_indx = np.arange(len(obs_labels))

    use_central_bins = False
    if use_central_bins:
        cent_bin = 0 #0-5%
        cent_pT_fl = 0 #0-5%
    else:
        cent_bin = 5 #40-50%
        cent_pT_fl = 8 #40-45%

    cent_bin_label = {0 : '0-5%', 5: '40-50%'}
    width = 0.2

    fig, axes = plt.subplots(nrows=17, ncols=1, figsize=(6,13), sharex=True)
    plt.suptitle("Sensitivity Indices at Mean Parameters : " + cent_bin_label[cent_bin] + " Cent.")
    #load the emulator
    for system in system_strs:
        emu0 = dill.load(open('emulator/emulator-' + 'Pb-Pb-2760' + '-idf-0.dill', "rb"))
        emu1 = dill.load(open('emulator/emulator-' + 'Pb-Pb-2760' + '-idf-1.dill', "rb"))
        emu3 = dill.load(open('emulator/emulator-' + 'Pb-Pb-2760' + '-idf-3.dill', "rb"))

        map_params0 = np.array( MAP_params[system]['Grad'] )
        map_params1 = np.array( MAP_params[system]['C.E.'] )
        map_params3 = np.array( MAP_params[system]['P.B.'] )

        all_params = np.column_stack( (map_params0, map_params1, map_params3) )
        mean_params = np.mean(all_params, axis=1)

        #evaluate all three df at the same set of params
        print("Evaluating model (emulators) at the average of the MAP parameters : ")
        print(labels)
        print(" = ")
        print(mean_params)
        params0 = mean_params
        params1 = mean_params
        params3 = mean_params

        #evaluate each df at the same parameters
        per_diff_params = 0.1
        for row, p in enumerate(params0):

            #10% variation
            d = np.zeros_like(params0)
            d[row] += per_diff_params
            diff_params0 = params0 + (d * params0)
            diff_params1 = params1 + (d * params1)
            diff_params3 = params3 + (d * params3)

            Yemu_mean0, Yemu_cov0 = emu0.predict( np.array( [params0] ), return_cov=True )
            Yemu_mean_diff0, Yemu_cov_diff0 = emu0.predict( np.array( [diff_params0] ), return_cov=True )
            obs0 = np.array([ Yemu_mean0[obs][0][cent_pT_fl if obs == 'pT_fluct' else cent_bin] for obs in obs_names])
            obs0_err = np.array( [ ( np.abs( Yemu_cov0[obs, obs][0][cent_pT_fl if obs == 'pT_fluct' else cent_bin][cent_pT_fl if obs == 'pT_fluct' else cent_bin] ) )**.5 for obs in obs_names] )
            diff_obs0 = np.array([ Yemu_mean_diff0[obs][0][cent_pT_fl if obs == 'pT_fluct' else cent_bin] for obs in obs_names])
            diff_obs0_err = np.array( [ ( np.abs( Yemu_cov_diff0[obs, obs][0][cent_pT_fl if obs == 'pT_fluct' else cent_bin][cent_pT_fl if obs == 'pT_fluct' else cent_bin] ) )**.5 for obs in obs_names] )
            per_diff_obs0 = (diff_obs0 - obs0) / obs0
            yerr = ( (obs0 * diff_obs0_err) + (diff_obs0 * obs0_err) ) / (obs0**2.)
            axes[row].bar(obs_indx - width, per_diff_obs0 / d[row], yerr = 0, width=width, bottom=None, align='center',
                            facecolor='b', edgecolor='b')

            Yemu_mean1, Yemu_cov1 = emu1.predict( np.array( [params1] ), return_cov=True )
            Yemu_mean_diff1, Yemu_cov_diff1 = emu1.predict( np.array( [diff_params1] ), return_cov=True )
            obs1 = np.array([ Yemu_mean1[obs_name][0][cent_pT_fl if obs_name == 'pT_fluct' else cent_bin] for obs_name in obs_names])
            diff_obs1 = np.array([ Yemu_mean_diff1[obs_name][0][cent_pT_fl if obs_name == 'pT_fluct' else cent_bin] for obs_name in obs_names])
            per_diff_obs1 = (diff_obs1 - obs1) / obs1
            axes[row].bar(obs_indx, per_diff_obs1 / per_diff_params, yerr = 0, width=width, bottom=None, align='center',
                            facecolor='r', edgecolor='r')

            Yemu_mean3, Yemu_cov3 = emu3.predict( np.array( [params3] ), return_cov=True )
            Yemu_mean_diff3, Yemu_cov_diff3 = emu3.predict( np.array( [diff_params3] ), return_cov=True )
            obs3 = np.array([ Yemu_mean3[obs_name][0][cent_pT_fl if obs_name == 'pT_fluct' else cent_bin] for obs_name in obs_names])
            diff_obs3 = np.array([ Yemu_mean_diff3[obs_name][0][cent_pT_fl if obs_name == 'pT_fluct' else cent_bin] for obs_name in obs_names])
            per_diff_obs3 = (diff_obs3 - obs3) / obs3
            axes[row].bar(obs_indx + width, per_diff_obs3 / per_diff_params, yerr = 0, width=width, bottom=None, align='center',
                            facecolor='g', edgecolor='g')

            max_height0 = np.max( np.abs( per_diff_obs0 / per_diff_params ) )
            max_height1 = np.max( np.abs( per_diff_obs1 / per_diff_params) )
            max_height3 = np.max( np.abs( per_diff_obs3 / per_diff_params) )
            max_height = np.max([max_height0, max_height1])
            max_height = np.max([max_height, max_height3])

            axes[row].set_ylabel(labels[row])
            axes[row].spines['bottom'].set_position('zero')
            axes[row].set_ylim(-1.1 * max_height, 1.1 * max_height)
            for tick in axes[row].yaxis.get_major_ticks():
                tick.label.set_fontsize(7)
            axes[row].tick_params(axis='x', pad=15)
            axes[row].axes.set_xticks(obs_indx)
            axes[row].axes.set_xticklabels( obs_labels )

    fig.align_ylabels(axes)
    plt.tight_layout(True)
    set_tight(fig, rect=[0, 0, 1, .96])


@plot
def observables_sobol_sensitivity():

    """
    Plots Sobol Sensitivity index of model observables to model parameters.
    (See https://journals.plos.org/plosone/article/file?type=supplementary&id=info:doi/10.1371/journal.pone.0095610.s003)

    """

    include_emu_uncert = False

    sns.set()
    labels = [r'$N$', r'$p$', r'$\sigma_k$', r'$w$', r'$d_{\mathrm{min}}^3$', r'$\tau_R$', r'$\alpha$', r'$T_{\eta,\mathrm{kink}}$',
    r'$a_{\eta,\mathrm{low}}$', r'$a_{\eta,\mathrm{high}}$', r'$(\eta/s)_{\mathrm{kink}}$', r'$(\zeta/s)_{\max}$', r'$T_{\zeta,c}$',
    r'$w_{\zeta}$', r'$\lambda_{\zeta}$', r'$b_{\pi}$', r'$T_{\mathrm{sw}}$']
    label_indx = np.arange(len(labels))

    n_samples = int(3e3) # the number of samples pf param. space should be large enough that result has converged
    n_samples_emu = int(1e0) # the number of samples of emu. pred. distribution should be large enough that result has converged
    do_parallel = False
    n_proc = 10 if do_parallel else None

    obs_names = [ 'dET_deta' , 'dNch_deta', 'dN_dy_pion', 'dN_dy_proton', 'mean_pT_pion', 'mean_pT_proton', 'v22', 'v32', 'v42', 'pT_fluct']
    obs_labels = [obs_tex_labels_2[obs] for obs in obs_names]
    obs_indx = np.arange(len(obs_labels))

    system = 'Pb-Pb-2760'
    design, design_min, design_max, design_labels = load_design(system)

    #load the emulator(s)
    emu0 = dill.load(open('emulator/emulator-' + 'Pb-Pb-2760' + '-idf-0.dill', "rb"))
    emu1 = dill.load(open('emulator/emulator-' + 'Pb-Pb-2760' + '-idf-1.dill', "rb"))
    emu3 = dill.load(open('emulator/emulator-' + 'Pb-Pb-2760' + '-idf-3.dill', "rb"))

    choose_central_bin = False
    if choose_central_bin:
        cent_bin = 0 #0-5%
        cent_pT_fl = 0 #0-5%
    else:
        cent_bin = 5 #40-50%
        cent_pT_fl = 8 #40-45%

    cent_bin_label = {0 : '0-5%', 5: '40-50%'}
    width = 0.2

    n_params = design.shape[1]
    fig, axes = plt.subplots(nrows=len(obs_names), ncols=1, figsize=(12,7), sharex=True)

    ########## USE SALib ##########
    # following https://salib.readthedocs.io/en/latest/getting-started.html

    # Define the model inputs
    bounds = np.column_stack( (design_min, design_max) )
    #print("bounds = " + str(bounds))
    problem = {
                'num_vars': n_params,
                'names': labels,
                'bounds': bounds
                }
    # Generate samples
    print("Generating " + str(n_samples) + " parameter samples")
    param_values = saltelli.sample(problem, n_samples)

    #run model
    print("Evaluating model outputs")

    if include_emu_uncert:
        #sample from emu. distribution with pred. uncertainty
        Yemu_mean0 = emu0.sample_y(param_values, n_samples=n_samples_emu)
        Yemu_mean1 = emu1.sample_y(param_values, n_samples=n_samples_emu)
        Yemu_mean3 = emu3.sample_y(param_values, n_samples=n_samples_emu)

    else:
        #use the emulator mean with no pred. uncertainty
        Yemu_mean0 = emu0.predict( param_values, return_cov=False )
        Yemu_mean1 = emu1.predict( param_values, return_cov=False )
        Yemu_mean3 = emu3.predict( param_values, return_cov=False )

    print("Calculating Sobol Indices and plotting")
    for row, obs in enumerate(obs_names):
        Y0 = Yemu_mean0[obs][:, cent_pT_fl if obs == 'pT_fluct' else cent_bin]
        Y1 = Yemu_mean1[obs][:, cent_pT_fl if obs == 'pT_fluct' else cent_bin]
        Y3 = Yemu_mean3[obs][:, cent_pT_fl if obs == 'pT_fluct' else cent_bin]

        Si_0 = sobol.analyze(problem, Y0, parallel=do_parallel, n_processors=n_proc, print_to_console=False)
        Si_1 = sobol.analyze(problem, Y1, parallel=do_parallel, n_processors=n_proc, print_to_console=False)
        Si_3 = sobol.analyze(problem, Y3, parallel=do_parallel, n_processors=n_proc, print_to_console=False)

        #first order sensitivity index and confidence 95% confidence intervals
        s1_0 = Si_0['S1']
        ds1_0 = Si_0['S1_conf']

        s1_1 = Si_1['S1']
        ds1_1 = Si_1['S1_conf']

        s1_3 = Si_3['S1']
        ds1_3 = Si_3['S1_conf']

        axes[row].bar(label_indx - width, s1_0, yerr = ds1_0, width=width, bottom=None, align='center',
                            facecolor='b', edgecolor='b')
        axes[row].bar(label_indx, s1_1, yerr = ds1_1, width=width, bottom=None, align='center',
                            facecolor='r', edgecolor='r')
        axes[row].bar(label_indx + width, s1_3, yerr = ds1_3, width=width, bottom=None, align='center',
                            facecolor='g', edgecolor='g')

        axes[row].set_ylabel(obs_labels[row])
        axes[row].spines['bottom'].set_position('zero')
        #axes[row].set_ylim(-1.1 * max_height, 1.1 * max_height)
        for tick in axes[row].yaxis.get_major_ticks():
            tick.label.set_fontsize(10)
        #axes[row].tick_params(axis='x', pad=15)
        axes[row].axes.set_xticks(label_indx)
        axes[row].axes.set_xticklabels(labels)

    fig.align_ylabels(axes)
    plt.tight_layout(True)


@plot
def posterior():
    _posterior()

@plot
def diag_posterior():
    _posterior_diag()


@plot
def posterior_shear():
    _posterior(
        scale=1.35, pad_subplots=.1, rect_t=.97,
        params={'etas_min', 'etas_slope', 'etas_crv'}
    )

def _region(ax, name, cmap=plt.cm.Blues, legend=False, title=False):
    """
    Visual estimate (posterior median and credible region) of
    temperature-dependent shear or bulk viscosity. (Deprecated - needs update)

    """
    var, keys, function, ymax = dict(
        shear=(
            'eta',
            ['min', 'slope', 'crv'],
            lambda T, m, s, c: m + s*(T - Tc)*(T/Tc)**c,
            .4
        ),
        bulk=(
            'zeta',
            ['max', 'width', 't0'],
            lambda T, m, w, T0: m / (1 + ((T - T0)/w)**2),
            .08
        ),
    )[name]

    Tmin, Tmax = .150, .300
    Tc = .154

    samples = mcmc.Chain().load(*['{}s_{}'.format(var, k) for k in keys])

    T = np.linspace(Tc if name == 'shear' else Tmin, Tmax, 1000)
    ax.plot(
        T, function(T, *np.median(samples, axis=0)),
        color=cmap(.75), label='Posterior median'
    )

    Tsparse = np.linspace(T[0], T[-1], 25)
    intervals = [
        PchipInterpolator(Tsparse, y)(T)
        for y in np.array([
            mcmc.credible_interval(function(t, *samples.T))
            for t in Tsparse
        ]).T
    ]
    ax.fill_between(
        T, *intervals,
        color=cmap(.3), label='90% credible region'
    )

    ax.set_xlim(Tmin, Tmax)
    ax.set_ylim(0, ymax)
    auto_ticks(ax, nbins=5)
    ax.xaxis.set_major_formatter(
        ticker.FuncFormatter(lambda x, pos: int(1000*x))
    )

    ax.set_xlabel('Temperature [MeV]')
    ax.set_ylabel(r'$\{}/s$'.format(var))

    if title:
        ax.set_title(name.capitalize() + ' viscosity')
    if legend:
        ax.legend(loc=legend if isinstance(legend, str) else 'best')
    if name == 'shear':
        ax.axhline(
            1/(4*np.pi),
            color='.5', linewidth=plt.rcParams['ytick.major.width']
        )
        ax.text(Tmax, .07, r'$1/4\pi$', va='top', ha='right', color='.3')


@plot
def region_shear():
    """
    Region plot for eta/s. (Deprecated - needs update)

    """
    fig, ax = plt.subplots(figsize=figsize(.65))
    _region(ax, 'shear', legend='upper left')


@plot
def eta_and_zeta_functions():
    """
    Plot eta/s and zeta/s as functions of Temperature for some choices of parameters.

    """
    Tmax = 0.4
    T = np.linspace(0.1, Tmax, 500)
    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(6,3))

    #values chosen for visualization
    #zmax = 0.0625
    #T0 = 0.15
    #width = 0.050
    #asym = 0.9

    #T_k = 0.25
    #alow = 1.0
    #ahigh = 0.3
    #etas_k = 0.125

    #values of old Grad MAP values
    zmax = 0.13
    T0 = 0.12
    width = 0.072
    asym = -0.12

    T_k = 0.223
    alow = -0.78
    ahigh = 0.37
    etas_k = 0.096

    zeta_s = zeta_over_s(T, zmax, T0, width, asym)
    axes[0].plot(T, zeta_s, color='black', lw=2)

    eta_s = eta_over_s(T, T_k, alow, ahigh, etas_k)
    axes[1].plot(T, eta_s, color='black', lw=2)

    axes[0].set_xlabel(r'$T$ [GeV]')
    axes[0].set_ylabel(r'$\zeta/s$')
    axes[1].set_xlabel(r'$T$ [GeV]')
    axes[1].set_ylabel(r'$\eta/s$')

    axes[0].set_xlim(0.1, Tmax)
    axes[0].set_ylim(0., 0.3)
    axes[1].set_xlim(0.1, Tmax)
    axes[1].set_ylim(0., 0.3)

    axes[0].locator_params(axis='y', nbins=4)
    axes[1].locator_params(axis='y', nbins=4)

    plt.suptitle('JS SIMS Preliminary : MAP Viscosities')
    plt.tight_layout(True)
    set_tight(pad=.0, h_pad=.0, w_pad=.0, rect=(0, 0, 1, 0.9))


@plot
def design():
    """
    Projection of a Latin Hypercube design into two dimensions. (Deprecated - needs update)

    """
    fig = plt.figure(figsize=figsize(.6, aspect=1))
    ratio = 5
    gs = plt.GridSpec(ratio + 1, ratio + 1)

    ax_j = fig.add_subplot(gs[1:, :-1])
    ax_x = fig.add_subplot(gs[0, :-1], sharex=ax_j)
    ax_y = fig.add_subplot(gs[1:, -1], sharey=ax_j)

    d = Design(systems[0])

    keys = ('etas_min', 'etas_slope')
    indices = tuple(d.keys.index(k) for k in keys)

    x, y = (d.array[:, i] for i in indices)
    ax_j.plot(x, y, 'o', color=plt.cm.Blues(0.75), mec='white', mew=.3)

    hist_kw = dict(bins=30, color=plt.cm.Blues(0.4), edgecolor='white', lw=.5)
    ax_x.hist(x, **hist_kw)
    ax_y.hist(y, orientation='horizontal', **hist_kw)

    for ax in fig.axes:
        spines = ['top', 'right']
        if ax is ax_x:
            spines += ['left']
        elif ax is ax_y:
            spines += ['bottom']
        for spine in spines:
            ax.spines[spine].set_visible(False)

    auto_ticks(ax_j, nbins=4)

    for ax in ax_x, ax_y:
        ax.tick_params(
            bottom=False, left=False,
            labelbottom=False, labelleft=False
        )

    for i, xy in zip(indices, 'xy'):
        for f, l in [('lim', d.range), ('label', d.labels)]:
            getattr(ax_j, 'set_{}{}'.format(xy, f))(l[i])


@plot
def gp():
    """
    Conditioning a Gaussian process.

    """
    fig, axes = plt.subplots(
        figsize=figsize(.6, aspect=1.35),
        nrows=2, sharex='col'
    )

    gp = GPR(1.*kernels.RBF(.8), optimizer=None)

    x = np.linspace(0, 5, 1000)
    X = x[:, np.newaxis]

    x_train = np.linspace(.5, 4.5, 4)
    X_train = x_train[:, np.newaxis]

    for title, ax in zip(['Random functions', 'Conditioned on data'], axes):
        if title.startswith('Conditioned'):
            y = gp.sample_y(X_train, random_state=23158).squeeze()
            y -= .5*(y.max() + y.min())
            gp.fit(X_train, y)
            training_data, = plt.plot(
                x_train, y, 'o',
                markersize=1.4*plt.rcParams['lines.markersize'],
                color='.3', zorder=50
            )

        for s, c in zip(
                gp.sample_y(X, n_samples=4, random_state=34576).T,
                ['Blues', 'Greens', 'Oranges', 'Purples']
        ):
            ax.plot(x, s, color=getattr(plt.cm, c)(.6))

        mean, std = gp.predict(X, return_std=True)
        std = ax.fill_between(x, mean - std, mean + std, color='.92')
        mean, = ax.plot(x, mean, color='.42', linestyle='dashed')

        ax.set_xlim(x[0], x[-1])
        ax.set_ylim(-2, 2)
        ax.set_ylabel('Output')
        auto_ticks(ax, nbins=5)

        ax.set_title(title, y=.9)

    ax.set_xlabel('Input')
    ax.legend(*zip(*[
        (mean, 'Mean prediction'),
        (std, 'Uncertainty'),
        (training_data, 'Training data'),
    ]), loc='lower left')

    set_tight(fig, h_pad=1)


@plot
def pca():
    """
    (Deprecated - needs update)
    """
    fig = plt.figure(figsize=figsize(.6, aspect=1))
    ratio = 5
    gs = plt.GridSpec(ratio + 1, ratio + 1)

    ax_j = fig.add_subplot(gs[1:, :-1])
    ax_x = fig.add_subplot(gs[0, :-1], sharex=ax_j)
    ax_y = fig.add_subplot(gs[1:, -1], sharey=ax_j)

    x, y = (
        model.data['PbPb2760'][obs][subobs]['Y'][:, 3]
        for obs, subobs in [('dN_dy', 'pion'), ('vnk', (2, 2))]
    )
    xlabel = r'$dN_{\pi^\pm}/dy$'
    ylabel = r'$v_2\{2\}$'
    xlim = 0, 1400
    ylim = 0, 0.15

    cmap = plt.cm.Blues

    ax_j.plot(x, y, 'o', color=cmap(.75), mec='white', mew=.25, zorder=10)

    for d, ax, orientation in [(x, ax_x, 'vertical'), (y, ax_y, 'horizontal')]:
        ax.hist(
            d, bins=20,
            orientation=orientation, color=cmap(.4), edgecolor='white'
        )

    xy = np.column_stack([x, y])
    xymean = xy.mean(axis=0)
    xystd = xy.std(axis=0)
    xy -= xymean
    xy /= xystd
    pca = PCA().fit(xy)
    pc = (
        6 * xystd *
        pca.explained_variance_ratio_[:, np.newaxis] *
        pca.components_
    )

    for w, p in zip(pca.explained_variance_ratio_, pc):
        if np.all(p < 0):
            p *= -1
        ax_j.annotate(
            '', xymean + p, xymean, zorder=20,
            arrowprops=dict(
                arrowstyle='->', shrinkA=0, shrinkB=0,
                color=offblack, lw=.7
            )
        )
        ax_j.text(
            *(xymean + p + (.8, .002)*np.sign(p)), s='{:.0f}%'.format(100*w),
            color=offblack, ha='center', va='top' if p[1] < 0 else 'bottom',
            zorder=20
        )

    for ax in fig.axes:
        spines = ['top', 'right']
        if ax is ax_x:
            spines += ['left']
        elif ax is ax_y:
            spines += ['bottom']
        for spine in spines:
            ax.spines[spine].set_visible(False)

    for ax in ax_x, ax_y:
        ax.tick_params(
            bottom=False, left=False,
            labelbottom=False, labelleft=False
        )

    auto_ticks(ax_j, nbins=5, prune='upper')

    ax_j.set_xlim(xlim)
    ax_j.set_ylim(ylim)

    ax_j.set_xlabel(xlabel)
    ax_j.set_ylabel(ylabel)

    set_tight(pad=.1, h_pad=.3, w_pad=.3)


@plot
def pca_vectors_variance(system='PbPb2760'):
    """
    PCA vectors and explained variance. (Deprecated - needs update)

    """
    fig, axes = plt.subplots(
        figsize=figsize(1.2, aspect=.4),
        ncols=2, gridspec_kw=dict(width_ratios=[5, 1])
    )

    emu = Trained_Emulators[system]
    pca = emu.pca

    ax = axes[0]

    for n, (pc, var) in enumerate(zip(
            pca.components_[:3], pca.explained_variance_ratio_
    ), start=1):
        ax.plot(pc, 'o', label='PC {} ({:.0f}%)'.format(n, 100*var))

    ax.axhline(
        0,
        color='.5', linewidth=plt.rcParams['ytick.major.width'],
        zorder=-100
    )

    x = -.5
    ticks = []
    ticklabels = []

    for obs, subobslist in emu.observables:
        for subobs in subobslist:
            i = model.data[system][obs][subobs]['Y'].shape[1]
            ticks.append(x + .5*i)
            ticklabels.append(obs_label(obs, subobs))
            x += i

    ax.set_xticks(ticks)
    ax.set_xticklabels(ticklabels)
    ax.tick_params(
        'x',
        bottom=False, labelbottom=False,
        labeltop=True, pad=1
    )
    for t in ax.get_xticklabels():
        t.set_verticalalignment('baseline')

    ax.set_ylim(-.1, .3)
    ax.set_ylabel('PCA coefficient', labelpad=1)
    auto_ticks(ax, 'y', nbins=4, minor=2)
    ax.legend(loc='upper left', handletextpad=0)

    ax = axes[1]

    npc = 10
    ax.plot(
        np.arange(1, 1 + npc),
        pca.explained_variance_ratio_.cumsum()[:npc],
        '-o',
    )

    ax.set_xlim(.5, npc + .5)
    ax.set_ylim(0, 1)

    majorticks = [1, 4, 7, 10]
    ax.set_xticks(majorticks)
    ax.set_xticks(sorted(set(range(1, npc)) - set(majorticks)), minor=True)
    auto_ticks(ax, 'y', nbins=5, minor=2)
    ax.xaxis.set_ticks_position('top')

    ax.set_xlabel('Number of PC')
    ax.set_ylabel('Cumulative explained variance fraction')
    ax.xaxis.set_ticks_position('top')
    ax.xaxis.set_label_position('top')

    for ax in axes:
        for s in ax.spines.values():
            s.set_visible(True)

    set_tight(w_pad=.5)

def boxplot(
        ax, percentiles, x=0, y=0, box_width=1,
        line_width=plt.rcParams['lines.linewidth'],
        color=(0, 0, 0), alpha=.6, zorder=10
):
    """
    Draw a minimal boxplot.

    `percentiles` must be a np.array of five numbers:

        whisker_low, quartile_1, median, quartile_3, whisker_high

    """
    pl, q1, q2, q3, ph = percentiles + y

    # IQR box
    ax.add_patch(patches.Rectangle(
        xy=(x - .5*box_width, q1),
        width=box_width, height=(q3 - q1),
        color=color, alpha=alpha, lw=0, zorder=zorder
    ))

    # median line
    ax.plot(
        [x - .5*box_width, x + .5*box_width], 2*[q2],
        lw=line_width, solid_capstyle='butt', color=color,
        zorder=zorder + 1
    )

    # whisker lines
    for y in [[q1, pl], [q3, ph]]:
        ax.plot(
            2*[x], y, lw=line_width, solid_capstyle='butt',
            color=color, alpha=alpha, zorder=zorder
        )

@plot
def diag_pca(system=system_strs[0]):
    """
    Diagnostic: histograms of principal components and scatterplots of pairs.
    Check for linear independence!

    """
    Y = [g.y_train_ for g in Trained_Emulators[system].gps]
    n = len(Y)
    ymax = np.ceil(max(np.fabs(y).max() for y in Y))
    lim = (-ymax, ymax)

    #fig, axes = plt.subplots(nrows=n, ncols=n, figsize=2*(n,))
    fig, axes = plt.subplots(nrows=n, ncols=n, figsize=(10,10))

    for y, ax in zip(Y, axes.diagonal()):
        ax.hist(y, bins=30)
        ax.set_xlim(lim)

    for ny, nx in zip(*np.tril_indices_from(axes, k=-1)):
        ax = axes[ny][nx]
        ax.scatter(Y[nx], Y[ny])
        ax.set_xlim(lim)
        ax.set_ylim(lim)
        axes[nx][ny].set_axis_off()

    for i in range(n):
        label = 'PC {}'.format(i)
        axes[-1][i].set_xlabel(label)
        axes[i][0].set_ylabel(label)

@plot
def diag_emu(system=system_strs[0], pcs=None, label_all=True):
    """
    Diagnostic: plots of each principal component vs each input parameter,
    overlaid by emulator predictions at several points in design space.

    """
    gps = Trained_Emulators[system].gps
    pcs = (
        range(len(gps)) if pcs is None else
        [p if p >= 0 else (len(gps) + p) for p in pcs]
    )
    nrows = len(pcs)

    #get design points
    design_file = design_dir + \
           '/design_points_main_{:s}{:s}-{:d}.dat'.format(*systems[0])
    logging.info("Loading design points from " + design_file)
    design = pd.read_csv(design_file)
    design = design.drop("idx", axis=1)
    # get range
    range_file = design_dir + \
               '/design_ranges_main_{:s}{:s}-{:d}.dat'.format(*systems[0])
    design_range = pd.read_csv(range_file)
    design_max = design_range['max'].values
    design_min = design_range['min'].values

    params = design.keys()
    ncols = len(params)

    fig, axes = plt.subplots(
        nrows=nrows, ncols=ncols,
        figsize=figsize((.5 if label_all else .375)*ncols, .62*nrows/ncols),
        sharex=(False if label_all else 'col'),
        sharey=(False if label_all else 'row')
    )

    ymax = np.ceil(2*max(np.fabs(gps[pc].y_train_).max() for pc in pcs))/2
    ylim = (-ymax, ymax)

    tmax = int(ymax)
    yticksmajor = [-tmax, 0, tmax]
    yticksminor = list(range(-tmax + 1, 0)) + list(range(1, tmax))

    for pc, row in zip(pcs, axes):
        gp = gps[pc]
        y = gp.y_train_

        for i, (param, ax) in enumerate(zip(params, row)):
            x = gp.X_train_[:, i]
            ax.plot(
                x, y, 'o',
                markersize=.4*plt.rcParams['lines.markersize'],
                color='.7',
                zorder=-30
            )

            xlim = design_min[i], design_max[i]
            x = np.linspace(xlim[0], xlim[1], 100)
            X = np.empty((x.size, gp.X_train_.shape[1]))

            for r, c in [(.2, 'purple'), (.5, 'blue'), (.8, 'green')]:
                X[:] = r*design_min + (1 - r)*design_max
                X[:, i] = x
                mean, std = gp.predict(X, return_std=True)

                color = colors[c]
                ax.plot(
                    x, mean,
                    linewidth=.8*plt.rcParams['lines.linewidth'],
                    color=color,
                    zorder=-10
                )
                ax.fill_between(
                    x, mean - std, mean + std,
                    lw=0, color=color, alpha=.3, zorder=-20
                )

            ax.set_xlim(xlim)
            ax.set_ylim(ylim)

            auto_ticks(ax, 'x', nbins=3, minor=2)
            ax.set_yticks(yticksmajor)
            ax.set_yticks(yticksminor, minor=True)

            if label_all or ax.is_last_row():
                ax.set_xlabel(design.keys()[i])
            if label_all or ax.is_first_col():
                ax.set_ylabel('PC {}'.format(pc + 1))

    set_tight(fig, w_pad=.5, h_pad=.25)

@plot
def mcmc_diagnostic():
    """
    This plots a diagonostic of the MCMC chain. Look for mixing and a short autocorrelation length.
    """
    from matplotlib.lines import Line2D

    chain = Chain(path=workdir/'mcmc_REDO'/'chain-idf-0_LHC_RHIC_PTSampler_500wkr_10ksteps_20temps_adaptive.hdf')
    labels = chain.labels
    ranges = chain.range

    nthin=1
    n_choose_walkers = 3
    max_percent_lag = 0.1

    indices = np.arange(19) #all
    labels = np.take(labels, indices)
    data = chain.load_wo_reshape(thin=nthin).T

    ndims, nsteps, nwalkers = data.shape
    walker_indices = np.random.choice(data.shape[0], n_choose_walkers)

    width_ratios = [0.7, 0.3]
    fig, axes = plt.subplots( nrows=ndims, ncols=2, figsize=(10, 20), gridspec_kw={'width_ratios': width_ratios} )
    plt.suptitle('MCMC Diagnostic')

    #styling
    colors = ['b', 'g', 'r', 'c', 'm']
    alpha=0.5

    for walker_idx in range(len(walker_indices)):
        wkr_data = data[ : , :, walker_indices[walker_idx] ]

        for row in range(ndims):
            x = wkr_data[row, :]
            window = len(x) // 10
            label = labels[row]
            df_wkr = pd.DataFrame(x, columns=['p'])
            df_wkr['mov_avg_p'] = df_wkr.p.rolling(window=window,center=False).mean()

            #plot the trace and its moving average
            axes[row][0].plot(x, alpha=alpha, color=colors[walker_idx], zorder=1)
            axes[row][0].plot(df_wkr['mov_avg_p'], alpha=1.0, ls='--', color=colors[walker_idx], lw=1.5, zorder=2)

            #plot the autocorrelation function
            acors = autocorrelation(chain=x, max_percent_lag = max_percent_lag)
            fraction_length = np.linspace(0., max_percent_lag, len(acors))
            axes[row][1].plot(fraction_length, acors, color=colors[walker_idx], ls='--')

            axes[row][0].set_ylabel(label)

    custom_lines = [Line2D([0], [0], color='k', lw=1, alpha=alpha),
                Line2D([0], [0], color='k', lw=1.5, alpha=1, ls='--')]
    axes[0][0].legend(custom_lines, ['Trace', str(window) + ' Step Mv. Avg.'], loc=(0.6, 0.9))
    #axes[0][0].set_title('Trace')
    axes[0][1].set_title('Autocorrelation')

    axes[ndims - 1][0].set_xlabel('Step')
    axes[ndims - 1][1].set_xlabel('Lag / Chain Length')

    fig.align_ylabels()
    plt.tight_layout(True)
    set_tight(pad=.0, h_pad=.0, w_pad=.0, rect=(0, 0, 1, 0.96))

if __name__ == '__main__':
    import argparse
    from matplotlib.mathtext import MathTextWarning

    warnings.filterwarnings(
        'ignore',
        category=MathTextWarning,
        message='Substituting with a symbol from Computer Modern.'
    )
    warnings.filterwarnings(
        'ignore',
        category=UserWarning,
        message=r"'[\w\.]+' can not be subsetted into a Type 3 font."
    )

    choices = list(plot_functions)

    def arg_to_plot(arg):
        arg = Path(arg).stem
        if arg not in choices:
            raise argparse.ArgumentTypeError(arg)
        return arg

    parser = argparse.ArgumentParser(description='generate plots')
    parser.add_argument(
        '--paper', action='store_true',
        help='use paper style: cm serif font, true black text + axes'
    )
    parser.add_argument(
        'plots', nargs='*', type=arg_to_plot, metavar='PLOT',
        help='{} (default: all)'.format(', '.join(choices).join('{}'))
    )
    args = parser.parse_args()

    if args.paper:
        plt.rcParams.update({
            'font.family': 'serif',
            'font.serif': ['CMU Serif'],
            'mathtext.fontset': 'cm',
            'text.color': 'black',
            'axes.edgecolor': 'black',
            'axes.labelcolor': 'black',
            'xtick.color': 'black',
            'ytick.color': 'black',
        })

    if args.plots:
        for p in args.plots:
            plot_functions[p]()
    else:
        for f in plot_functions.values():
            f()
